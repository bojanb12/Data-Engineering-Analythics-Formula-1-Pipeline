[2024-06-19T07:29:13.730+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T07:29:13.746+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T07:29:13.752+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T07:29:13.752+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T07:29:13.759+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T07:29:13.764+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=640) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T07:29:13.765+0000] {standard_task_runner.py:63} INFO - Started process 662 to run task
[2024-06-19T07:29:13.765+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp731cp6m9']
[2024-06-19T07:29:13.766+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-19T07:29:13.797+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 5d5bc16a80d8
[2024-06-19T07:29:13.851+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T07:29:13.852+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T07:29:13.985+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T07:29:13.987+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-19T07:29:13.988+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T07:29:13.988+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-19T07:29:14.133+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T07:29:14.133+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T07:29:14.287+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-19T07:29:14.288+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-19T07:29:14.288+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-19T07:29:14.603+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T07:29:14.642+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-19T07:29:14.643+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T07:29:14.643+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T07:29:14.644+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T07:29:14.651+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T072913, end_date=20240619T072914
[2024-06-19T07:29:14.700+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T07:29:14.711+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T07:29:14.712+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T08:27:36.179+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T08:27:36.198+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:27:36.204+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:27:36.204+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T08:27:36.212+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T08:27:36.217+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=611) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T08:27:36.218+0000] {standard_task_runner.py:63} INFO - Started process 635 to run task
[2024-06-19T08:27:36.218+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpm5l425cz']
[2024-06-19T08:27:36.220+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-19T08:27:36.250+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host d64590577fb7
[2024-06-19T08:27:36.300+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T08:27:36.301+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T08:27:36.435+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T08:27:36.437+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-19T08:27:36.437+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T08:27:36.438+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-19T08:27:36.542+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T08:27:36.543+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T08:27:36.697+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-19T08:27:36.697+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-19T08:27:36.697+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-19T08:27:36.809+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T08:27:36.815+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-19T08:27:36.816+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T08:27:36.817+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T08:27:36.817+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T08:27:36.826+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T082736, end_date=20240619T082736
[2024-06-19T08:27:36.873+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T08:27:36.884+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T08:27:36.885+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T08:54:41.219+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T08:54:41.237+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:54:41.243+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:54:41.244+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T08:54:41.252+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T08:54:41.257+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=601) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T08:54:41.258+0000] {standard_task_runner.py:63} INFO - Started process 631 to run task
[2024-06-19T08:54:41.258+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmppeinfx7d']
[2024-06-19T08:54:41.260+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-19T08:54:41.291+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host e5c8778eab06
[2024-06-19T08:54:41.343+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T08:54:41.344+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T08:54:41.475+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T08:54:41.477+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-19T08:54:41.478+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T08:54:41.478+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-19T08:54:41.592+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T08:54:41.592+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T08:54:41.745+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-19T08:54:41.746+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-19T08:54:41.746+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-19T08:54:41.997+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T08:54:42.033+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-19T08:54:42.034+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T08:54:42.034+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T08:54:42.034+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T08:54:42.041+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T085441, end_date=20240619T085442
[2024-06-19T08:54:42.073+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T08:54:42.083+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T08:54:42.084+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:06:00.035+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:06:00.055+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:06:00.061+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:06:00.062+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:06:00.071+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:06:00.076+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=634) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:06:00.077+0000] {standard_task_runner.py:63} INFO - Started process 654 to run task
[2024-06-19T12:06:00.077+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpnsf7x2fm']
[2024-06-19T12:06:00.079+0000] {standard_task_runner.py:91} INFO - Job 42: Subtask fetch_and_publish_freePractice
[2024-06-19T12:06:00.113+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host eef124934bf8
[2024-06-19T12:06:00.171+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:06:00.171+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:06:00.334+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T12:06:00.336+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-19T12:06:00.336+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T12:06:00.337+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-19T12:06:00.439+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T12:06:00.440+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T12:06:00.443+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T12:06:00.444+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-19T12:06:00.444+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-19T12:06:00.444+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:06:00.450+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:06:00.450+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T12:06:00.451+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:06:00.451+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:06:00.458+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T120600, end_date=20240619T120600
[2024-06-19T12:06:00.490+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:06:00.502+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:06:00.503+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:37:09.440+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:37:09.510+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:37:09.524+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:37:09.524+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:37:09.545+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:37:09.554+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=655) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:37:09.556+0000] {standard_task_runner.py:63} INFO - Started process 675 to run task
[2024-06-19T12:37:09.557+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmput3j1mml']
[2024-06-19T12:37:09.559+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask fetch_and_publish_freePractice
[2024-06-19T12:37:09.628+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 3a98e934d90a
[2024-06-19T12:37:09.738+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:37:09.740+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:37:09.887+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T12:37:09.889+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-19T12:37:09.890+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T12:37:09.890+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-19T12:37:10.139+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T12:37:10.139+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T12:37:10.313+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-19T12:37:10.314+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-19T12:37:10.314+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:37:10.874+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T12:37:10.881+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:37:10.882+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T12:37:10.882+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:37:10.883+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:37:10.890+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T123709, end_date=20240619T123710
[2024-06-19T12:37:10.934+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:37:10.946+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:37:10.948+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:53:37.624+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:53:37.650+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:53:37.659+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:53:37.659+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:53:37.669+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:53:37.675+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=607) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:53:37.677+0000] {standard_task_runner.py:63} INFO - Started process 621 to run task
[2024-06-19T12:53:37.677+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpsmqo042b']
[2024-06-19T12:53:37.679+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask fetch_and_publish_freePractice
[2024-06-19T12:53:37.720+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 9426bfe013d2
[2024-06-19T12:53:37.794+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:53:37.795+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:53:38.124+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T12:53:38.127+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-19T12:53:38.127+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T12:53:38.128+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-19T12:53:38.408+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T12:53:38.408+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T12:53:38.562+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-19T12:53:38.562+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-19T12:53:38.562+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:53:39.200+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T12:53:39.284+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-19T12:53:39.284+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T12:53:39.285+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:53:39.285+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:53:39.293+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T125337, end_date=20240619T125339
[2024-06-19T12:53:39.334+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:53:39.347+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:53:39.348+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:03:41.855+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:03:41.878+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:03:41.886+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:03:41.886+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:03:41.896+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:03:41.901+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=612) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:03:41.902+0000] {standard_task_runner.py:63} INFO - Started process 636 to run task
[2024-06-19T13:03:41.903+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp2kyoikcx']
[2024-06-19T13:03:41.904+0000] {standard_task_runner.py:91} INFO - Job 41: Subtask fetch_and_publish_freePractice
[2024-06-19T13:03:41.944+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 6fa64189ef34
[2024-06-19T13:03:42.013+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:03:42.014+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:03:42.144+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T13:03:42.146+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-19T13:03:42.146+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T13:03:42.147+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-19T13:03:42.249+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T13:03:42.249+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T13:03:42.403+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-19T13:03:42.403+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-19T13:03:42.403+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:03:42.818+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T13:03:42.828+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:03:42.829+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T13:03:42.830+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:03:42.830+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:03:42.838+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T130341, end_date=20240619T130342
[2024-06-19T13:03:42.878+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:03:42.884+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:17:24.771+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:17:24.794+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:17:24.804+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:17:24.804+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:17:24.816+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:17:24.822+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=606) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:17:24.823+0000] {standard_task_runner.py:63} INFO - Started process 626 to run task
[2024-06-19T13:17:24.824+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpv13ts7rj']
[2024-06-19T13:17:24.826+0000] {standard_task_runner.py:91} INFO - Job 36: Subtask fetch_and_publish_freePractice
[2024-06-19T13:17:24.873+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host d5b44298ec9f
[2024-06-19T13:17:24.950+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:17:24.951+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:17:25.179+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T13:17:25.181+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-19T13:17:25.181+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T13:17:25.182+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-19T13:17:25.391+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T13:17:25.392+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T13:17:25.546+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-19T13:17:25.546+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-19T13:17:25.547+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:17:26.119+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T13:17:26.201+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:17:26.201+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T13:17:26.202+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:17:26.202+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:17:26.210+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T131724, end_date=20240619T131726
[2024-06-19T13:17:26.240+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:17:26.253+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:17:26.256+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:27:53.692+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:27:53.716+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:27:53.726+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:27:53.726+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:27:53.736+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:27:53.742+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=595) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:27:53.743+0000] {standard_task_runner.py:63} INFO - Started process 611 to run task
[2024-06-19T13:27:53.744+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpo08_t5na']
[2024-06-19T13:27:53.746+0000] {standard_task_runner.py:91} INFO - Job 35: Subtask fetch_and_publish_freePractice
[2024-06-19T13:27:53.789+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host fc0cf0aa1225
[2024-06-19T13:27:53.874+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:27:53.876+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:27:54.007+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T13:27:54.009+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-19T13:27:54.009+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T13:27:54.010+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-19T13:27:54.298+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T13:27:54.298+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T13:27:54.451+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-19T13:27:54.452+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-19T13:27:54.452+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:27:55.107+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T13:27:55.170+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:27:55.171+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T13:27:55.172+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:27:55.172+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:27:55.180+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T132753, end_date=20240619T132755
[2024-06-19T13:27:55.201+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:27:55.213+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:27:55.214+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:38:03.182+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:38:03.205+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:38:03.213+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:38:03.213+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:38:03.226+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:38:03.231+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=598) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:38:03.233+0000] {standard_task_runner.py:63} INFO - Started process 615 to run task
[2024-06-19T13:38:03.234+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpirvion7x']
[2024-06-19T13:38:03.236+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask fetch_and_publish_freePractice
[2024-06-19T13:38:03.278+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 790bccf90551
[2024-06-19T13:38:03.354+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:38:03.355+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:38:03.504+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T13:38:03.505+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-19T13:38:03.506+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T13:38:03.506+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-19T13:38:03.748+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T13:38:03.748+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T13:38:03.904+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-19T13:38:03.904+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-19T13:38:03.905+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:38:04.389+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T13:38:04.479+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-19T13:38:04.479+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T13:38:04.480+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:38:04.480+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:38:04.487+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T133803, end_date=20240619T133804
[2024-06-19T13:38:04.529+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:38:04.537+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:01:47.277+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:01:47.301+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:01:47.312+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:01:47.313+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:01:47.325+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:01:47.332+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=611) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:01:47.334+0000] {standard_task_runner.py:63} INFO - Started process 628 to run task
[2024-06-19T14:01:47.334+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp3c43udig']
[2024-06-19T14:01:47.336+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-19T14:01:47.378+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 0ff0d3189758
[2024-06-19T14:01:47.453+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:01:47.454+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:01:47.619+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T14:01:47.621+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-19T14:01:47.622+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T14:01:47.622+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-19T14:01:47.831+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T14:01:47.831+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T14:01:47.985+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-19T14:01:47.985+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-19T14:01:47.985+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:01:48.613+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T14:01:48.739+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:01:48.739+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T14:01:48.740+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:01:48.740+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:01:48.748+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T140147, end_date=20240619T140148
[2024-06-19T14:01:48.791+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:01:48.802+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:01:48.804+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:05:24.937+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:05:24.961+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:05:24.970+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:05:24.971+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:05:24.983+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:05:24.990+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=598) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:05:24.991+0000] {standard_task_runner.py:63} INFO - Started process 615 to run task
[2024-06-19T14:05:24.991+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp6u33n2w9']
[2024-06-19T14:05:24.993+0000] {standard_task_runner.py:91} INFO - Job 35: Subtask fetch_and_publish_freePractice
[2024-06-19T14:05:25.041+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host dc92dd71b4a2
[2024-06-19T14:05:25.116+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:05:25.117+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:05:25.250+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T14:05:25.252+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-19T14:05:25.252+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T14:05:25.253+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-19T14:05:25.511+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T14:05:25.511+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T14:05:25.665+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-19T14:05:25.665+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-19T14:05:25.666+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:05:26.359+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T14:05:26.502+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:05:26.503+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T14:05:26.503+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:05:26.503+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:05:26.512+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T140524, end_date=20240619T140526
[2024-06-19T14:05:26.568+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:05:26.576+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:14:24.771+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:14:24.792+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:14:24.800+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:14:24.800+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:14:24.810+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:14:24.816+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=632) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:14:24.817+0000] {standard_task_runner.py:63} INFO - Started process 648 to run task
[2024-06-19T14:14:24.818+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpez8hpoun']
[2024-06-19T14:14:24.819+0000] {standard_task_runner.py:91} INFO - Job 36: Subtask fetch_and_publish_freePractice
[2024-06-19T14:14:24.862+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 2acd74b25e37
[2024-06-19T14:14:24.934+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:14:24.935+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:14:25.069+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T14:14:25.070+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('192.168.0.6', 9092)]>: connecting to kafka:9092 [('192.168.0.6', 9092) IPv4]
[2024-06-19T14:14:25.071+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T14:14:25.071+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('192.168.0.6', 9092)]>: Connection complete.
[2024-06-19T14:14:25.283+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T14:14:25.283+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T14:14:25.437+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('192.168.0.6', 9092)]>: connecting to kafka:9092 [('192.168.0.6', 9092) IPv4]
[2024-06-19T14:14:25.437+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('192.168.0.6', 9092)]>: Connection complete.
[2024-06-19T14:14:25.438+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('192.168.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:14:25.890+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T14:14:25.976+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('192.168.0.6', 9092)]>: Closing connection. 
[2024-06-19T14:14:25.976+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T14:14:25.977+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:14:25.977+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:14:25.985+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T141424, end_date=20240619T141425
[2024-06-19T14:14:26.033+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:14:26.044+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:14:26.045+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:26:20.979+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:26:21.008+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:26:21.020+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:26:21.020+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:26:21.032+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:26:21.039+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=600) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:26:21.040+0000] {standard_task_runner.py:63} INFO - Started process 620 to run task
[2024-06-19T14:26:21.042+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpmev6syzc']
[2024-06-19T14:26:21.044+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask fetch_and_publish_freePractice
[2024-06-19T14:26:21.093+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-18T00:00:00+00:00 [running]> on host 7f714baf6013
[2024-06-19T14:26:21.179+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:26:21.181+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:26:21.316+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-19T14:26:21.318+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('192.168.32.6', 9092)]>: connecting to kafka:9092 [('192.168.32.6', 9092) IPv4]
[2024-06-19T14:26:21.318+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-19T14:26:21.319+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('192.168.32.6', 9092)]>: Connection complete.
[2024-06-19T14:26:21.703+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-19T14:26:21.703+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-19T14:26:21.857+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('192.168.32.6', 9092)]>: connecting to kafka:9092 [('192.168.32.6', 9092) IPv4]
[2024-06-19T14:26:21.858+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('192.168.32.6', 9092)]>: Connection complete.
[2024-06-19T14:26:21.858+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('192.168.32.6', 9092)]>: Closing connection. 
[2024-06-19T14:26:22.466+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-19T14:26:22.560+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('192.168.32.6', 9092)]>: Closing connection. 
[2024-06-19T14:26:22.561+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-19T14:26:22.562+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:26:22.562+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:26:22.570+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T142621, end_date=20240619T142622
[2024-06-19T14:26:22.618+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:26:22.626+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
