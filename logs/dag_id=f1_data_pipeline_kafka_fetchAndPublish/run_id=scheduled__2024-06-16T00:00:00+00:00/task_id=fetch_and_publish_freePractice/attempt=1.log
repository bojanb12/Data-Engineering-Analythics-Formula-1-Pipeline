[2024-06-17T07:43:39.741+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T07:43:39.757+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:39.762+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:39.762+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T07:43:39.772+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T07:43:39.778+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=647) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T07:43:39.778+0000] {standard_task_runner.py:63} INFO - Started process 665 to run task
[2024-06-17T07:43:39.779+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpxejp7_na']
[2024-06-17T07:43:39.780+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask fetch_and_publish_freePractice
[2024-06-17T07:43:39.825+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host c78fbdbb8669
[2024-06-17T07:43:39.896+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T07:43:39.897+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T07:43:40.041+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T07:43:40.043+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-17T07:43:40.043+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T07:43:40.044+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-17T07:43:40.153+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T07:43:40.153+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T07:43:40.307+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-17T07:43:40.307+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-17T07:43:40.307+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-17T07:43:40.569+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T07:43:40.601+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-17T07:43:40.602+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T07:43:40.602+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T07:43:40.610+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T074339, end_date=20240617T074340
[2024-06-17T07:43:40.634+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T07:43:40.645+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T07:43:40.647+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T08:18:46.760+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T08:18:46.779+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:18:46.786+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:18:46.787+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T08:18:46.799+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T08:18:46.804+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=622) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T08:18:46.805+0000] {standard_task_runner.py:63} INFO - Started process 640 to run task
[2024-06-17T08:18:46.807+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpycznyo63']
[2024-06-17T08:18:46.809+0000] {standard_task_runner.py:91} INFO - Job 35: Subtask fetch_and_publish_freePractice
[2024-06-17T08:18:46.850+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 8b2116437c09
[2024-06-17T08:18:46.916+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T08:18:46.917+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T08:18:47.048+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T08:18:47.050+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-17T08:18:47.050+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T08:18:47.051+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-17T08:18:47.171+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T08:18:47.172+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T08:18:47.326+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-17T08:18:47.327+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-17T08:18:47.327+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-17T08:18:47.599+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T08:18:47.661+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-17T08:18:47.661+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T08:18:47.662+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T08:18:47.669+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T081846, end_date=20240617T081847
[2024-06-17T08:18:47.701+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T08:18:47.712+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T08:18:47.713+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:05:19.007+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:05:19.019+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:05:19.023+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:05:19.023+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:05:19.030+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:05:19.034+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=613) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:05:19.035+0000] {standard_task_runner.py:63} INFO - Started process 623 to run task
[2024-06-17T09:05:19.035+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpyp00oc1z']
[2024-06-17T09:05:19.036+0000] {standard_task_runner.py:91} INFO - Job 38: Subtask fetch_and_publish_freePractice
[2024-06-17T09:05:19.064+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host c4902b1065ce
[2024-06-17T09:05:19.109+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:05:19.110+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:05:19.240+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T09:05:19.242+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-17T09:05:19.242+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T09:05:19.243+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-17T09:05:19.345+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T09:05:19.346+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T09:05:19.500+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-17T09:05:19.500+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-17T09:05:19.500+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-17T09:05:19.612+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T09:05:19.618+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-17T09:05:19.618+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T09:05:19.619+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T09:05:19.619+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:05:19.625+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T090519, end_date=20240617T090519
[2024-06-17T09:05:19.650+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:05:19.659+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:05:19.660+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:26:46.707+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:26:46.720+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:26:46.725+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:26:46.725+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:26:46.733+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:26:46.737+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=604) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:26:46.738+0000] {standard_task_runner.py:63} INFO - Started process 626 to run task
[2024-06-17T09:26:46.738+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp3bb7elmn']
[2024-06-17T09:26:46.739+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask fetch_and_publish_freePractice
[2024-06-17T09:26:46.770+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host dbef0fd3372f
[2024-06-17T09:26:46.819+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:26:46.820+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:26:46.982+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T09:26:46.983+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-17T09:26:46.984+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T09:26:46.984+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-17T09:26:47.086+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T09:26:47.086+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T09:26:47.240+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-17T09:26:47.240+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-17T09:26:47.240+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-17T09:26:47.350+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T09:26:47.355+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-17T09:26:47.355+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T09:26:47.355+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T09:26:47.356+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:26:47.362+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T092646, end_date=20240617T092647
[2024-06-17T09:26:47.392+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:26:47.403+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:26:47.404+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:26:01.389+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:26:01.403+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:26:01.408+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:26:01.409+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:26:01.417+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:26:01.422+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1240) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:26:01.423+0000] {standard_task_runner.py:63} INFO - Started process 1253 to run task
[2024-06-17T10:26:01.423+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpc1hfqz4j']
[2024-06-17T10:26:01.424+0000] {standard_task_runner.py:91} INFO - Job 38: Subtask fetch_and_publish_freePractice
[2024-06-17T10:26:01.458+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host f37b7fb66c71
[2024-06-17T10:26:01.511+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:26:01.512+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:26:01.644+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T10:26:01.645+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-17T10:26:01.645+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T10:26:01.646+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-17T10:26:01.749+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T10:26:01.749+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T10:26:01.903+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-17T10:26:01.904+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-17T10:26:01.904+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-17T10:26:02.019+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T10:26:02.025+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-17T10:26:02.026+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T10:26:02.026+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T10:26:02.027+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:26:02.033+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T102601, end_date=20240617T102602
[2024-06-17T10:26:02.077+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:26:02.088+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:26:02.089+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:41:05.780+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:41:05.798+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:41:05.805+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:41:05.806+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:41:05.820+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:41:05.827+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=606) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:41:05.828+0000] {standard_task_runner.py:63} INFO - Started process 629 to run task
[2024-06-17T10:41:05.829+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpbnfc1vi2']
[2024-06-17T10:41:05.832+0000] {standard_task_runner.py:91} INFO - Job 38: Subtask fetch_and_publish_freePractice
[2024-06-17T10:41:05.879+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 688ecc0cce5b
[2024-06-17T10:41:05.950+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:41:05.951+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:41:06.117+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T10:41:06.119+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-17T10:41:06.119+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T10:41:06.120+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-17T10:41:06.227+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T10:41:06.228+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T10:41:06.382+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-17T10:41:06.383+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-17T10:41:06.383+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-17T10:41:06.639+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T10:41:06.674+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-17T10:41:06.675+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T10:41:06.675+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T10:41:06.676+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:41:06.682+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T104105, end_date=20240617T104106
[2024-06-17T10:41:06.724+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:41:06.734+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:41:06.736+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T11:13:41.932+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T11:13:41.949+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:41.954+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:41.955+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T11:13:41.964+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T11:13:41.968+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=587) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T11:13:41.969+0000] {standard_task_runner.py:63} INFO - Started process 600 to run task
[2024-06-17T11:13:41.970+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '31', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpy22kvz9i']
[2024-06-17T11:13:41.971+0000] {standard_task_runner.py:91} INFO - Job 31: Subtask fetch_and_publish_freePractice
[2024-06-17T11:13:42.013+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 3a133740bf3d
[2024-06-17T11:13:42.078+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T11:13:42.079+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T11:13:42.274+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T11:13:42.276+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-17T11:13:42.276+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T11:13:42.276+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-17T11:13:42.388+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T11:13:42.388+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T11:13:42.543+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-17T11:13:42.543+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-17T11:13:42.543+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-17T11:13:42.793+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T11:13:42.799+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-17T11:13:42.799+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T11:13:42.799+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T11:13:42.800+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T11:13:42.806+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T111341, end_date=20240617T111342
[2024-06-17T11:13:42.824+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T11:13:42.835+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T11:13:42.836+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:24:11.323+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:24:11.336+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:24:11.341+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:24:11.341+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:24:11.349+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:24:11.354+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=583) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:24:11.355+0000] {standard_task_runner.py:63} INFO - Started process 604 to run task
[2024-06-17T12:24:11.355+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmphnte8n1k']
[2024-06-17T12:24:11.356+0000] {standard_task_runner.py:91} INFO - Job 38: Subtask fetch_and_publish_freePractice
[2024-06-17T12:24:11.386+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 5ef985758484
[2024-06-17T12:24:11.437+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:24:11.438+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:24:11.567+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T12:24:11.569+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-17T12:24:11.570+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T12:24:11.571+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-17T12:24:11.695+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T12:24:11.696+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T12:24:11.849+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-17T12:24:11.850+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-17T12:24:11.850+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:24:12.115+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T12:24:12.148+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:24:12.149+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T12:24:12.149+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:24:12.150+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:24:12.156+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T122411, end_date=20240617T122412
[2024-06-17T12:24:12.170+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:24:12.180+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:24:12.182+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:42:11.499+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:42:11.516+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:42:11.523+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:42:11.523+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:42:11.533+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:42:11.539+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=593) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:42:11.540+0000] {standard_task_runner.py:63} INFO - Started process 608 to run task
[2024-06-17T12:42:11.541+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '31', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpifjx5d3v']
[2024-06-17T12:42:11.543+0000] {standard_task_runner.py:91} INFO - Job 31: Subtask fetch_and_publish_freePractice
[2024-06-17T12:42:11.586+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host c6f07e7c011e
[2024-06-17T12:42:11.658+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:42:11.659+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:42:11.988+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T12:42:11.990+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-17T12:42:11.990+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T12:42:11.990+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-17T12:42:12.108+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T12:42:12.108+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T12:42:12.261+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-17T12:42:12.262+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-17T12:42:12.262+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:42:12.552+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T12:42:12.589+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:42:12.589+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T12:42:12.590+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:42:12.590+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:42:12.599+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124211, end_date=20240617T124212
[2024-06-17T12:42:12.636+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:42:12.649+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:42:12.650+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:47:49.982+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:47:50.004+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:50.012+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:50.013+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:47:50.026+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:47:50.032+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=588) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:47:50.033+0000] {standard_task_runner.py:63} INFO - Started process 609 to run task
[2024-06-17T12:47:50.033+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp7kunjjum']
[2024-06-17T12:47:50.035+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask fetch_and_publish_freePractice
[2024-06-17T12:47:50.087+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 7b9616fbccae
[2024-06-17T12:47:50.167+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:47:50.168+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:47:50.299+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T12:47:50.301+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-17T12:47:50.302+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T12:47:50.303+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-17T12:47:50.412+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T12:47:50.413+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T12:47:50.567+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-17T12:47:50.568+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-17T12:47:50.568+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:47:50.831+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T12:47:50.867+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-17T12:47:50.867+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T12:47:50.868+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:47:50.869+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:47:50.877+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124750, end_date=20240617T124750
[2024-06-17T12:47:50.889+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:47:50.900+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:47:50.901+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:17:24.195+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:17:24.210+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:17:24.215+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:17:24.215+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:17:24.224+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:17:24.229+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=611) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:17:24.230+0000] {standard_task_runner.py:63} INFO - Started process 635 to run task
[2024-06-17T13:17:24.230+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp2612b2lh']
[2024-06-17T13:17:24.231+0000] {standard_task_runner.py:91} INFO - Job 36: Subtask fetch_and_publish_freePractice
[2024-06-17T13:17:24.262+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 32e484e314f3
[2024-06-17T13:17:24.314+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:17:24.315+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:17:24.448+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T13:17:24.450+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-17T13:17:24.450+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T13:17:24.451+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-17T13:17:24.553+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T13:17:24.554+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T13:17:24.708+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-17T13:17:24.708+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-17T13:17:24.708+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:17:24.820+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T13:17:24.826+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:17:24.826+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T13:17:24.827+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:17:24.827+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:17:24.834+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T131724, end_date=20240617T131724
[2024-06-17T13:17:24.884+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:17:24.891+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:19:50.934+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:19:50.951+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:19:50.958+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:19:50.958+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:19:50.968+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:19:50.975+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1244) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:19:50.976+0000] {standard_task_runner.py:63} INFO - Started process 1269 to run task
[2024-06-17T13:19:50.976+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpapiax1bg']
[2024-06-17T13:19:50.978+0000] {standard_task_runner.py:91} INFO - Job 52: Subtask fetch_and_publish_freePractice
[2024-06-17T13:19:51.020+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 32e484e314f3
[2024-06-17T13:19:51.095+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:19:51.097+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:19:51.228+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T13:19:51.230+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-17T13:19:51.230+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T13:19:51.231+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-17T13:19:51.333+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T13:19:51.333+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T13:19:51.336+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T13:19:51.337+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-17T13:19:51.337+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-17T13:19:51.337+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:19:51.341+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:19:51.342+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T13:19:51.342+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:19:51.342+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:19:51.350+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T131950, end_date=20240617T131951
[2024-06-17T13:19:51.389+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:19:51.402+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:19:51.404+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:27:11.807+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:27:11.826+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:27:11.834+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:27:11.834+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:27:11.844+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:27:11.851+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=601) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:27:11.853+0000] {standard_task_runner.py:63} INFO - Started process 618 to run task
[2024-06-17T13:27:11.853+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpq8ksgqlo']
[2024-06-17T13:27:11.855+0000] {standard_task_runner.py:91} INFO - Job 32: Subtask fetch_and_publish_freePractice
[2024-06-17T13:27:11.906+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 96c07605841c
[2024-06-17T13:27:11.976+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:27:11.977+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:27:12.109+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T13:27:12.111+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-17T13:27:12.112+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T13:27:12.112+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-17T13:27:12.227+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T13:27:12.227+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T13:27:12.382+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-17T13:27:12.382+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-17T13:27:12.382+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:27:12.640+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T13:27:12.676+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:27:12.677+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T13:27:12.678+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:27:12.678+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:27:12.685+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T132711, end_date=20240617T132712
[2024-06-17T13:27:12.709+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:27:12.720+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:27:12.722+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:33:26.177+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:33:26.193+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:33:26.199+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:33:26.199+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:33:26.208+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:33:26.214+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1874) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:33:26.216+0000] {standard_task_runner.py:63} INFO - Started process 1912 to run task
[2024-06-17T13:33:26.217+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpizrojb8f']
[2024-06-17T13:33:26.218+0000] {standard_task_runner.py:91} INFO - Job 68: Subtask fetch_and_publish_freePractice
[2024-06-17T13:33:26.255+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 96c07605841c
[2024-06-17T13:33:26.312+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:33:26.313+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:33:26.444+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T13:33:26.446+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-17T13:33:26.447+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T13:33:26.447+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-17T13:33:26.549+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T13:33:26.549+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T13:33:26.551+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T13:33:26.552+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: connecting to kafka:9092 [('172.29.0.6', 9092) IPv4]
[2024-06-17T13:33:26.553+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.29.0.6', 9092)]>: Connection complete.
[2024-06-17T13:33:26.553+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:33:26.556+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.29.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:33:26.557+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T13:33:26.557+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:33:26.557+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:33:26.565+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T133326, end_date=20240617T133326
[2024-06-17T13:33:26.590+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:33:26.601+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:33:26.602+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:57:30.498+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:57:30.520+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:57:30.528+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:57:30.528+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:57:30.541+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:57:30.547+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=622) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:57:30.550+0000] {standard_task_runner.py:63} INFO - Started process 641 to run task
[2024-06-17T13:57:30.549+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp31snh2tb']
[2024-06-17T13:57:30.551+0000] {standard_task_runner.py:91} INFO - Job 32: Subtask fetch_and_publish_freePractice
[2024-06-17T13:57:30.606+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host b1cdb958cbe8
[2024-06-17T13:57:30.675+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:57:30.676+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:57:30.848+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T13:57:30.850+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-17T13:57:30.850+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T13:57:30.851+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-17T13:57:30.970+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T13:57:30.971+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T13:57:31.126+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-17T13:57:31.127+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-17T13:57:31.127+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:57:31.398+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T13:57:31.431+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-17T13:57:31.431+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T13:57:31.432+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:57:31.432+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:57:31.439+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T135730, end_date=20240617T135731
[2024-06-17T13:57:31.486+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:57:31.497+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:57:31.499+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T14:14:59.521+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T14:14:59.542+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:59.552+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:59.552+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T14:14:59.563+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-17T14:14:59.569+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=604) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T14:14:59.570+0000] {standard_task_runner.py:63} INFO - Started process 623 to run task
[2024-06-17T14:14:59.572+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpgxz5m9rq']
[2024-06-17T14:14:59.573+0000] {standard_task_runner.py:91} INFO - Job 35: Subtask fetch_and_publish_freePractice
[2024-06-17T14:14:59.615+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host ad2413a51065
[2024-06-17T14:14:59.687+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T14:14:59.689+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T14:14:59.833+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-17T14:14:59.834+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-17T14:14:59.835+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-17T14:14:59.835+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-17T14:15:00.101+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-17T14:15:00.101+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-17T14:15:00.264+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-17T14:15:00.264+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-17T14:15:00.264+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-17T14:15:00.813+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-17T14:15:00.905+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-17T14:15:00.906+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-17T14:15:00.906+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T14:15:00.906+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T14:15:00.913+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T141459, end_date=20240617T141500
[2024-06-17T14:15:00.947+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T14:15:00.958+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T14:15:00.959+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-24T07:22:15.094+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-24T07:22:15.112+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:22:15.117+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:22:15.118+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-24T07:22:15.126+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-16 00:00:00+00:00
[2024-06-24T07:22:15.130+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=600) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-24T07:22:15.131+0000] {standard_task_runner.py:63} INFO - Started process 626 to run task
[2024-06-24T07:22:15.132+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpc987x2l9']
[2024-06-24T07:22:15.133+0000] {standard_task_runner.py:91} INFO - Job 42: Subtask fetch_and_publish_freePractice
[2024-06-24T07:22:15.167+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-16T00:00:00+00:00 [running]> on host 4fefe0a35f4a
[2024-06-24T07:22:15.223+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-24T07:22:15.224+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-24T07:22:15.355+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-24T07:22:15.356+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-24T07:22:15.357+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-24T07:22:15.357+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-24T07:22:15.460+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-24T07:22:15.460+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-24T07:22:15.464+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-24T07:22:15.465+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-24T07:22:15.466+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-24T07:22:15.466+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-24T07:22:15.470+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-24T07:22:15.471+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-24T07:22:15.471+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-24T07:22:15.472+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-24T07:22:15.479+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240624T072215, end_date=20240624T072215
[2024-06-24T07:22:15.505+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-24T07:22:15.516+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-24T07:22:15.517+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
