[2024-06-18T07:20:23.826+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T07:20:23.846+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:20:23.858+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:20:23.858+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T07:20:23.873+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T07:20:23.879+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=599) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T07:20:23.880+0000] {standard_task_runner.py:63} INFO - Started process 617 to run task
[2024-06-18T07:20:23.880+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpvrlq6k01']
[2024-06-18T07:20:23.882+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask fetch_and_publish_freePractice
[2024-06-18T07:20:23.932+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host ce62f6b650cd
[2024-06-18T07:20:24.004+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T07:20:24.006+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T07:20:24.222+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T07:20:24.224+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-18T07:20:24.224+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T07:20:24.225+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-18T07:20:24.326+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T07:20:24.327+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T07:20:24.480+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-18T07:20:24.480+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-18T07:20:24.481+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-18T07:20:24.607+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T07:20:24.637+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-18T07:20:24.638+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T07:20:24.638+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T07:20:24.638+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T07:20:24.645+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T072023, end_date=20240618T072024
[2024-06-18T07:20:24.695+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T07:20:24.705+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T07:20:24.707+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:12:31.228+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:12:31.249+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:12:31.259+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:12:31.259+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:12:31.270+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:12:31.276+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=600) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:12:31.277+0000] {standard_task_runner.py:63} INFO - Started process 619 to run task
[2024-06-18T08:12:31.279+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp3sqmnco0']
[2024-06-18T08:12:31.281+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask fetch_and_publish_freePractice
[2024-06-18T08:12:31.323+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 0a8bae48237c
[2024-06-18T08:12:31.393+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:12:31.394+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:12:31.626+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T08:12:31.627+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-18T08:12:31.628+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:12:31.628+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-18T08:12:31.748+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:12:31.748+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:12:31.902+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: connecting to kafka:9092 [('172.19.0.6', 9092) IPv4]
[2024-06-18T08:12:31.902+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.19.0.6', 9092)]>: Connection complete.
[2024-06-18T08:12:31.903+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:12:32.362+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T08:12:32.458+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.19.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:12:32.459+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T08:12:32.460+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:12:32.460+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:12:32.468+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T081231, end_date=20240618T081232
[2024-06-18T08:12:32.493+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:12:32.507+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:12:32.508+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:23:11.300+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:23:11.315+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:23:11.321+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:23:11.322+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:23:11.328+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:23:11.332+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=650) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:23:11.333+0000] {standard_task_runner.py:63} INFO - Started process 661 to run task
[2024-06-18T08:23:11.334+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp02q0oxmt']
[2024-06-18T08:23:11.335+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-18T08:23:11.367+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 7d3c9e9f45b7
[2024-06-18T08:23:11.416+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:23:11.417+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:23:11.547+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T08:23:11.548+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-18T08:23:11.548+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:23:11.549+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-18T08:23:11.651+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:23:11.652+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:23:11.806+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: connecting to kafka:9092 [('172.20.0.6', 9092) IPv4]
[2024-06-18T08:23:11.806+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.20.0.6', 9092)]>: Connection complete.
[2024-06-18T08:23:11.806+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:23:11.920+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T08:23:11.929+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.20.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:23:11.930+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T08:23:11.930+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:23:11.931+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:23:11.938+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T082311, end_date=20240618T082311
[2024-06-18T08:23:11.988+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:23:11.998+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:23:11.999+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:30:35.671+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:30:35.696+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:30:35.706+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:30:35.706+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:30:35.722+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:30:35.729+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=597) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:30:35.730+0000] {standard_task_runner.py:63} INFO - Started process 614 to run task
[2024-06-18T08:30:35.730+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpiz95s2va']
[2024-06-18T08:30:35.732+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask fetch_and_publish_freePractice
[2024-06-18T08:30:35.779+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host d26fdf24870c
[2024-06-18T08:30:35.854+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:30:35.855+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:30:36.073+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T08:30:36.074+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-18T08:30:36.075+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:30:36.076+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-18T08:30:36.199+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:30:36.199+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:30:36.353+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-18T08:30:36.353+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-18T08:30:36.353+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:30:36.684+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T08:30:36.718+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:30:36.719+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T08:30:36.719+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:30:36.720+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:30:36.726+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T083035, end_date=20240618T083036
[2024-06-18T08:30:36.745+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:30:36.756+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:30:36.757+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:55:08.010+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:55:08.035+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:55:08.042+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:55:08.043+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:55:08.056+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:55:08.064+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=607) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:55:08.065+0000] {standard_task_runner.py:63} INFO - Started process 627 to run task
[2024-06-18T08:55:08.066+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpcrl4jaff']
[2024-06-18T08:55:08.068+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask fetch_and_publish_freePractice
[2024-06-18T08:55:08.115+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 70dbe2d93c7b
[2024-06-18T08:55:08.196+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:55:08.197+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:55:08.329+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T08:55:08.331+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-18T08:55:08.331+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:55:08.332+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-18T08:55:08.440+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:55:08.440+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:55:08.594+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: connecting to kafka:9092 [('172.22.0.6', 9092) IPv4]
[2024-06-18T08:55:08.595+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.22.0.6', 9092)]>: Connection complete.
[2024-06-18T08:55:08.595+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:55:08.851+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T08:55:08.857+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.22.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:55:08.857+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T08:55:08.858+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:55:08.858+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:55:08.865+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T085508, end_date=20240618T085508
[2024-06-18T08:55:08.880+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:55:08.892+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:55:08.893+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:58:44.027+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:58:44.047+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:58:44.057+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:58:44.057+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:58:44.068+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:58:44.073+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=598) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:58:44.074+0000] {standard_task_runner.py:63} INFO - Started process 618 to run task
[2024-06-18T08:58:44.075+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpa7z6x6yl']
[2024-06-18T08:58:44.077+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask fetch_and_publish_freePractice
[2024-06-18T08:58:44.116+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 85d13f87db98
[2024-06-18T08:58:44.191+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:58:44.192+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:58:44.326+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T08:58:44.328+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T08:58:44.328+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:58:44.329+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T08:58:44.608+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:58:44.608+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:58:44.784+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T08:58:44.785+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T08:58:44.785+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:58:45.447+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T08:58:45.527+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:58:45.527+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T08:58:45.528+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:58:45.528+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:58:45.537+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T085844, end_date=20240618T085845
[2024-06-18T08:58:45.571+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:58:45.585+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:58:45.586+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T11:56:04.369+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T11:56:04.399+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:56:04.409+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:56:04.410+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T11:56:04.423+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T11:56:04.431+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=610) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T11:56:04.433+0000] {standard_task_runner.py:63} INFO - Started process 625 to run task
[2024-06-18T11:56:04.432+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpbocb21x0']
[2024-06-18T11:56:04.436+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask fetch_and_publish_freePractice
[2024-06-18T11:56:04.489+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T11:56:04.570+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T11:56:04.571+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T11:56:04.780+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T11:56:04.782+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T11:56:04.783+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T11:56:04.783+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T11:56:04.992+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T11:56:04.992+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T11:56:05.146+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T11:56:05.147+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T11:56:05.147+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T11:56:05.729+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T11:56:05.810+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T11:56:05.811+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T11:56:05.812+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T11:56:05.812+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T11:56:05.820+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T115604, end_date=20240618T115605
[2024-06-18T11:56:05.850+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T11:56:05.865+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T11:56:05.866+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:53:09.798+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:53:09.831+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:53:09.844+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:53:09.844+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:53:09.860+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:53:09.868+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=611) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:53:09.869+0000] {standard_task_runner.py:63} INFO - Started process 630 to run task
[2024-06-18T12:53:09.870+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp50w86wgs']
[2024-06-18T12:53:09.873+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask fetch_and_publish_freePractice
[2024-06-18T12:53:09.918+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 29634c3e6318
[2024-06-18T12:53:10.055+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:53:10.056+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:53:10.221+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T12:53:10.223+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:53:10.223+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:53:10.224+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:53:10.538+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:53:10.538+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:53:10.692+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:53:10.693+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:53:10.693+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:53:11.382+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T12:53:11.472+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:53:11.473+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T12:53:11.473+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:53:11.473+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:53:11.481+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T125309, end_date=20240618T125311
[2024-06-18T12:53:11.527+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:53:11.548+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:53:11.550+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:18:41.232+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:18:41.250+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:18:41.256+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:18:41.256+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:18:41.264+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:18:41.268+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=645) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:18:41.269+0000] {standard_task_runner.py:63} INFO - Started process 670 to run task
[2024-06-18T13:18:41.269+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp18mt7u0q']
[2024-06-18T13:18:41.271+0000] {standard_task_runner.py:91} INFO - Job 42: Subtask fetch_and_publish_freePractice
[2024-06-18T13:18:41.303+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 642827d53473
[2024-06-18T13:18:41.356+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:18:41.356+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:18:41.492+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T13:18:41.494+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:18:41.494+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:18:41.495+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:18:41.597+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:18:41.597+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:18:41.600+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T13:18:41.601+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:18:41.601+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:18:41.602+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:18:41.606+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:18:41.606+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T13:18:41.606+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:18:41.607+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:18:41.614+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T131841, end_date=20240618T131841
[2024-06-18T13:18:41.643+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:18:41.653+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:18:41.655+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:28:49.860+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:28:49.880+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:28:49.887+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:28:49.888+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:28:49.897+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:28:49.902+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=604) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:28:49.903+0000] {standard_task_runner.py:63} INFO - Started process 634 to run task
[2024-06-18T13:28:49.903+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmp1h7wnyz7']
[2024-06-18T13:28:49.905+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask fetch_and_publish_freePractice
[2024-06-18T13:28:49.942+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host 9ae4be1c5479
[2024-06-18T13:28:50.017+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:28:50.018+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:28:50.152+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T13:28:50.154+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:28:50.154+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:28:50.155+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:28:50.258+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:28:50.258+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:28:50.262+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T13:28:50.263+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:28:50.264+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:28:50.264+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:28:50.270+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:28:50.271+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T13:28:50.271+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:28:50.271+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:28:50.281+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T132849, end_date=20240618T132850
[2024-06-18T13:28:50.317+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:28:50.330+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:28:50.331+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:58:00.049+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:58:00.072+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:58:00.081+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:58:00.081+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:58:00.091+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:58:00.097+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=627) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:58:00.099+0000] {standard_task_runner.py:63} INFO - Started process 648 to run task
[2024-06-18T13:58:00.099+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpsc1uu9cv']
[2024-06-18T13:58:00.101+0000] {standard_task_runner.py:91} INFO - Job 36: Subtask fetch_and_publish_freePractice
[2024-06-18T13:58:00.141+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host a16dbee39cfe
[2024-06-18T13:58:00.210+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:58:00.211+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:58:00.460+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T13:58:00.462+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T13:58:00.462+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:58:00.463+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T13:58:00.599+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:58:00.600+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:58:00.753+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T13:58:00.753+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T13:58:00.754+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:58:01.041+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T13:58:01.077+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:58:01.078+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T13:58:01.078+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:58:01.078+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:58:01.085+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T135800, end_date=20240618T135801
[2024-06-18T13:58:01.114+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:58:01.125+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:58:01.127+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:07:35.746+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:07:35.770+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:07:35.780+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:07:35.780+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:07:35.800+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): fetch_and_publish_freePractice> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:07:35.806+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=613) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:07:35.808+0000] {standard_task_runner.py:63} INFO - Started process 634 to run task
[2024-06-18T14:07:35.808+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_fetchAndPublish', 'fetch_and_publish_freePractice', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_fetch_and_publish.py', '--cfg-path', '/tmp/tmpbr_x_0ez']
[2024-06-18T14:07:35.810+0000] {standard_task_runner.py:91} INFO - Job 35: Subtask fetch_and_publish_freePractice
[2024-06-18T14:07:35.859+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_fetchAndPublish.fetch_and_publish_freePractice scheduled__2024-06-17T00:00:00+00:00 [running]> on host f083cbcc503e
[2024-06-18T14:07:35.936+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_fetchAndPublish' AIRFLOW_CTX_TASK_ID='fetch_and_publish_freePractice' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:07:35.937+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:07:36.069+0000] {logging_mixin.py:188} INFO - tried to find producer
[2024-06-18T14:07:36.071+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:07:36.071+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T14:07:36.071+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:07:36.244+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T14:07:36.244+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T14:07:36.398+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:07:36.398+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:07:36.398+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:07:36.945+0000] {kafka.py:486} INFO - Closing the Kafka producer with 9223372036.0 secs timeout.
[2024-06-18T14:07:37.014+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:07:37.014+0000] {logging_mixin.py:188} INFO - Total number of free practice sessions fetched: 66
[2024-06-18T14:07:37.015+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T14:07:37.015+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:07:37.023+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_fetchAndPublish, task_id=fetch_and_publish_freePractice, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T140735, end_date=20240618T140737
[2024-06-18T14:07:37.064+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T14:07:37.077+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:07:37.079+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
