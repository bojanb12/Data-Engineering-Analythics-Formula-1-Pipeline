[2024-06-14T07:29:47.813+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T07:29:47.950+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T07:29:47.956+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T07:29:47.956+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T07:29:47.965+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T07:29:47.971+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=895) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T07:29:47.972+0000] {standard_task_runner.py:63} INFO - Started process 905 to run task
[2024-06-14T07:29:47.972+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpj85m4t2p']
[2024-06-14T07:29:47.974+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-14T07:29:48.007+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host aece75d0a06d
[2024-06-14T07:29:48.112+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T07:29:48.112+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T07:29:48.113+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T07:29:48.114+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T07:29:48.246+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T07:29:48.246+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T07:29:48.254+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T072947, end_date=20240614T072948
[2024-06-14T07:29:48.306+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T07:29:48.323+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T07:29:48.324+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T07:56:22.599+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T07:56:22.746+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T07:56:22.753+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T07:56:22.753+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T07:56:22.762+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T07:56:22.768+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=475) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T07:56:22.769+0000] {standard_task_runner.py:63} INFO - Started process 485 to run task
[2024-06-14T07:56:22.769+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp42epdmrx']
[2024-06-14T07:56:22.771+0000] {standard_task_runner.py:91} INFO - Job 23: Subtask load_pitStops_task
[2024-06-14T07:56:22.808+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 22673327f9c1
[2024-06-14T07:56:22.940+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T07:56:22.941+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T07:56:22.942+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T07:56:22.942+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T07:56:23.117+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T07:56:23.118+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T07:56:23.126+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T075622, end_date=20240614T075623
[2024-06-14T07:56:23.143+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T07:56:23.162+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T07:56:23.163+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T08:05:11.919+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T08:05:11.939+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:05:11.948+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:05:11.949+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T08:05:11.962+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T08:05:11.969+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=501) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T08:05:11.971+0000] {standard_task_runner.py:63} INFO - Started process 512 to run task
[2024-06-14T08:05:11.970+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpummfi6ma']
[2024-06-14T08:05:11.972+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-14T08:05:12.022+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 75ebf4a056df
[2024-06-14T08:05:12.152+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T08:05:12.153+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T08:05:12.154+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T08:05:12.155+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T08:05:12.313+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T08:05:12.314+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T08:05:12.321+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T080511, end_date=20240614T080512
[2024-06-14T08:05:12.345+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T08:05:12.363+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T08:05:12.365+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T08:33:36.805+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T08:33:36.970+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:33:36.980+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:33:36.980+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T08:33:36.994+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T08:33:37.002+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=489) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T08:33:37.003+0000] {standard_task_runner.py:63} INFO - Started process 499 to run task
[2024-06-14T08:33:37.003+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmptsk4rayr']
[2024-06-14T08:33:37.006+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask load_pitStops_task
[2024-06-14T08:33:37.056+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 02396e2d7ca5
[2024-06-14T08:33:37.222+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T08:33:37.223+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T08:33:37.224+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T08:33:37.224+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T08:33:37.356+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T08:33:37.356+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T08:33:37.364+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T083336, end_date=20240614T083337
[2024-06-14T08:33:37.377+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T08:33:37.395+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T08:33:37.396+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T08:56:39.733+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T08:56:39.749+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:56:39.755+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T08:56:39.756+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T08:56:39.765+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T08:56:39.771+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=597) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T08:56:39.772+0000] {standard_task_runner.py:63} INFO - Started process 608 to run task
[2024-06-14T08:56:39.772+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8f5keqlc']
[2024-06-14T08:56:39.774+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-14T08:56:39.811+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 78c0b56418d0
[2024-06-14T08:56:39.920+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T08:56:39.921+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T08:56:39.923+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T08:56:39.923+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T08:56:40.060+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T08:56:40.061+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T08:56:40.067+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T085639, end_date=20240614T085640
[2024-06-14T08:56:40.106+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T08:56:40.122+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T08:56:40.124+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T09:05:29.188+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T09:05:29.336+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T09:05:29.343+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T09:05:29.343+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T09:05:29.354+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T09:05:29.359+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=496) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T09:05:29.361+0000] {standard_task_runner.py:63} INFO - Started process 524 to run task
[2024-06-14T09:05:29.361+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmplgb2pz4c']
[2024-06-14T09:05:29.363+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask load_pitStops_task
[2024-06-14T09:05:29.402+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 2998375d03a6
[2024-06-14T09:05:29.516+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T09:05:29.518+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T09:05:29.519+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T09:05:29.519+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T09:05:29.682+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T09:05:29.683+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T09:05:29.693+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T090529, end_date=20240614T090529
[2024-06-14T09:05:29.735+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T09:05:29.751+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T09:05:29.753+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T09:27:32.829+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T09:27:32.845+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T09:27:32.852+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T09:27:32.852+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T09:27:32.869+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T09:27:32.875+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=504) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T09:27:32.876+0000] {standard_task_runner.py:63} INFO - Started process 514 to run task
[2024-06-14T09:27:32.877+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpwio9d54v']
[2024-06-14T09:27:32.879+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-14T09:27:32.919+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 05f8e2de7bcc
[2024-06-14T09:27:33.044+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T09:27:33.045+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T09:27:33.046+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T09:27:33.047+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T09:27:33.230+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T09:27:33.230+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T09:27:33.238+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T092732, end_date=20240614T092733
[2024-06-14T09:27:33.291+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T09:27:33.313+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T09:27:33.314+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T10:52:07.292+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T10:52:07.310+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T10:52:07.317+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T10:52:07.317+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T10:52:07.327+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T10:52:07.334+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=572) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T10:52:07.335+0000] {standard_task_runner.py:63} INFO - Started process 582 to run task
[2024-06-14T10:52:07.336+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp3217eydi']
[2024-06-14T10:52:07.337+0000] {standard_task_runner.py:91} INFO - Job 30: Subtask load_pitStops_task
[2024-06-14T10:52:07.377+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host e391edf20c31
[2024-06-14T10:52:07.496+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T10:52:07.497+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T10:52:07.498+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T10:52:07.498+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T10:52:07.649+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T10:52:07.650+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T10:52:07.657+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T105207, end_date=20240614T105207
[2024-06-14T10:52:07.709+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T10:52:07.726+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T10:52:07.728+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T10:55:51.368+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T10:55:51.386+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T10:55:51.393+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T10:55:51.393+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T10:55:51.403+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T10:55:51.409+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=476) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T10:55:51.410+0000] {standard_task_runner.py:63} INFO - Started process 486 to run task
[2024-06-14T10:55:51.411+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpewir95ib']
[2024-06-14T10:55:51.412+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-14T10:55:51.455+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host c9e393690dc3
[2024-06-14T10:55:51.571+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T10:55:51.572+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T10:55:51.573+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T10:55:51.574+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T10:55:51.711+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T10:55:51.711+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T10:55:51.718+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T105551, end_date=20240614T105551
[2024-06-14T10:55:51.744+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T10:55:51.761+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T10:55:51.763+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:03:56.913+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:03:56.931+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:03:56.937+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:03:56.937+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:03:56.950+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:03:56.957+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=513) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:03:56.958+0000] {standard_task_runner.py:63} INFO - Started process 523 to run task
[2024-06-14T11:03:56.958+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp829m_dyc']
[2024-06-14T11:03:56.960+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-14T11:03:57.010+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host cfca011b7e89
[2024-06-14T11:03:57.143+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:03:57.144+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:03:57.145+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:03:57.146+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:03:57.297+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:03:57.298+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:03:57.306+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T110356, end_date=20240614T110357
[2024-06-14T11:03:57.332+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:03:57.349+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:03:57.351+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:08:27.025+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:08:27.044+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:08:27.051+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:08:27.051+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:08:27.063+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:08:27.070+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=486) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:08:27.071+0000] {standard_task_runner.py:63} INFO - Started process 497 to run task
[2024-06-14T11:08:27.071+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '27', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpddkifsx2']
[2024-06-14T11:08:27.073+0000] {standard_task_runner.py:91} INFO - Job 27: Subtask load_pitStops_task
[2024-06-14T11:08:27.113+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 6e52e947d844
[2024-06-14T11:08:27.239+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:08:27.241+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:08:27.242+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:08:27.243+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:08:27.422+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:08:27.423+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:08:27.431+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T110827, end_date=20240614T110827
[2024-06-14T11:08:27.485+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:08:27.504+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:08:27.505+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:16:02.526+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:16:02.544+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:16:02.552+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:16:02.552+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:16:02.564+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:16:02.570+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=506) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:16:02.572+0000] {standard_task_runner.py:63} INFO - Started process 516 to run task
[2024-06-14T11:16:02.572+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp_m_mpbvi']
[2024-06-14T11:16:02.574+0000] {standard_task_runner.py:91} INFO - Job 23: Subtask load_pitStops_task
[2024-06-14T11:16:02.615+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 82d779af27dd
[2024-06-14T11:16:02.757+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:16:02.758+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:16:02.760+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:16:02.760+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:16:02.923+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:16:02.924+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:16:02.932+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T111602, end_date=20240614T111602
[2024-06-14T11:16:02.986+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:16:03.004+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:16:03.005+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:21:24.010+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:21:24.039+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:21:24.053+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:21:24.054+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:21:24.075+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:21:24.084+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=506) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:21:24.085+0000] {standard_task_runner.py:63} INFO - Started process 517 to run task
[2024-06-14T11:21:24.086+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpg9kzcl1m']
[2024-06-14T11:21:24.088+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-14T11:21:24.144+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 385858123cc9
[2024-06-14T11:21:24.272+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:21:24.273+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:21:24.274+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:21:24.274+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:21:24.421+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:21:24.421+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:21:24.428+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T112124, end_date=20240614T112124
[2024-06-14T11:21:24.459+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:21:24.476+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:21:24.477+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:26:25.763+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:26:25.781+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:26:25.788+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:26:25.789+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:26:25.798+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:26:25.805+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=502) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:26:25.806+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-14T11:26:25.807+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpv39w41ad']
[2024-06-14T11:26:25.808+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_pitStops_task
[2024-06-14T11:26:25.846+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 3da481cb81cd
[2024-06-14T11:26:25.955+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:26:25.956+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:26:25.957+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:26:25.957+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:26:26.093+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:26:26.093+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:26:26.101+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T112625, end_date=20240614T112626
[2024-06-14T11:26:26.140+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:26:26.154+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:26:26.156+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:30:56.216+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:30:56.235+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:30:56.241+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:30:56.241+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:30:56.250+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:30:56.256+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=504) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:30:56.257+0000] {standard_task_runner.py:63} INFO - Started process 514 to run task
[2024-06-14T11:30:56.258+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '27', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprt4_zd0s']
[2024-06-14T11:30:56.260+0000] {standard_task_runner.py:91} INFO - Job 27: Subtask load_pitStops_task
[2024-06-14T11:30:56.298+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 397171faad63
[2024-06-14T11:30:56.408+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:30:56.409+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:30:56.410+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:30:56.411+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:30:56.542+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:30:56.543+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:30:56.550+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T113056, end_date=20240614T113056
[2024-06-14T11:30:56.591+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:30:56.605+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:30:56.606+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:35:36.666+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:35:36.683+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:35:36.690+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:35:36.691+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:35:36.702+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:35:36.709+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=504) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:35:36.710+0000] {standard_task_runner.py:63} INFO - Started process 515 to run task
[2024-06-14T11:35:36.711+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp5eerxkjr']
[2024-06-14T11:35:36.712+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-14T11:35:36.754+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host d0ca0375d865
[2024-06-14T11:35:36.871+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:35:36.872+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:35:36.873+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:35:36.873+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:35:37.050+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:35:37.050+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:35:37.057+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T113536, end_date=20240614T113537
[2024-06-14T11:35:37.084+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:35:37.101+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:35:37.102+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T11:42:55.875+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T11:42:55.893+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:42:55.899+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T11:42:55.899+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T11:42:55.908+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T11:42:55.915+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=511) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T11:42:55.916+0000] {standard_task_runner.py:63} INFO - Started process 521 to run task
[2024-06-14T11:42:55.917+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpcnpd4xui']
[2024-06-14T11:42:55.918+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-14T11:42:55.958+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host aae9b98b8a12
[2024-06-14T11:42:56.070+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T11:42:56.071+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T11:42:56.073+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T11:42:56.074+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T11:42:56.207+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T11:42:56.208+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T11:42:56.215+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T114255, end_date=20240614T114256
[2024-06-14T11:42:56.250+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T11:42:56.267+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T11:42:56.269+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T12:17:27.409+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T12:17:27.563+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T12:17:27.570+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T12:17:27.571+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T12:17:27.581+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T12:17:27.588+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=500) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T12:17:27.590+0000] {standard_task_runner.py:63} INFO - Started process 513 to run task
[2024-06-14T12:17:27.590+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpi2ggejs_']
[2024-06-14T12:17:27.592+0000] {standard_task_runner.py:91} INFO - Job 23: Subtask load_pitStops_task
[2024-06-14T12:17:27.631+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host e4ecbb11494f
[2024-06-14T12:17:27.751+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T12:17:27.752+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T12:17:27.753+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T12:17:27.753+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T12:17:27.900+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T12:17:27.900+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T12:17:27.908+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T121727, end_date=20240614T121727
[2024-06-14T12:17:27.924+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T12:17:27.942+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T12:17:27.943+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T12:44:58.922+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T12:44:58.947+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T12:44:58.954+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T12:44:58.954+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T12:44:58.964+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T12:44:58.970+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=500) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T12:44:58.972+0000] {standard_task_runner.py:63} INFO - Started process 510 to run task
[2024-06-14T12:44:58.972+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpg1rmpul_']
[2024-06-14T12:44:58.974+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-14T12:44:59.019+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 23fced7d152c
[2024-06-14T12:44:59.137+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T12:44:59.137+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T12:44:59.138+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T12:44:59.139+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T12:44:59.272+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T12:44:59.273+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T12:44:59.279+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T124458, end_date=20240614T124459
[2024-06-14T12:44:59.306+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T12:44:59.323+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T12:44:59.324+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T13:32:31.159+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T13:32:31.318+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T13:32:31.326+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T13:32:31.326+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T13:32:31.338+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T13:32:31.345+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=462) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T13:32:31.346+0000] {standard_task_runner.py:63} INFO - Started process 478 to run task
[2024-06-14T13:32:31.347+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpc5n3lmac']
[2024-06-14T13:32:31.348+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask load_pitStops_task
[2024-06-14T13:32:31.388+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 5a14b9f42b04
[2024-06-14T13:32:31.529+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T13:32:31.531+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T13:32:31.532+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T13:32:31.532+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T13:32:31.720+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T13:32:31.721+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T13:32:31.729+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T133231, end_date=20240614T133231
[2024-06-14T13:32:31.760+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T13:32:31.780+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T13:32:31.781+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-14T13:56:44.277+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T13:56:44.293+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T13:56:44.299+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [queued]>
[2024-06-14T13:56:44.299+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-14T13:56:44.311+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-13 00:00:00+00:00
[2024-06-14T13:56:44.318+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=493) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-14T13:56:44.319+0000] {standard_task_runner.py:63} INFO - Started process 505 to run task
[2024-06-14T13:56:44.319+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-13T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpugz1wx7a']
[2024-06-14T13:56:44.321+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-14T13:56:44.362+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-13T00:00:00+00:00 [running]> on host 32b182b24782
[2024-06-14T13:56:44.477+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-13T00:00:00+00:00'
[2024-06-14T13:56:44.478+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T13:56:44.479+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-14T13:56:44.480+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-14T13:56:44.618+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-14T13:56:44.619+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T13:56:44.626+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-13T00:00:00+00:00, execution_date=20240613T000000, start_date=20240614T135644, end_date=20240614T135644
[2024-06-14T13:56:44.653+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-14T13:56:44.669+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T13:56:44.671+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
