[2024-06-06T07:56:54.713+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T07:56:54.736+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T07:56:54.746+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T07:56:54.746+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T07:56:54.758+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T07:56:54.763+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=515) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T07:56:54.766+0000] {standard_task_runner.py:63} INFO - Started process 539 to run task
[2024-06-06T07:56:54.766+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp0p9txzev']
[2024-06-06T07:56:54.769+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask lapsDim_transform
[2024-06-06T07:56:54.823+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 08774e8514f7
[2024-06-06T07:56:56.899+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T07:56:56.901+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T07:56:57.028+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T07:56:57.041+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T07:56:57.362+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T075654, end_date=20240606T075657
[2024-06-06T07:56:57.406+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T07:56:57.423+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T07:56:57.424+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T08:56:40.327+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T08:56:40.347+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T08:56:40.355+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T08:56:40.355+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T08:56:40.366+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T08:56:40.373+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=95) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T08:56:40.374+0000] {standard_task_runner.py:63} INFO - Started process 109 to run task
[2024-06-06T08:56:40.374+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprxn7qc23']
[2024-06-06T08:56:40.376+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask lapsDim_transform
[2024-06-06T08:56:40.422+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 92fdeb90b6dc
[2024-06-06T08:56:42.686+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T08:56:42.687+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T08:56:42.861+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T08:56:42.881+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T08:56:43.267+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T085640, end_date=20240606T085643
[2024-06-06T08:56:43.327+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T08:56:43.347+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T08:56:43.349+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T09:16:46.774+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T09:16:46.794+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T09:16:46.805+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T09:16:46.805+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T09:16:46.819+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T09:16:46.825+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=110) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T09:16:46.827+0000] {standard_task_runner.py:63} INFO - Started process 129 to run task
[2024-06-06T09:16:46.828+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpz3n0t6so']
[2024-06-06T09:16:46.830+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask lapsDim_transform
[2024-06-06T09:16:46.884+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 51c6f3587312
[2024-06-06T09:16:49.243+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T09:16:49.245+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T09:16:49.408+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T09:16:49.422+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T09:16:49.775+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T091646, end_date=20240606T091649
[2024-06-06T09:16:49.826+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T09:16:49.846+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T09:16:49.847+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T09:36:04.731+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T09:36:04.749+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T09:36:04.759+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T09:36:04.759+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T09:36:04.772+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T09:36:04.777+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=93) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T09:36:04.778+0000] {standard_task_runner.py:63} INFO - Started process 114 to run task
[2024-06-06T09:36:04.778+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpibz8cfgb']
[2024-06-06T09:36:04.780+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask lapsDim_transform
[2024-06-06T09:36:04.825+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 65a3ac1acc01
[2024-06-06T09:36:06.826+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T09:36:06.829+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T09:36:07.045+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T09:36:07.066+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T09:36:07.436+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T093604, end_date=20240606T093607
[2024-06-06T09:36:07.507+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T09:36:07.530+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T09:36:07.532+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T12:13:38.334+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T12:13:38.354+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:13:38.363+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:13:38.363+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T12:13:38.378+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T12:13:38.385+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=103) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T12:13:38.387+0000] {standard_task_runner.py:63} INFO - Started process 119 to run task
[2024-06-06T12:13:38.387+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpi71hvzb2']
[2024-06-06T12:13:38.389+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask lapsDim_transform
[2024-06-06T12:13:38.438+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 67c96aeea7c1
[2024-06-06T12:13:40.718+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T12:13:40.720+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T12:13:40.891+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T12:13:40.906+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T12:13:41.277+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T121338, end_date=20240606T121341
[2024-06-06T12:13:41.339+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T12:13:41.361+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T12:13:41.362+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T12:18:54.458+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T12:18:54.483+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:18:54.494+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:18:54.494+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T12:18:54.507+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T12:18:54.514+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=114) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T12:18:54.515+0000] {standard_task_runner.py:63} INFO - Started process 132 to run task
[2024-06-06T12:18:54.516+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmplzkh0iex']
[2024-06-06T12:18:54.517+0000] {standard_task_runner.py:91} INFO - Job 9: Subtask lapsDim_transform
[2024-06-06T12:18:54.574+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 4f215e9dab06
[2024-06-06T12:18:56.970+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T12:18:56.972+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T12:18:57.126+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T12:18:57.144+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T12:18:57.506+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T121854, end_date=20240606T121857
[2024-06-06T12:18:57.584+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T12:18:57.602+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T12:18:57.604+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T12:23:16.653+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T12:23:16.684+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:23:16.692+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:23:16.692+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T12:23:16.702+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T12:23:16.707+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=95) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T12:23:16.709+0000] {standard_task_runner.py:63} INFO - Started process 111 to run task
[2024-06-06T12:23:16.709+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpq_3lr5xb']
[2024-06-06T12:23:16.711+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask lapsDim_transform
[2024-06-06T12:23:16.754+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 7679c901c0ae
[2024-06-06T12:23:18.887+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T12:23:18.890+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T12:23:19.081+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T12:23:19.102+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T12:23:19.533+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T122316, end_date=20240606T122319
[2024-06-06T12:23:19.564+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T12:23:19.586+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T12:23:19.587+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T12:28:53.103+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T12:28:53.126+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:28:53.135+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T12:28:53.135+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T12:28:53.146+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T12:28:53.153+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=98) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T12:28:53.154+0000] {standard_task_runner.py:63} INFO - Started process 118 to run task
[2024-06-06T12:28:53.154+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpbslm04h6']
[2024-06-06T12:28:53.156+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask lapsDim_transform
[2024-06-06T12:28:53.199+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host a23e7e40387a
[2024-06-06T12:28:55.436+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T12:28:55.438+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T12:28:55.586+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T12:28:55.600+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T12:28:55.955+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T122853, end_date=20240606T122855
[2024-06-06T12:28:55.993+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T12:28:56.012+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T12:28:56.013+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T13:06:21.500+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T13:06:21.519+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T13:06:21.526+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T13:06:21.526+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T13:06:21.540+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T13:06:21.545+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=228) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T13:06:21.547+0000] {standard_task_runner.py:63} INFO - Started process 244 to run task
[2024-06-06T13:06:21.548+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpezlqzirg']
[2024-06-06T13:06:21.549+0000] {standard_task_runner.py:91} INFO - Job 8: Subtask lapsDim_transform
[2024-06-06T13:06:21.590+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 96c3a9a38613
[2024-06-06T13:06:23.790+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T13:06:23.792+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T13:06:23.930+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T13:06:23.944+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T13:06:24.283+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T130621, end_date=20240606T130624
[2024-06-06T13:06:24.323+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T13:06:24.341+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T13:06:24.343+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T14:23:33.257+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T14:23:33.278+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T14:23:33.285+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T14:23:33.286+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T14:23:33.298+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T14:23:33.304+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=115) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T14:23:33.305+0000] {standard_task_runner.py:63} INFO - Started process 136 to run task
[2024-06-06T14:23:33.306+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpgyqhkqt3']
[2024-06-06T14:23:33.308+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask lapsDim_transform
[2024-06-06T14:23:33.352+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host a10f77dd72b8
[2024-06-06T14:23:35.366+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T14:23:35.369+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T14:23:35.521+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T14:23:35.543+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T14:23:35.879+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T142333, end_date=20240606T142335
[2024-06-06T14:23:35.928+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T14:23:35.946+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T14:23:35.947+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-06T14:27:36.955+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-06T14:27:36.972+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T14:27:36.980+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [queued]>
[2024-06-06T14:27:36.980+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-06T14:27:36.992+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-05 00:00:00+00:00
[2024-06-06T14:27:36.999+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=93) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-06T14:27:37.000+0000] {standard_task_runner.py:63} INFO - Started process 114 to run task
[2024-06-06T14:27:37.000+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-05T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8luroojj']
[2024-06-06T14:27:37.002+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask lapsDim_transform
[2024-06-06T14:27:37.045+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-05T00:00:00+00:00 [running]> on host 3059d4e2f604
[2024-06-06T14:27:38.995+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-05T00:00:00+00:00'
[2024-06-06T14:27:38.998+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-06T14:27:39.154+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-06T14:27:39.167+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-06T14:27:39.533+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-05T00:00:00+00:00, execution_date=20240605T000000, start_date=20240606T142736, end_date=20240606T142739
[2024-06-06T14:27:39.603+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-06T14:27:39.628+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-06T14:27:39.630+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
