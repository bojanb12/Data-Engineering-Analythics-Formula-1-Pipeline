[2024-06-11T07:51:14.394+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-11T07:51:14.409+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T07:51:14.414+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T07:51:14.415+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-11T07:51:14.423+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-10 00:00:00+00:00
[2024-06-11T07:51:14.429+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=710) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-11T07:51:14.430+0000] {standard_task_runner.py:63} INFO - Started process 713 to run task
[2024-06-11T07:51:14.431+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-10T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp5nyjbngr']
[2024-06-11T07:51:14.432+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask sprint_transform
[2024-06-11T07:51:14.466+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [running]> on host 774afe459216
[2024-06-11T07:51:15.020+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-10T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-10T00:00:00+00:00'
[2024-06-11T07:51:15.021+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-11T07:51:15.049+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-11T07:51:15.056+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-11T07:51:15.083+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-10T00:00:00+00:00, execution_date=20240610T000000, start_date=20240611T075114, end_date=20240611T075115
[2024-06-11T07:51:15.126+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-11T07:51:15.134+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-11T09:15:37.917+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-11T09:15:37.933+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T09:15:37.939+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T09:15:37.940+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-11T09:15:37.949+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-10 00:00:00+00:00
[2024-06-11T09:15:37.954+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=569) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-11T09:15:37.955+0000] {standard_task_runner.py:63} INFO - Started process 598 to run task
[2024-06-11T09:15:37.956+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-10T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpccthi22_']
[2024-06-11T09:15:37.957+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask sprint_transform
[2024-06-11T09:15:37.992+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [running]> on host fdc9bf7b6fb8
[2024-06-11T09:15:38.577+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-10T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-10T00:00:00+00:00'
[2024-06-11T09:15:38.578+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-11T09:15:38.604+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-11T09:15:38.611+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-11T09:15:38.637+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-10T00:00:00+00:00, execution_date=20240610T000000, start_date=20240611T091537, end_date=20240611T091538
[2024-06-11T09:15:38.690+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-11T09:15:38.709+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-11T09:15:38.711+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-11T11:21:39.680+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-11T11:21:39.698+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T11:21:39.705+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T11:21:39.706+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-11T11:21:39.714+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-10 00:00:00+00:00
[2024-06-11T11:21:39.721+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=581) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-11T11:21:39.722+0000] {standard_task_runner.py:63} INFO - Started process 594 to run task
[2024-06-11T11:21:39.722+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-10T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpr7vvlknf']
[2024-06-11T11:21:39.724+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask sprint_transform
[2024-06-11T11:21:39.761+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [running]> on host bc9f1e77df41
[2024-06-11T11:21:40.351+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-10T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-10T00:00:00+00:00'
[2024-06-11T11:21:40.352+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-11T11:21:40.376+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-11T11:21:40.383+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-11T11:21:40.407+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-10T00:00:00+00:00, execution_date=20240610T000000, start_date=20240611T112139, end_date=20240611T112140
[2024-06-11T11:21:40.458+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-11T11:21:40.476+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-11T11:21:40.477+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-11T14:24:38.656+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-11T14:24:38.672+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T14:24:38.680+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [queued]>
[2024-06-11T14:24:38.681+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-11T14:24:38.694+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-10 00:00:00+00:00
[2024-06-11T14:24:38.701+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=665) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-11T14:24:38.703+0000] {standard_task_runner.py:63} INFO - Started process 669 to run task
[2024-06-11T14:24:38.703+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-10T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmppgygunvc']
[2024-06-11T14:24:38.705+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask sprint_transform
[2024-06-11T14:24:38.750+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-10T00:00:00+00:00 [running]> on host f99ae21f53ae
[2024-06-11T14:24:39.319+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-10T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-10T00:00:00+00:00'
[2024-06-11T14:24:39.320+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-11T14:24:39.342+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-11T14:24:39.350+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-11T14:24:39.374+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-10T00:00:00+00:00, execution_date=20240610T000000, start_date=20240611T142438, end_date=20240611T142439
[2024-06-11T14:24:39.397+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-11T14:24:39.417+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-11T14:24:39.419+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
