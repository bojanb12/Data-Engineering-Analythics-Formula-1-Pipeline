[2024-06-18T07:20:00.431+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T07:20:00.448+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:20:00.457+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:20:00.458+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T07:20:00.468+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T07:20:00.475+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=513) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T07:20:00.476+0000] {standard_task_runner.py:63} INFO - Started process 525 to run task
[2024-06-18T07:20:00.477+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmptuyxak8f']
[2024-06-18T07:20:00.478+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-18T07:20:00.516+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host ce62f6b650cd
[2024-06-18T07:20:00.626+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T07:20:00.627+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T07:20:00.628+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T07:20:00.628+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T07:20:00.765+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T07:20:00.765+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T07:20:00.772+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T072000, end_date=20240618T072000
[2024-06-18T07:20:00.810+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T07:20:00.827+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T07:20:00.828+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:12:09.879+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:12:09.897+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:12:09.905+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:12:09.906+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:12:09.915+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:12:09.922+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=507) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:12:09.924+0000] {standard_task_runner.py:63} INFO - Started process 520 to run task
[2024-06-18T08:12:09.923+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmppb2oueol']
[2024-06-18T08:12:09.925+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-18T08:12:09.962+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 0a8bae48237c
[2024-06-18T08:12:10.071+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:12:10.072+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:12:10.073+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:12:10.073+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:12:10.206+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:12:10.207+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:12:10.213+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T081209, end_date=20240618T081210
[2024-06-18T08:12:10.258+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:12:10.276+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:12:10.277+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:22:48.308+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:22:48.458+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:22:48.464+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:22:48.464+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:22:48.474+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:22:48.479+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=539) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:22:48.480+0000] {standard_task_runner.py:63} INFO - Started process 552 to run task
[2024-06-18T08:22:48.481+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpkj2p3nt3']
[2024-06-18T08:22:48.482+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-18T08:22:48.518+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 7d3c9e9f45b7
[2024-06-18T08:22:48.627+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:22:48.629+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:22:48.630+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:22:48.630+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:22:48.765+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:22:48.766+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:22:48.773+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T082248, end_date=20240618T082248
[2024-06-18T08:22:48.814+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:22:48.831+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:22:48.833+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:30:14.393+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:30:14.411+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:30:14.418+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:30:14.418+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:30:14.429+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:30:14.435+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=508) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:30:14.436+0000] {standard_task_runner.py:63} INFO - Started process 519 to run task
[2024-06-18T08:30:14.436+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '27', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmph1mib3rz']
[2024-06-18T08:30:14.438+0000] {standard_task_runner.py:91} INFO - Job 27: Subtask load_pitStops_task
[2024-06-18T08:30:14.481+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host d26fdf24870c
[2024-06-18T08:30:14.607+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:30:14.608+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:30:14.609+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:30:14.609+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:30:14.757+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:30:14.758+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:30:14.765+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T083014, end_date=20240618T083014
[2024-06-18T08:30:14.810+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:30:14.827+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:30:14.828+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:54:46.226+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:54:46.430+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:54:46.438+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:54:46.438+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:54:46.449+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:54:46.455+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=513) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:54:46.456+0000] {standard_task_runner.py:63} INFO - Started process 526 to run task
[2024-06-18T08:54:46.456+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpw66dylc5']
[2024-06-18T08:54:46.458+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-18T08:54:46.504+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 70dbe2d93c7b
[2024-06-18T08:54:46.631+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:54:46.633+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:54:46.634+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:54:46.634+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:54:46.796+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:54:46.797+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:54:46.807+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T085446, end_date=20240618T085446
[2024-06-18T08:54:46.830+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:54:46.848+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:54:46.850+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:58:19.634+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:58:19.650+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:58:19.657+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:58:19.658+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:58:19.668+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:58:19.674+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=483) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:58:19.675+0000] {standard_task_runner.py:63} INFO - Started process 495 to run task
[2024-06-18T08:58:19.676+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpq2f1bcfe']
[2024-06-18T08:58:19.677+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-18T08:58:19.716+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 85d13f87db98
[2024-06-18T08:58:19.836+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:58:19.837+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:58:19.838+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:58:19.838+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:58:20.018+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:58:20.018+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:58:20.026+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T085819, end_date=20240618T085820
[2024-06-18T08:58:20.050+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:58:20.070+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:58:20.071+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T11:55:42.356+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T11:55:42.379+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:55:42.387+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:55:42.388+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T11:55:42.397+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T11:55:42.402+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=487) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T11:55:42.403+0000] {standard_task_runner.py:63} INFO - Started process 499 to run task
[2024-06-18T11:55:42.404+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprgjtq87l']
[2024-06-18T11:55:42.405+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-18T11:55:42.447+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T11:55:42.559+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T11:55:42.559+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T11:55:42.560+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T11:55:42.561+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T11:55:42.738+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T11:55:42.739+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T11:55:42.746+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T115542, end_date=20240618T115542
[2024-06-18T11:55:42.777+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T11:55:42.794+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T11:55:42.795+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:52:48.252+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:52:48.270+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:52:48.276+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:52:48.277+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:52:48.286+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:52:48.292+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=496) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:52:48.293+0000] {standard_task_runner.py:63} INFO - Started process 503 to run task
[2024-06-18T12:52:48.294+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpxg6ur1i1']
[2024-06-18T12:52:48.295+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask load_pitStops_task
[2024-06-18T12:52:48.339+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 29634c3e6318
[2024-06-18T12:52:48.506+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:52:48.507+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:52:48.509+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:52:48.509+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:52:48.705+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:52:48.706+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:52:48.713+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T125248, end_date=20240618T125248
[2024-06-18T12:52:48.750+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:52:48.767+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:52:48.768+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:18:17.369+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:18:17.386+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:18:17.396+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:18:17.396+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:18:17.406+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:18:17.413+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=515) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:18:17.415+0000] {standard_task_runner.py:63} INFO - Started process 530 to run task
[2024-06-18T13:18:17.415+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '27', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpcab13ftz']
[2024-06-18T13:18:17.416+0000] {standard_task_runner.py:91} INFO - Job 27: Subtask load_pitStops_task
[2024-06-18T13:18:17.456+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 642827d53473
[2024-06-18T13:18:17.584+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:18:17.584+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:18:17.586+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:18:17.586+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:18:17.769+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:18:17.770+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:18:17.778+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T131817, end_date=20240618T131817
[2024-06-18T13:18:17.829+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:18:17.849+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:18:17.851+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:28:28.344+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:28:28.364+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:28:28.374+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:28:28.375+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:28:28.388+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:28:28.397+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=512) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:28:28.398+0000] {standard_task_runner.py:63} INFO - Started process 521 to run task
[2024-06-18T13:28:28.398+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8b4exe8b']
[2024-06-18T13:28:28.400+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-18T13:28:28.450+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host 9ae4be1c5479
[2024-06-18T13:28:28.588+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:28:28.589+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:28:28.590+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:28:28.591+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:28:28.734+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:28:28.735+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:28:28.742+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T132828, end_date=20240618T132828
[2024-06-18T13:28:28.772+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:28:28.790+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:28:28.791+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:57:40.876+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:57:40.894+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:57:40.901+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:57:40.901+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:57:40.911+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:57:40.917+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=538) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:57:40.919+0000] {standard_task_runner.py:63} INFO - Started process 551 to run task
[2024-06-18T13:57:40.919+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp3t3j4b_y']
[2024-06-18T13:57:40.920+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-18T13:57:40.959+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host a16dbee39cfe
[2024-06-18T13:57:41.076+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:57:41.077+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:57:41.078+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:57:41.078+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:57:41.216+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:57:41.217+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:57:41.224+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T135740, end_date=20240618T135741
[2024-06-18T13:57:41.252+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:57:41.268+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:57:41.270+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:07:13.390+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:07:13.408+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:07:13.414+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:07:13.415+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:07:13.424+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:07:13.430+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=496) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:07:13.431+0000] {standard_task_runner.py:63} INFO - Started process 507 to run task
[2024-06-18T14:07:13.432+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpm7realc5']
[2024-06-18T14:07:13.433+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-18T14:07:13.474+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-17T00:00:00+00:00 [running]> on host f083cbcc503e
[2024-06-18T14:07:13.601+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:07:13.602+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:07:13.603+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T14:07:13.604+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T14:07:13.793+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T14:07:13.794+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:07:13.802+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T140713, end_date=20240618T140713
[2024-06-18T14:07:13.845+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T14:07:13.864+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:07:13.865+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
