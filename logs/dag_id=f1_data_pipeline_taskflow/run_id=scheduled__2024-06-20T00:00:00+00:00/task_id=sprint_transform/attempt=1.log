[2024-06-21T07:37:00.897+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-21T07:37:00.910+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-20T00:00:00+00:00 [queued]>
[2024-06-21T07:37:00.915+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-20T00:00:00+00:00 [queued]>
[2024-06-21T07:37:00.916+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-21T07:37:00.924+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-20 00:00:00+00:00
[2024-06-21T07:37:00.930+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=467) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-21T07:37:00.930+0000] {standard_task_runner.py:63} INFO - Started process 471 to run task
[2024-06-21T07:37:00.931+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-20T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpz3x5wsbm']
[2024-06-21T07:37:00.933+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask sprint_transform
[2024-06-21T07:37:00.967+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-20T00:00:00+00:00 [running]> on host f9e8c8c49316
[2024-06-21T07:37:01.526+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-20T00:00:00+00:00'
[2024-06-21T07:37:01.527+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-21T07:37:01.558+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-21T07:37:01.564+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-21T07:37:01.593+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-20T00:00:00+00:00, execution_date=20240620T000000, start_date=20240621T073700, end_date=20240621T073701
[2024-06-21T07:37:01.625+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-21T07:37:01.646+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-21T07:37:01.648+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
