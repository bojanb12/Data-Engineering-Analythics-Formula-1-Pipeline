[2024-06-19T07:28:52.019+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T07:28:52.035+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T07:28:52.042+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T07:28:52.042+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T07:28:52.052+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T07:28:52.058+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=538) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T07:28:52.059+0000] {standard_task_runner.py:63} INFO - Started process 551 to run task
[2024-06-19T07:28:52.059+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpha2iv3y4']
[2024-06-19T07:28:52.061+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-19T07:28:52.098+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 5d5bc16a80d8
[2024-06-19T07:28:52.209+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T07:28:52.210+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T07:28:52.212+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T07:28:52.212+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T07:28:52.355+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T07:28:52.355+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T07:28:52.363+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T072852, end_date=20240619T072852
[2024-06-19T07:28:52.392+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T07:28:52.411+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T07:28:52.412+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T08:27:12.609+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T08:27:12.625+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:27:12.631+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:27:12.631+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T08:27:12.646+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T08:27:12.653+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=510) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T08:27:12.654+0000] {standard_task_runner.py:63} INFO - Started process 522 to run task
[2024-06-19T08:27:12.654+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpai8xk9o1']
[2024-06-19T08:27:12.655+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-19T08:27:12.695+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host d64590577fb7
[2024-06-19T08:27:12.811+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T08:27:12.812+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T08:27:12.813+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T08:27:12.814+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T08:27:12.949+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T08:27:12.950+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T08:27:12.957+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T082712, end_date=20240619T082712
[2024-06-19T08:27:12.987+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T08:27:13.012+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T08:27:13.013+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T08:54:21.446+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T08:54:21.463+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:54:21.469+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T08:54:21.470+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T08:54:21.478+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T08:54:21.484+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=512) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T08:54:21.485+0000] {standard_task_runner.py:63} INFO - Started process 557 to run task
[2024-06-19T08:54:21.485+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpkusmn81i']
[2024-06-19T08:54:21.487+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_pitStops_task
[2024-06-19T08:54:21.523+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host e5c8778eab06
[2024-06-19T08:54:21.626+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T08:54:21.627+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T08:54:21.628+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T08:54:21.629+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T08:54:21.762+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T08:54:21.762+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T08:54:21.770+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T085421, end_date=20240619T085421
[2024-06-19T08:54:21.818+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T08:54:21.836+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T08:54:21.837+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:05:38.830+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:05:38.846+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:05:38.853+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:05:38.853+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:05:38.862+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:05:38.868+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=526) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:05:38.869+0000] {standard_task_runner.py:63} INFO - Started process 537 to run task
[2024-06-19T12:05:38.870+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp_9wy2w2j']
[2024-06-19T12:05:38.872+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-19T12:05:38.909+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host eef124934bf8
[2024-06-19T12:05:39.026+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:05:39.027+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:05:39.029+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T12:05:39.029+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T12:05:39.166+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:05:39.167+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:05:39.173+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T120538, end_date=20240619T120539
[2024-06-19T12:05:39.203+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:05:39.220+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:05:39.221+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:36:52.453+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:36:52.468+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:36:52.473+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:36:52.474+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:36:52.483+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:36:52.489+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=557) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:36:52.490+0000] {standard_task_runner.py:63} INFO - Started process 592 to run task
[2024-06-19T12:36:52.490+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmps27xgms9']
[2024-06-19T12:36:52.492+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_pitStops_task
[2024-06-19T12:36:52.527+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 3a98e934d90a
[2024-06-19T12:36:52.635+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:36:52.636+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:36:52.637+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T12:36:52.638+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T12:36:52.774+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:36:52.775+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:36:52.783+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T123652, end_date=20240619T123652
[2024-06-19T12:36:52.823+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:36:52.841+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:36:52.843+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T12:53:19.582+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T12:53:19.598+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:53:19.606+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T12:53:19.606+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T12:53:19.617+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T12:53:19.624+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=489) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T12:53:19.625+0000] {standard_task_runner.py:63} INFO - Started process 499 to run task
[2024-06-19T12:53:19.626+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmphvqsmnwj']
[2024-06-19T12:53:19.627+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-19T12:53:19.668+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 9426bfe013d2
[2024-06-19T12:53:19.790+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T12:53:19.791+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T12:53:19.792+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T12:53:19.792+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T12:53:19.979+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T12:53:19.979+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T12:53:19.987+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T125319, end_date=20240619T125319
[2024-06-19T12:53:20.039+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T12:53:20.058+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T12:53:20.060+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:03:20.503+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:03:20.521+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:03:20.528+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:03:20.528+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:03:20.538+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:03:20.546+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=513) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:03:20.547+0000] {standard_task_runner.py:63} INFO - Started process 523 to run task
[2024-06-19T13:03:20.548+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpc2hhevpx']
[2024-06-19T13:03:20.550+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask load_pitStops_task
[2024-06-19T13:03:20.593+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 6fa64189ef34
[2024-06-19T13:03:20.708+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:03:20.709+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:03:20.710+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T13:03:20.710+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T13:03:20.867+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:03:20.867+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:03:20.876+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T130320, end_date=20240619T130320
[2024-06-19T13:03:20.921+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:03:20.939+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:03:20.940+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:17:04.652+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:17:04.669+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:17:04.676+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:17:04.676+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:17:04.686+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:17:04.692+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=487) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:17:04.693+0000] {standard_task_runner.py:63} INFO - Started process 498 to run task
[2024-06-19T13:17:04.693+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpa96hj2ql']
[2024-06-19T13:17:04.695+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask load_pitStops_task
[2024-06-19T13:17:04.736+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host d5b44298ec9f
[2024-06-19T13:17:04.864+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:17:04.866+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:17:04.867+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T13:17:04.868+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T13:17:05.066+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:17:05.066+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:17:05.075+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T131704, end_date=20240619T131705
[2024-06-19T13:17:05.107+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:17:05.127+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:17:05.129+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:27:33.356+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:27:33.374+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:27:33.381+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:27:33.381+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:27:33.396+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:27:33.403+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=483) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:27:33.403+0000] {standard_task_runner.py:63} INFO - Started process 496 to run task
[2024-06-19T13:27:33.404+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp24qystqb']
[2024-06-19T13:27:33.406+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-19T13:27:33.447+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host fc0cf0aa1225
[2024-06-19T13:27:33.574+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:27:33.575+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:27:33.576+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T13:27:33.576+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T13:27:33.755+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:27:33.756+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:27:33.764+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T132733, end_date=20240619T132733
[2024-06-19T13:27:33.818+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:27:33.839+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:27:33.841+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:37:44.399+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:37:44.417+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:37:44.424+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:37:44.424+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T13:37:44.434+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:37:44.441+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=512) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T13:37:44.442+0000] {standard_task_runner.py:63} INFO - Started process 520 to run task
[2024-06-19T13:37:44.445+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmppioqkni_']
[2024-06-19T13:37:44.447+0000] {standard_task_runner.py:91} INFO - Job 30: Subtask load_pitStops_task
[2024-06-19T13:37:44.491+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 790bccf90551
[2024-06-19T13:37:44.617+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:37:44.618+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:37:44.619+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T13:37:44.619+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T13:37:44.760+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T13:37:44.761+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:37:44.768+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T133744, end_date=20240619T133744
[2024-06-19T13:37:44.816+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:37:44.834+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:37:44.835+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:01:25.694+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:01:25.710+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:01:25.716+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:01:25.716+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:01:25.725+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:01:25.731+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=485) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:01:25.732+0000] {standard_task_runner.py:63} INFO - Started process 493 to run task
[2024-06-19T14:01:25.733+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp0pwjfq5g']
[2024-06-19T14:01:25.734+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_pitStops_task
[2024-06-19T14:01:25.771+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 0ff0d3189758
[2024-06-19T14:01:25.886+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:01:25.887+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:01:25.888+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T14:01:25.888+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T14:01:26.060+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:01:26.061+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:01:26.068+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T140125, end_date=20240619T140126
[2024-06-19T14:01:26.106+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:01:26.126+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:01:26.127+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:05:05.678+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:05:05.698+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:05:05.706+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:05:05.706+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:05:05.716+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:05:05.722+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=510) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:05:05.723+0000] {standard_task_runner.py:63} INFO - Started process 522 to run task
[2024-06-19T14:05:05.724+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '31', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp03sp561e']
[2024-06-19T14:05:05.725+0000] {standard_task_runner.py:91} INFO - Job 31: Subtask load_pitStops_task
[2024-06-19T14:05:05.767+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host dc92dd71b4a2
[2024-06-19T14:05:05.897+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:05:05.899+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:05:05.900+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T14:05:05.900+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T14:05:06.051+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:05:06.052+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:05:06.058+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T140505, end_date=20240619T140506
[2024-06-19T14:05:06.097+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:05:06.115+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:05:06.116+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:14:03.374+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:14:03.390+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:14:03.396+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:14:03.397+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:14:03.406+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:14:03.412+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=542) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:14:03.413+0000] {standard_task_runner.py:63} INFO - Started process 554 to run task
[2024-06-19T14:14:03.413+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpif9b7ecl']
[2024-06-19T14:14:03.415+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-19T14:14:03.451+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 2acd74b25e37
[2024-06-19T14:14:03.563+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:14:03.565+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:14:03.566+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T14:14:03.567+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T14:14:03.706+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:14:03.707+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:14:03.714+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T141403, end_date=20240619T141403
[2024-06-19T14:14:03.748+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:14:03.765+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:14:03.767+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T14:26:00.846+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T14:26:00.870+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:26:00.878+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T14:26:00.879+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-19T14:26:00.891+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_pitStops_task> on 2024-06-18 00:00:00+00:00
[2024-06-19T14:26:00.899+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=506) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-19T14:26:00.900+0000] {standard_task_runner.py:63} INFO - Started process 516 to run task
[2024-06-19T14:26:00.900+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_pitStops_task', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpfzb8sqb2']
[2024-06-19T14:26:00.902+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_pitStops_task
[2024-06-19T14:26:00.952+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_pitStops_task scheduled__2024-06-18T00:00:00+00:00 [running]> on host 7f714baf6013
[2024-06-19T14:26:01.078+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_pitStops_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T14:26:01.079+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T14:26:01.080+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-19T14:26:01.080+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-19T14:26:01.212+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T14:26:01.213+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T14:26:01.220+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_pitStops_task, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T142600, end_date=20240619T142601
[2024-06-19T14:26:01.234+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T14:26:01.252+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T14:26:01.253+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
