[2024-06-05T07:10:00.025+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T07:10:00.183+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T07:10:00.190+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T07:10:00.190+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T07:10:00.202+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T07:10:00.208+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=160) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T07:10:00.209+0000] {standard_task_runner.py:63} INFO - Started process 182 to run task
[2024-06-05T07:10:00.209+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp83u51p4x']
[2024-06-05T07:10:00.211+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask lapsDim_transform
[2024-06-05T07:10:00.262+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host add871a599c8
[2024-06-05T07:10:02.148+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T07:10:02.149+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T07:10:02.312+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T07:10:02.322+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T07:10:02.674+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T071000, end_date=20240605T071002
[2024-06-05T07:10:02.717+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T07:10:02.734+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T07:10:02.736+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T09:14:50.668+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T09:14:50.725+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T09:14:50.733+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T09:14:50.733+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T09:14:50.747+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T09:14:50.754+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=95) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T09:14:50.756+0000] {standard_task_runner.py:63} INFO - Started process 114 to run task
[2024-06-05T09:14:50.756+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpuo4_z63f']
[2024-06-05T09:14:50.758+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask lapsDim_transform
[2024-06-05T09:14:50.810+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host b40b31c0938c
[2024-06-05T09:14:54.203+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T09:14:54.207+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T09:14:54.343+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T09:14:54.358+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T09:14:54.739+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T091450, end_date=20240605T091454
[2024-06-05T09:14:54.792+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T09:14:54.833+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T09:14:54.835+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T09:57:20.166+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T09:57:20.187+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T09:57:20.194+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T09:57:20.195+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T09:57:20.206+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T09:57:20.211+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=100) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T09:57:20.212+0000] {standard_task_runner.py:63} INFO - Started process 116 to run task
[2024-06-05T09:57:20.212+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp44izvn9f']
[2024-06-05T09:57:20.214+0000] {standard_task_runner.py:91} INFO - Job 8: Subtask lapsDim_transform
[2024-06-05T09:57:20.260+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host 4404d6f11afd
[2024-06-05T09:57:22.476+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T09:57:22.478+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T09:57:22.608+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T09:57:22.623+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T09:57:22.974+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T095720, end_date=20240605T095722
[2024-06-05T09:57:23.019+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T09:57:23.038+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T09:57:23.039+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T10:05:46.511+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T10:05:46.533+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T10:05:46.541+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T10:05:46.542+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T10:05:46.555+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T10:05:46.561+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=157) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T10:05:46.562+0000] {standard_task_runner.py:63} INFO - Started process 180 to run task
[2024-06-05T10:05:46.563+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp4vxgplsx']
[2024-06-05T10:05:46.564+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask lapsDim_transform
[2024-06-05T10:05:46.613+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host c82c00099500
[2024-06-05T10:05:48.655+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T10:05:48.658+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T10:05:48.853+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T10:05:48.865+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T10:05:49.196+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T100546, end_date=20240605T100549
[2024-06-05T10:05:49.266+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T10:05:49.291+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T10:05:49.293+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T10:27:21.513+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T10:27:21.532+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T10:27:21.540+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T10:27:21.540+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T10:27:21.552+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T10:27:21.558+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=118) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T10:27:21.560+0000] {standard_task_runner.py:63} INFO - Started process 139 to run task
[2024-06-05T10:27:21.560+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpfc_v48no']
[2024-06-05T10:27:21.562+0000] {standard_task_runner.py:91} INFO - Job 9: Subtask lapsDim_transform
[2024-06-05T10:27:21.606+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host 6ad0dd8168be
[2024-06-05T10:27:23.491+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T10:27:23.492+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T10:27:23.662+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T10:27:23.674+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T10:27:24.039+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T102721, end_date=20240605T102724
[2024-06-05T10:27:24.087+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T10:27:24.105+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T10:27:24.106+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T12:24:22.050+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T12:24:22.075+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T12:24:22.084+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T12:24:22.084+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T12:24:22.095+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T12:24:22.100+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=172) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T12:24:22.101+0000] {standard_task_runner.py:63} INFO - Started process 199 to run task
[2024-06-05T12:24:22.102+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpc8x7bit5']
[2024-06-05T12:24:22.104+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask lapsDim_transform
[2024-06-05T12:24:22.149+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host f5493de6508e
[2024-06-05T12:24:24.492+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T12:24:24.493+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T12:24:24.657+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T12:24:24.677+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T12:24:25.062+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T122422, end_date=20240605T122425
[2024-06-05T12:24:25.126+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T12:24:25.148+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T12:24:25.150+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T13:55:30.590+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T13:55:30.609+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T13:55:30.616+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T13:55:30.616+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T13:55:30.628+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T13:55:30.634+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=93) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T13:55:30.635+0000] {standard_task_runner.py:63} INFO - Started process 112 to run task
[2024-06-05T13:55:30.636+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpxy616uua']
[2024-06-05T13:55:30.638+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask lapsDim_transform
[2024-06-05T13:55:30.683+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host 097d29da6aa2
[2024-06-05T13:55:32.971+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T13:55:32.973+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T13:55:33.142+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T13:55:33.160+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T13:55:33.544+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T135530, end_date=20240605T135533
[2024-06-05T13:55:33.591+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T13:55:33.617+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T13:55:33.619+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T14:24:40.594+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T14:24:40.614+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:24:40.621+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:24:40.622+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T14:24:40.635+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T14:24:40.640+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=101) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T14:24:40.642+0000] {standard_task_runner.py:63} INFO - Started process 117 to run task
[2024-06-05T14:24:40.642+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmptcw6p42_']
[2024-06-05T14:24:40.644+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask lapsDim_transform
[2024-06-05T14:24:40.693+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host 3da1f8dc12f1
[2024-06-05T14:24:43.395+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T14:24:43.417+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T14:24:43.587+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T14:24:43.600+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T14:24:44.003+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T142440, end_date=20240605T142444
[2024-06-05T14:24:44.075+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T14:24:44.256+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T14:24:44.263+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T14:27:42.318+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T14:27:42.341+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:27:42.351+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:27:42.351+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T14:27:42.364+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T14:27:42.370+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=96) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T14:27:42.372+0000] {standard_task_runner.py:63} INFO - Started process 118 to run task
[2024-06-05T14:27:42.372+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp1qd68bx9']
[2024-06-05T14:27:42.376+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask lapsDim_transform
[2024-06-05T14:27:42.426+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host d1c992285f47
[2024-06-05T14:27:44.639+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T14:27:44.641+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T14:27:44.821+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T14:27:44.834+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T14:27:45.217+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T142742, end_date=20240605T142745
[2024-06-05T14:27:45.299+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T14:27:45.330+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T14:27:45.332+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T14:34:44.927+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T14:34:45.096+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:34:45.105+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:34:45.106+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T14:34:45.121+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T14:34:45.127+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=98) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T14:34:45.129+0000] {standard_task_runner.py:63} INFO - Started process 115 to run task
[2024-06-05T14:34:45.129+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpofp7wkas']
[2024-06-05T14:34:45.133+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask lapsDim_transform
[2024-06-05T14:34:45.198+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host 0c159eaec4ac
[2024-06-05T14:34:47.508+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T14:34:47.511+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T14:34:47.708+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T14:34:47.721+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T14:34:48.079+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T143445, end_date=20240605T143448
[2024-06-05T14:34:48.129+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T14:34:48.153+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T14:34:48.157+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-05T14:42:54.560+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-05T14:42:54.766+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:42:54.774+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [queued]>
[2024-06-05T14:42:54.775+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-05T14:42:54.789+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): lapsDim_transform> on 2024-06-04 00:00:00+00:00
[2024-06-05T14:42:54.795+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=111) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-05T14:42:54.796+0000] {standard_task_runner.py:63} INFO - Started process 127 to run task
[2024-06-05T14:42:54.796+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'lapsDim_transform', 'scheduled__2024-06-04T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpexc4czcx']
[2024-06-05T14:42:54.798+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask lapsDim_transform
[2024-06-05T14:42:54.854+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.lapsDim_transform scheduled__2024-06-04T00:00:00+00:00 [running]> on host dc71de5e87bd
[2024-06-05T14:42:56.992+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='lapsDim_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-04T00:00:00+00:00'
[2024-06-05T14:42:56.999+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-05T14:42:57.212+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId  ...         milliseconds_laptimes position_laptimes
0          860        18  ... 1970-01-01 00:00:00.000099264                 1
2          860        18  ... 1970-01-01 00:00:00.000093414                 1
4          860        18  ... 1970-01-01 00:00:00.000093350                 1
6          860        18  ... 1970-01-01 00:00:00.000093131                 1
8          860        18  ... 1970-01-01 00:00:00.000092984                 1
...        ...       ...  ...                           ...               ...
518402     953       837  ... 1970-01-01 00:00:00.000079868                15
518405     953       837  ... 1970-01-01 00:00:00.000082086                15
518408     953       837  ... 1970-01-01 00:00:00.000088272                15
518411     953       837  ... 1970-01-01 00:00:00.000086970                15
518414     953       837  ... 1970-01-01 00:00:00.000084657                15

[256836 rows x 6 columns]
[2024-06-05T14:42:57.235+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-05T14:42:57.653+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=lapsDim_transform, run_id=scheduled__2024-06-04T00:00:00+00:00, execution_date=20240604T000000, start_date=20240605T144254, end_date=20240605T144257
[2024-06-05T14:42:57.695+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-05T14:42:57.715+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-05T14:42:57.716+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
