[2024-06-17T07:43:12.351+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T07:43:13.046+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:13.052+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:13.053+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T07:43:13.062+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T07:43:13.070+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=347) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T07:43:13.071+0000] {standard_task_runner.py:63} INFO - Started process 416 to run task
[2024-06-17T07:43:13.071+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpfmj3rob6']
[2024-06-17T07:43:13.073+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask load_constructor_task
[2024-06-17T07:43:13.111+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host c78fbdbb8669
[2024-06-17T07:43:13.223+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T07:43:13.225+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T07:43:13.227+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T07:43:13.227+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T07:43:13.244+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T07:43:13.245+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T07:43:13.253+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T074313, end_date=20240617T074313
[2024-06-17T07:43:13.284+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T07:43:13.298+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T07:43:13.300+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T08:17:49.167+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T08:17:49.186+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:17:49.194+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:17:49.195+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T08:17:49.205+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T08:17:49.212+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=325) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T08:17:49.213+0000] {standard_task_runner.py:63} INFO - Started process 348 to run task
[2024-06-17T08:17:49.214+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpqod1r4jf']
[2024-06-17T08:17:49.215+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T08:17:49.252+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 8b2116437c09
[2024-06-17T08:17:49.422+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T08:17:49.423+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T08:17:49.424+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T08:17:49.424+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T08:17:49.444+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T08:17:49.446+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T08:17:49.459+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T081749, end_date=20240617T081749
[2024-06-17T08:17:49.508+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T08:17:49.537+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T08:17:49.538+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:04:13.072+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:04:13.089+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:04:13.096+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:04:13.096+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:04:13.105+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:04:13.111+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=292) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:04:13.112+0000] {standard_task_runner.py:63} INFO - Started process 354 to run task
[2024-06-17T09:04:13.113+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpcea6jmak']
[2024-06-17T09:04:13.114+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask load_constructor_task
[2024-06-17T09:04:13.161+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host c4902b1065ce
[2024-06-17T09:04:13.302+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:04:13.303+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:04:13.304+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T09:04:13.304+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T09:04:13.318+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T09:04:13.319+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:04:13.326+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T090413, end_date=20240617T090413
[2024-06-17T09:04:13.366+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:04:13.382+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:04:13.383+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:25:54.426+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:25:54.441+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:25:54.447+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:25:54.447+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:25:54.455+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:25:54.461+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=305) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:25:54.461+0000] {standard_task_runner.py:63} INFO - Started process 352 to run task
[2024-06-17T09:25:54.462+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpsh21bjfa']
[2024-06-17T09:25:54.463+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T09:25:54.500+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host dbef0fd3372f
[2024-06-17T09:25:54.630+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:25:54.636+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:25:54.640+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T09:25:54.641+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T09:25:54.671+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T09:25:54.672+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:25:54.686+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T092554, end_date=20240617T092554
[2024-06-17T09:25:54.715+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:25:54.731+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:25:54.739+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:24:10.199+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:24:10.214+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:24:10.220+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:24:10.220+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:24:10.229+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:24:10.235+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=912) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:24:10.236+0000] {standard_task_runner.py:63} INFO - Started process 932 to run task
[2024-06-17T10:24:10.236+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp0k2ziwmq']
[2024-06-17T10:24:10.238+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_constructor_task
[2024-06-17T10:24:10.271+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host f37b7fb66c71
[2024-06-17T10:24:10.366+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:24:10.366+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:24:10.367+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T10:24:10.368+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T10:24:10.380+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T10:24:10.380+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:24:10.387+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T102410, end_date=20240617T102410
[2024-06-17T10:24:10.409+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:24:10.426+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:24:10.428+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:39:21.725+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:39:21.740+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:39:21.746+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:39:21.746+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:39:21.755+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:39:21.761+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=303) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:39:21.762+0000] {standard_task_runner.py:63} INFO - Started process 403 to run task
[2024-06-17T10:39:21.762+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpywoh7i56']
[2024-06-17T10:39:21.763+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-17T10:39:21.811+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 688ecc0cce5b
[2024-06-17T10:39:21.962+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:39:21.964+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:39:21.967+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T10:39:21.969+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T10:39:22.002+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T10:39:22.003+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:39:22.011+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T103921, end_date=20240617T103922
[2024-06-17T10:39:22.056+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:39:22.075+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:39:22.077+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T11:13:22.232+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T11:13:22.248+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:22.254+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:22.254+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T11:13:22.264+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T11:13:22.270+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=298) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T11:13:22.271+0000] {standard_task_runner.py:63} INFO - Started process 354 to run task
[2024-06-17T11:13:22.271+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmplxw0kvt3']
[2024-06-17T11:13:22.273+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T11:13:22.311+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 3a133740bf3d
[2024-06-17T11:13:22.412+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T11:13:22.413+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T11:13:22.414+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T11:13:22.415+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T11:13:22.433+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T11:13:22.434+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T11:13:22.441+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T111322, end_date=20240617T111322
[2024-06-17T11:13:22.484+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T11:13:22.499+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T11:13:22.500+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:23:52.232+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:23:52.249+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:23:52.256+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:23:52.256+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:23:52.266+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:23:52.273+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=298) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:23:52.274+0000] {standard_task_runner.py:63} INFO - Started process 373 to run task
[2024-06-17T12:23:52.274+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpuf85ejij']
[2024-06-17T12:23:52.276+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T12:23:52.312+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 5ef985758484
[2024-06-17T12:23:52.420+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:23:52.421+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:23:52.422+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T12:23:52.423+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T12:23:52.436+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:23:52.437+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:23:52.445+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T122352, end_date=20240617T122352
[2024-06-17T12:23:52.487+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:23:52.503+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:23:52.504+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:41:56.449+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:41:56.464+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:41:56.469+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:41:56.470+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:41:56.478+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:41:56.484+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=296) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:41:56.485+0000] {standard_task_runner.py:63} INFO - Started process 306 to run task
[2024-06-17T12:41:56.485+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmped8182s0']
[2024-06-17T12:41:56.487+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask load_constructor_task
[2024-06-17T12:41:56.522+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host c6f07e7c011e
[2024-06-17T12:41:56.646+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:41:56.647+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:41:56.648+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T12:41:56.648+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T12:41:56.682+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:41:56.683+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:41:56.694+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124156, end_date=20240617T124156
[2024-06-17T12:41:56.778+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:41:56.798+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:41:56.832+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:47:20.417+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:47:20.434+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:20.440+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:20.441+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:47:20.456+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:47:20.463+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=297) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:47:20.464+0000] {standard_task_runner.py:63} INFO - Started process 344 to run task
[2024-06-17T12:47:20.465+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpz1iboamh']
[2024-06-17T12:47:20.466+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T12:47:20.505+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 7b9616fbccae
[2024-06-17T12:47:20.662+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:47:20.663+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:47:20.664+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T12:47:20.664+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T12:47:20.680+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T12:47:20.681+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:47:20.689+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124720, end_date=20240617T124720
[2024-06-17T12:47:20.718+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:47:20.734+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:47:20.736+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:15:46.630+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:15:46.648+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:15:46.654+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:15:46.654+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:15:46.667+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:15:46.674+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=300) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:15:46.675+0000] {standard_task_runner.py:63} INFO - Started process 331 to run task
[2024-06-17T13:15:46.675+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpywpp9lvi']
[2024-06-17T13:15:46.677+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask load_constructor_task
[2024-06-17T13:15:46.713+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 32e484e314f3
[2024-06-17T13:15:46.820+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:15:46.821+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:15:46.822+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T13:15:46.823+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T13:15:46.852+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:15:46.853+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:15:46.861+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T131546, end_date=20240617T131546
[2024-06-17T13:15:46.888+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:15:46.903+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:15:46.905+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:26:01.732+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:26:02.403+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:26:02.410+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:26:02.410+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:26:02.418+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:26:02.425+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=297) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:26:02.426+0000] {standard_task_runner.py:63} INFO - Started process 322 to run task
[2024-06-17T13:26:02.427+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp0v9bt8m7']
[2024-06-17T13:26:02.429+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask load_constructor_task
[2024-06-17T13:26:02.466+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 96c07605841c
[2024-06-17T13:26:02.630+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:26:02.632+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:26:02.633+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T13:26:02.634+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T13:26:02.654+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:26:02.655+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:26:02.664+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T132602, end_date=20240617T132602
[2024-06-17T13:26:02.680+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:26:02.697+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:26:02.698+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:55:26.659+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:55:27.290+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:55:27.295+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:55:27.296+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:55:27.303+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:55:27.309+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=306) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:55:27.310+0000] {standard_task_runner.py:63} INFO - Started process 339 to run task
[2024-06-17T13:55:27.310+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpvconp4n6']
[2024-06-17T13:55:27.312+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask load_constructor_task
[2024-06-17T13:55:27.345+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host b1cdb958cbe8
[2024-06-17T13:55:27.443+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:55:27.444+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:55:27.444+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T13:55:27.445+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T13:55:27.459+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T13:55:27.460+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:55:27.466+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T135527, end_date=20240617T135527
[2024-06-17T13:55:27.483+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:55:27.497+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:55:27.498+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T14:14:31.844+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T14:14:31.859+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:31.865+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:31.865+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T14:14:31.876+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-17T14:14:31.883+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp7groa345']
[2024-06-17T14:14:31.885+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-17T14:14:31.887+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=309) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T14:14:31.888+0000] {standard_task_runner.py:63} INFO - Started process 317 to run task
[2024-06-17T14:14:31.925+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host ad2413a51065
[2024-06-17T14:14:32.083+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T14:14:32.084+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T14:14:32.085+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-17T14:14:32.085+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-17T14:14:32.115+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T14:14:32.116+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T14:14:32.124+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T141431, end_date=20240617T141432
[2024-06-17T14:14:32.141+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T14:14:32.167+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T14:14:32.169+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-24T07:21:47.493+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-24T07:21:47.516+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:21:47.524+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:21:47.525+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-24T07:21:47.548+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-16 00:00:00+00:00
[2024-06-24T07:21:47.555+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=306) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-24T07:21:47.556+0000] {standard_task_runner.py:63} INFO - Started process 338 to run task
[2024-06-24T07:21:47.556+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp3lqdoto4']
[2024-06-24T07:21:47.558+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask load_constructor_task
[2024-06-24T07:21:47.599+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-16T00:00:00+00:00 [running]> on host 4fefe0a35f4a
[2024-06-24T07:21:47.713+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-24T07:21:47.714+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-24T07:21:47.715+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-24T07:21:47.715+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-24T07:21:47.731+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-24T07:21:47.731+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-24T07:21:47.739+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240624T072147, end_date=20240624T072147
[2024-06-24T07:21:47.769+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-24T07:21:47.786+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-24T07:21:47.788+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
