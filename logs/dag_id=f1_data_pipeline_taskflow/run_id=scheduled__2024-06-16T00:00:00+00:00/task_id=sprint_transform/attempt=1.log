[2024-06-17T07:43:16.169+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T07:43:16.185+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:16.190+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T07:43:16.191+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T07:43:16.199+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T07:43:16.206+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=516) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T07:43:16.207+0000] {standard_task_runner.py:63} INFO - Started process 520 to run task
[2024-06-17T07:43:16.207+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp2s_n08_2']
[2024-06-17T07:43:16.209+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask sprint_transform
[2024-06-17T07:43:16.250+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host c78fbdbb8669
[2024-06-17T07:43:16.864+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T07:43:16.866+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T07:43:16.904+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T07:43:16.911+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T07:43:16.944+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T074316, end_date=20240617T074316
[2024-06-17T07:43:16.983+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T07:43:17.005+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T07:43:17.007+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T08:17:53.375+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T08:17:53.392+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:17:53.398+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T08:17:53.398+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T08:17:53.408+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T08:17:53.415+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=487) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T08:17:53.416+0000] {standard_task_runner.py:63} INFO - Started process 490 to run task
[2024-06-17T08:17:53.416+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpwlhl4csm']
[2024-06-17T08:17:53.418+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask sprint_transform
[2024-06-17T08:17:53.458+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 8b2116437c09
[2024-06-17T08:17:54.026+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T08:17:54.027+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T08:17:54.049+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T08:17:54.055+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T08:17:54.079+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T081753, end_date=20240617T081754
[2024-06-17T08:17:54.111+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T08:17:54.129+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T08:17:54.130+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:04:16.443+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:04:16.578+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:04:16.584+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:04:16.584+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:04:16.593+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:04:16.598+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=474) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:04:16.599+0000] {standard_task_runner.py:63} INFO - Started process 484 to run task
[2024-06-17T09:04:16.599+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpv733v4hj']
[2024-06-17T09:04:16.601+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask sprint_transform
[2024-06-17T09:04:16.634+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host c4902b1065ce
[2024-06-17T09:04:17.230+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:04:17.231+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:04:17.264+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T09:04:17.270+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:04:17.292+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T090416, end_date=20240617T090417
[2024-06-17T09:04:17.334+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:04:17.351+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:04:17.352+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T09:25:59.347+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T09:25:59.362+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:25:59.368+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T09:25:59.368+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T09:25:59.376+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T09:25:59.383+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=487) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T09:25:59.383+0000] {standard_task_runner.py:63} INFO - Started process 529 to run task
[2024-06-17T09:25:59.384+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '27', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpgldtym4u']
[2024-06-17T09:25:59.385+0000] {standard_task_runner.py:91} INFO - Job 27: Subtask sprint_transform
[2024-06-17T09:25:59.417+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host dbef0fd3372f
[2024-06-17T09:25:59.963+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T09:25:59.964+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T09:25:59.987+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T09:25:59.994+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T09:26:00.022+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T092559, end_date=20240617T092600
[2024-06-17T09:26:00.078+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T09:26:00.095+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T09:26:00.097+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:24:15.024+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:24:15.041+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:24:15.047+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:24:15.047+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:24:15.056+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:24:15.062+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1131) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:24:15.062+0000] {standard_task_runner.py:63} INFO - Started process 1134 to run task
[2024-06-17T10:24:15.063+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp9a70m0ud']
[2024-06-17T10:24:15.064+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask sprint_transform
[2024-06-17T10:24:15.101+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host f37b7fb66c71
[2024-06-17T10:24:15.693+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:24:15.694+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:24:15.717+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T10:24:15.724+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:24:15.747+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T102415, end_date=20240617T102415
[2024-06-17T10:24:15.797+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:24:15.815+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:24:15.816+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T10:39:23.886+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T10:39:23.905+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:39:23.913+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T10:39:23.913+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T10:39:23.922+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T10:39:23.928+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=454) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T10:39:23.929+0000] {standard_task_runner.py:63} INFO - Started process 466 to run task
[2024-06-17T10:39:23.929+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp5kicocc2']
[2024-06-17T10:39:23.931+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask sprint_transform
[2024-06-17T10:39:23.970+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 688ecc0cce5b
[2024-06-17T10:39:24.603+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T10:39:24.604+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T10:39:24.629+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T10:39:24.635+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T10:39:24.658+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T103923, end_date=20240617T103924
[2024-06-17T10:39:24.704+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T10:39:24.724+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T10:39:24.725+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T11:13:24.397+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T11:13:24.412+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:24.417+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T11:13:24.418+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T11:13:24.425+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T11:13:24.431+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=458) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T11:13:24.432+0000] {standard_task_runner.py:63} INFO - Started process 460 to run task
[2024-06-17T11:13:24.432+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp6b6dzc1u']
[2024-06-17T11:13:24.434+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask sprint_transform
[2024-06-17T11:13:24.467+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 3a133740bf3d
[2024-06-17T11:13:25.045+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T11:13:25.045+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T11:13:25.068+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T11:13:25.075+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T11:13:25.099+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T111324, end_date=20240617T111325
[2024-06-17T11:13:25.127+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T11:13:25.143+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T11:13:25.144+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:23:54.595+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:23:54.611+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:23:54.616+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:23:54.616+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:23:54.626+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:23:54.632+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=453) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:23:54.633+0000] {standard_task_runner.py:63} INFO - Started process 458 to run task
[2024-06-17T12:23:54.634+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpufawd42c']
[2024-06-17T12:23:54.636+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask sprint_transform
[2024-06-17T12:23:54.670+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 5ef985758484
[2024-06-17T12:23:55.248+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:23:55.248+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:23:55.276+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T12:23:55.283+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:23:55.308+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T122354, end_date=20240617T122355
[2024-06-17T12:23:55.328+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:23:55.347+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:23:55.349+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:42:01.185+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:42:01.206+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:42:01.215+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:42:01.215+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:42:01.227+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:42:01.236+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=465) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:42:01.238+0000] {standard_task_runner.py:63} INFO - Started process 469 to run task
[2024-06-17T12:42:01.238+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp0tts8bm1']
[2024-06-17T12:42:01.240+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask sprint_transform
[2024-06-17T12:42:01.288+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host c6f07e7c011e
[2024-06-17T12:42:01.888+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:42:01.889+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:42:01.915+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T12:42:01.920+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:42:01.943+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124201, end_date=20240617T124201
[2024-06-17T12:42:01.974+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:42:01.991+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:42:01.994+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T12:47:24.210+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T12:47:24.351+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:24.360+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T12:47:24.360+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T12:47:24.372+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T12:47:24.378+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=517) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T12:47:24.379+0000] {standard_task_runner.py:63} INFO - Started process 521 to run task
[2024-06-17T12:47:24.380+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpw0t96c0u']
[2024-06-17T12:47:24.382+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask sprint_transform
[2024-06-17T12:47:24.424+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 7b9616fbccae
[2024-06-17T12:47:24.997+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T12:47:24.998+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T12:47:25.025+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T12:47:25.030+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T12:47:25.054+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T124724, end_date=20240617T124725
[2024-06-17T12:47:25.075+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T12:47:25.092+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T12:47:25.093+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:15:48.773+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:15:48.788+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:15:48.794+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:15:48.794+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:15:48.802+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:15:48.808+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=460) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:15:48.808+0000] {standard_task_runner.py:63} INFO - Started process 462 to run task
[2024-06-17T13:15:48.809+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmppzyjkc9b']
[2024-06-17T13:15:48.810+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask sprint_transform
[2024-06-17T13:15:48.843+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 32e484e314f3
[2024-06-17T13:15:49.387+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:15:49.388+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:15:49.413+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T13:15:49.419+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:15:49.442+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T131548, end_date=20240617T131549
[2024-06-17T13:15:49.464+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:15:49.481+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:15:49.482+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:26:06.416+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:26:06.436+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:26:06.444+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:26:06.444+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:26:06.456+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:26:06.464+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=476) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:26:06.465+0000] {standard_task_runner.py:63} INFO - Started process 511 to run task
[2024-06-17T13:26:06.465+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpuzh6xr5f']
[2024-06-17T13:26:06.467+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask sprint_transform
[2024-06-17T13:26:06.512+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 96c07605841c
[2024-06-17T13:26:07.110+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:26:07.110+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:26:07.133+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T13:26:07.139+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:26:07.163+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T132606, end_date=20240617T132607
[2024-06-17T13:26:07.200+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:26:07.219+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:26:07.220+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T13:55:31.062+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T13:55:31.079+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:55:31.085+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T13:55:31.086+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T13:55:31.095+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T13:55:31.102+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=480) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T13:55:31.102+0000] {standard_task_runner.py:63} INFO - Started process 490 to run task
[2024-06-17T13:55:31.103+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpj4cryhd_']
[2024-06-17T13:55:31.104+0000] {standard_task_runner.py:91} INFO - Job 23: Subtask sprint_transform
[2024-06-17T13:55:31.141+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host b1cdb958cbe8
[2024-06-17T13:55:31.750+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T13:55:31.751+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T13:55:31.777+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T13:55:31.783+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T13:55:31.809+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T135531, end_date=20240617T135531
[2024-06-17T13:55:31.837+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T13:55:31.856+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T13:55:31.857+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T14:14:36.351+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T14:14:36.374+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:36.383+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-17T14:14:36.384+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-17T14:14:36.396+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-17T14:14:36.402+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=485) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-17T14:14:36.403+0000] {standard_task_runner.py:63} INFO - Started process 497 to run task
[2024-06-17T14:14:36.404+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpi_5hy0wc']
[2024-06-17T14:14:36.406+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask sprint_transform
[2024-06-17T14:14:36.449+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host ad2413a51065
[2024-06-17T14:14:37.125+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-17T14:14:37.126+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T14:14:37.148+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-17T14:14:37.154+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T14:14:37.179+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240617T141436, end_date=20240617T141437
[2024-06-17T14:14:37.219+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T14:14:37.243+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-17T14:14:37.244+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-24T07:21:51.637+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-24T07:21:51.653+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:21:51.659+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [queued]>
[2024-06-24T07:21:51.659+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-24T07:21:51.668+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): sprint_transform> on 2024-06-16 00:00:00+00:00
[2024-06-24T07:21:51.674+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=468) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-24T07:21:51.675+0000] {standard_task_runner.py:63} INFO - Started process 471 to run task
[2024-06-24T07:21:51.675+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'sprint_transform', 'scheduled__2024-06-16T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8k04m5ae']
[2024-06-24T07:21:51.677+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask sprint_transform
[2024-06-24T07:21:51.713+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.sprint_transform scheduled__2024-06-16T00:00:00+00:00 [running]> on host 4fefe0a35f4a
[2024-06-24T07:21:52.374+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='sprint_transform' AIRFLOW_CTX_EXECUTION_DATE='2024-06-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-16T00:00:00+00:00'
[2024-06-24T07:21:52.375+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-24T07:21:52.406+0000] {python.py:237} INFO - Done. Returned value was:         raceId  driverId sprint_date sprint_time
0          860        18        None        None
116        860         1        None        None
232        861        18        None        None
512        861         1        None        None
680        862        18        None        None
...        ...       ...         ...         ...
517536     932       829        None        None
517602     936       829        None        None
517927     944       829        None        None
518061     944       834        None        None
518195     953       837        None        None

[4502 rows x 4 columns]
[2024-06-24T07:21:52.414+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-24T07:21:52.442+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=sprint_transform, run_id=scheduled__2024-06-16T00:00:00+00:00, execution_date=20240616T000000, start_date=20240624T072151, end_date=20240624T072152
[2024-06-24T07:21:52.491+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-24T07:21:52.512+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-24T07:21:52.514+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
