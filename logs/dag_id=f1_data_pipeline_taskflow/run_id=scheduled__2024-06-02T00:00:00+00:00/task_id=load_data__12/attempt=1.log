[2024-06-03T08:34:00.687+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T08:34:00.703+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:34:00.709+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:34:00.709+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T08:34:00.717+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T08:34:00.723+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=555) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T08:34:00.724+0000] {standard_task_runner.py:63} INFO - Started process 557 to run task
[2024-06-03T08:34:00.724+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpr1z0qvbs']
[2024-06-03T08:34:00.726+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask load_data__12
[2024-06-03T08:34:00.757+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 25a65b768c81
[2024-06-03T08:34:00.872+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T08:34:00.873+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T08:34:00.874+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T08:34:00.874+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T08:34:00.883+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T08:34:00.935+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T08:34:00.935+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T08:34:00.952+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T083400, end_date=20240603T083400
[2024-06-03T08:34:00.959+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 28 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 557)
[2024-06-03T08:34:00.977+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T08:34:00.988+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T08:34:00.990+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T08:44:40.167+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T08:44:40.182+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:44:40.187+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:44:40.188+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T08:44:40.195+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T08:44:40.201+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T08:44:40.202+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T08:44:40.202+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpactkk1gd']
[2024-06-03T08:44:40.204+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T08:44:40.236+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 1b93f8e855cd
[2024-06-03T08:44:40.350+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T08:44:40.350+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T08:44:40.351+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T08:44:40.352+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T08:44:40.360+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T08:44:40.412+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T08:44:40.413+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T08:44:40.432+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T084440, end_date=20240603T084440
[2024-06-03T08:44:40.441+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type time: "+4.075"
LINE 1: ...4932, 64978, 3, 15.0, 58, 1, '1:29.538', 213.214, '+4.075', ...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 560)
[2024-06-03T08:44:40.455+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T08:44:40.466+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T08:44:40.467+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T08:51:41.229+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T08:51:41.245+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:51:41.251+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:51:41.251+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T08:51:41.258+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T08:51:41.264+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=605) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T08:51:41.265+0000] {standard_task_runner.py:63} INFO - Started process 607 to run task
[2024-06-03T08:51:41.265+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpoazs1cyr']
[2024-06-03T08:51:41.267+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T08:51:41.297+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 216c629358bb
[2024-06-03T08:51:41.423+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T08:51:41.423+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T08:51:41.425+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T08:51:41.425+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T08:51:41.435+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T08:51:41.495+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T08:51:41.496+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T08:51:41.512+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T085141, end_date=20240603T085141
[2024-06-03T08:51:41.520+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 607)
[2024-06-03T08:51:41.559+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T08:51:41.576+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T08:51:41.578+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T08:57:11.918+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T08:57:11.933+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:57:11.938+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T08:57:11.939+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T08:57:11.946+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T08:57:11.952+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=565) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T08:57:11.953+0000] {standard_task_runner.py:63} INFO - Started process 567 to run task
[2024-06-03T08:57:11.953+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpik5h_2sf']
[2024-06-03T08:57:11.955+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T08:57:11.986+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host dc35e2debed5
[2024-06-03T08:57:12.106+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T08:57:12.107+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T08:57:12.108+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T08:57:12.109+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T08:57:12.118+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T08:57:12.174+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T08:57:12.175+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T08:57:12.191+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T085711, end_date=20240603T085712
[2024-06-03T08:57:12.198+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 567)
[2024-06-03T08:57:12.206+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T08:57:12.217+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T08:57:12.218+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:06:02.737+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:06:02.752+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:06:02.757+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:06:02.758+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:06:02.766+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:06:02.772+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:06:02.772+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T09:06:02.773+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmphilxtq7t']
[2024-06-03T09:06:02.774+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:06:02.804+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host f68a8afe55d2
[2024-06-03T09:06:02.924+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:06:02.924+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:06:02.926+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:06:02.926+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:06:02.935+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:06:02.989+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:06:02.990+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': None, 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': 4.075, 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': None, 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': 14.591, 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': 20.626, 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': 26.012, 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': 58.984, 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': None, 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:06:03.006+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T090602, end_date=20240603T090603
[2024-06-03T09:06:03.014+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': None, 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': 4.075, 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': None, 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': 14.591, 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': 20.626, 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': 26.012, 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': 58.984, 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': None, 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 560)
[2024-06-03T09:06:03.026+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:06:03.037+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:06:03.038+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:13:57.242+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:13:57.257+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:13:57.262+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:13:57.262+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:13:57.270+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:13:57.275+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=559) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:13:57.276+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-03T09:13:57.276+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpyjkhu65k']
[2024-06-03T09:13:57.278+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:13:57.313+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 4119bb8bb291
[2024-06-03T09:13:57.434+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:13:57.436+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:13:57.437+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:13:57.437+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:13:57.446+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:13:57.501+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:13:57.502+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:13:57.522+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T091357, end_date=20240603T091357
[2024-06-03T09:13:57.530+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 561)
[2024-06-03T09:13:57.570+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:13:57.581+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:13:57.583+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:25:38.053+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:25:38.070+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:25:38.076+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:25:38.076+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:25:38.084+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:25:38.091+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=621) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:25:38.092+0000] {standard_task_runner.py:63} INFO - Started process 623 to run task
[2024-06-03T09:25:38.092+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpfwwbzcz2']
[2024-06-03T09:25:38.094+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:25:38.128+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 27c9a82b83bd
[2024-06-03T09:25:38.250+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:25:38.251+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:25:38.252+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:25:38.252+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:25:38.261+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:196: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:25:38.315+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:25:38.315+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ... 18, 24932, 64976, 1, 25.0, 58, 2, NULL, 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 196, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ... 18, 24932, 64976, 1, 25.0, 58, 2, NULL, 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': None, 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': None, 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': None, 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': None, 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': None, 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': None, 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': None, 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:25:38.332+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T092538, end_date=20240603T092538
[2024-06-03T09:25:38.341+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ... 18, 24932, 64976, 1, 25.0, 58, 2, NULL, 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': None, 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': None, 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': None, 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': None, 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': None, 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': None, 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': None, 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': None, 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 623)
[2024-06-03T09:25:38.386+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:25:38.398+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:25:38.399+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:38:12.349+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:38:12.364+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:38:12.370+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:38:12.370+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:38:12.378+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:38:12.385+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:38:12.386+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T09:38:12.386+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpk3ji4kgr']
[2024-06-03T09:38:12.387+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:38:12.420+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 191d21591140
[2024-06-03T09:38:12.549+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:38:12.550+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:38:12.551+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:38:12.552+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:38:12.560+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:197: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:38:12.613+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:38:12.613+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ..., 1, 25.0, 58, 2,  -9223372036854775808, 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 197, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ..., 1, 25.0, 58, 2,  -9223372036854775808, 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:38:12.633+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T093812, end_date=20240603T093812
[2024-06-03T09:38:12.642+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ..., 1, 25.0, 58, 2,  -9223372036854775808, 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': -9223372036854775808, 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 562)
[2024-06-03T09:38:12.679+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:38:12.690+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:38:12.692+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:42:18.580+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:42:18.597+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:42:18.603+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:42:18.603+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:42:18.613+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:42:18.619+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:42:18.620+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T09:42:18.620+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpr88gas9g']
[2024-06-03T09:42:18.621+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:42:18.657+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host ac0500c9cdd5
[2024-06-03T09:42:18.775+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:42:18.775+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:42:18.777+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:42:18.777+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:42:18.786+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:198: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:42:18.843+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:42:18.843+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 198, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:42:18.862+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T094218, end_date=20240603T094218
[2024-06-03T09:42:18.872+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 560)
[2024-06-03T09:42:18.913+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:42:18.925+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:42:18.927+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T09:45:02.550+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T09:45:02.564+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:45:02.569+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T09:45:02.570+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T09:45:02.577+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T09:45:02.583+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T09:45:02.584+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T09:45:02.584+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpzcs3qisd']
[2024-06-03T09:45:02.585+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T09:45:02.616+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 4d4610b8dd99
[2024-06-03T09:45:02.726+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T09:45:02.727+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T09:45:02.728+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T09:45:02.729+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T09:45:02.737+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:198: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T09:45:02.790+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T09:45:02.791+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 198, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T09:45:02.808+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T094502, end_date=20240603T094502
[2024-06-03T09:45:02.816+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type double precision: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0, 'milliseconds': 5649565000000}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0, 'milliseconds': 5653640000000}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0, 'milliseconds': 9971531000000}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0, 'milliseconds': 9906403000000}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0, 'milliseconds': 5807555000000}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0, 'milliseconds': 5812941000000}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0, 'milliseconds': 5769974000000}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0, 'milliseconds': 6034391000000}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': -9223372036854775808}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': -9223372036854775808})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 563)
[2024-06-03T09:45:02.877+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T09:45:02.890+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T09:45:02.891+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T10:02:41.719+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T10:02:41.735+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:02:41.740+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:02:41.741+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T10:02:41.749+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T10:02:41.755+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T10:02:41.756+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T10:02:41.756+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8fe7c5f0']
[2024-06-03T10:02:41.758+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T10:02:41.791+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host a5fec9cf7dd1
[2024-06-03T10:02:41.919+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T10:02:41.920+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T10:02:41.921+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T10:02:41.921+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T10:02:41.931+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:198: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T10:02:42.142+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T10:02:42.143+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T10:02:42.149+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T100241, end_date=20240603T100242
[2024-06-03T10:02:42.170+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T10:02:42.181+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T10:02:42.182+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T10:14:23.281+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T10:14:23.297+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:14:23.303+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:14:23.303+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T10:14:23.312+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T10:14:23.318+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=556) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T10:14:23.319+0000] {standard_task_runner.py:63} INFO - Started process 558 to run task
[2024-06-03T10:14:23.319+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp_kbyzy6x']
[2024-06-03T10:14:23.321+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T10:14:23.358+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host bb971094f44b
[2024-06-03T10:14:23.495+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T10:14:23.496+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T10:14:23.498+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T10:14:23.498+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T10:14:23.509+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:198: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T10:14:23.731+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T10:14:23.732+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T10:14:23.739+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T101423, end_date=20240603T101423
[2024-06-03T10:14:23.774+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T10:14:23.785+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T10:14:23.787+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T10:21:29.151+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T10:21:29.167+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:21:29.173+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:21:29.173+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T10:21:29.180+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T10:21:29.186+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T10:21:29.187+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T10:21:29.188+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprcxmj_9f']
[2024-06-03T10:21:29.189+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T10:21:29.220+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 0053659eca33
[2024-06-03T10:21:29.337+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T10:21:29.338+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T10:21:29.339+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T10:21:29.339+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T10:21:29.348+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:188: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T10:21:29.553+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T10:21:29.554+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T10:21:29.563+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T102129, end_date=20240603T102129
[2024-06-03T10:21:29.602+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T10:21:29.616+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T10:21:29.618+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T10:50:20.958+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T10:50:20.975+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:50:20.981+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T10:50:20.982+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T10:50:20.990+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T10:50:20.995+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=565) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T10:50:20.996+0000] {standard_task_runner.py:63} INFO - Started process 567 to run task
[2024-06-03T10:50:20.996+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpptspzr_l']
[2024-06-03T10:50:20.997+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T10:50:21.032+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 1119030805b8
[2024-06-03T10:50:21.154+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T10:50:21.155+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T10:50:21.157+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T10:50:21.157+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T10:50:21.167+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:187: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T10:50:21.381+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T10:50:21.381+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T10:50:21.388+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T105020, end_date=20240603T105021
[2024-06-03T10:50:21.409+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T10:50:21.419+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T10:50:21.421+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T11:48:52.934+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T11:48:52.950+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T11:48:52.955+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T11:48:52.955+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T11:48:52.963+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T11:48:52.969+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T11:48:52.970+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T11:48:52.970+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpe10fgmjj']
[2024-06-03T11:48:52.972+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T11:48:53.003+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 87197cc50edf
[2024-06-03T11:48:53.121+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T11:48:53.121+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T11:48:53.123+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T11:48:53.123+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T11:48:53.132+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:187: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T11:48:53.339+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T11:48:53.340+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T11:48:53.347+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T114852, end_date=20240603T114853
[2024-06-03T11:48:53.385+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T11:48:53.397+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T11:48:53.398+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:02:26.920+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:02:26.936+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:02:26.942+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:02:26.942+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:02:26.951+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:02:26.957+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=562) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:02:26.958+0000] {standard_task_runner.py:63} INFO - Started process 564 to run task
[2024-06-03T12:02:26.958+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpn32sdp8m']
[2024-06-03T12:02:26.960+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:02:26.993+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 4a3738072664
[2024-06-03T12:02:27.123+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:02:27.124+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:02:27.126+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:02:27.126+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:02:27.135+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:187: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T12:02:27.349+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:02:27.350+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:02:27.356+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T120226, end_date=20240603T120227
[2024-06-03T12:02:27.373+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:02:27.385+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:02:27.386+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:05:51.038+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:05:51.053+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:05:51.058+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:05:51.058+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:05:51.066+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:05:51.071+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:05:51.072+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T12:05:51.073+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprw23wqed']
[2024-06-03T12:05:51.074+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:05:51.106+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 0b82a86b0d64
[2024-06-03T12:05:51.219+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:05:51.220+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:05:51.221+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:05:51.221+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:05:51.229+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:187: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T12:05:51.434+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:05:51.435+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:05:51.442+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T120551, end_date=20240603T120551
[2024-06-03T12:05:51.486+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:05:51.503+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:05:51.506+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:08:58.413+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:08:58.429+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:08:58.435+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:08:58.435+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:08:58.443+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:08:58.450+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=562) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:08:58.450+0000] {standard_task_runner.py:63} INFO - Started process 564 to run task
[2024-06-03T12:08:58.451+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpt8xh8sv0']
[2024-06-03T12:08:58.452+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:08:58.485+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 023837dae654
[2024-06-03T12:08:58.602+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:08:58.603+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:08:58.604+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:08:58.604+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:08:58.614+0000] {warnings.py:110} WARNING - /opt/***/dags/etl_dag.py:187: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
  df.to_sql(table_name, engine, if_exists='append', index=False)

[2024-06-03T12:08:58.822+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:08:58.822+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:08:58.829+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T120858, end_date=20240603T120858
[2024-06-03T12:08:58.865+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:08:58.876+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:08:58.877+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:25:52.099+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:25:52.116+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:25:52.122+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:25:52.122+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:25:52.131+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:25:52.137+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:25:52.138+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T12:25:52.138+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpyp_pki25']
[2024-06-03T12:25:52.140+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:25:52.173+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 309ef248c5d4
[2024-06-03T12:25:52.288+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:25:52.289+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:25:52.290+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:25:52.290+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:25:52.353+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:25:52.353+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.DatatypeMismatch: column "milliseconds" is of type double precision but expression is of type timestamp without time zone
LINE 1: ... 1, 25.0, 58, 2, '1:29.187', 214.053, NULL, 56.0, '1970-01-0...
                                                             ^
HINT:  You will need to rewrite or cast the expression.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 187, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DatatypeMismatch) column "milliseconds" is of type double precision but expression is of type timestamp without time zone
LINE 1: ... 1, 25.0, 58, 2, '1:29.187', 214.053, NULL, 56.0, '1970-01-0...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': None, 'fastestLap': 56.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5649)}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': 4.075, 'fastestLap': 57.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5653)}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': None, 'fastestLap': 50.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 9971)}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': 14.591, 'fastestLap': 50.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 9906)}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': 20.626, 'fastestLap': 56.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5807)}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': 26.012, 'fastestLap': 40.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5812)}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': 58.984, 'fastestLap': 38.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5769)}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': None, 'fastestLap': 41.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 6034)}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': None}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': None})]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-03T12:25:52.373+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T122552, end_date=20240603T122552
[2024-06-03T12:25:52.380+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.DatatypeMismatch) column "milliseconds" is of type double precision but expression is of type timestamp without time zone
LINE 1: ... 1, 25.0, 58, 2, '1:29.187', 214.053, NULL, 56.0, '1970-01-0...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap", milliseconds) VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s, %(milliseconds)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': None, 'fastestLap': 56.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5649)}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': 4.075, 'fastestLap': 57.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5653)}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': None, 'fastestLap': 50.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 9971)}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': 14.591, 'fastestLap': 50.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 9906)}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': 20.626, 'fastestLap': 56.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5807)}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': 26.012, 'fastestLap': 40.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5812)}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': 58.984, 'fastestLap': 38.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 5769)}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': None, 'fastestLap': 41.0, 'milliseconds': datetime.datetime(1970, 1, 1, 0, 0, 0, 6034)}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0, 'milliseconds': None}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0, 'milliseconds': None})]
(Background on this error at: https://sqlalche.me/e/14/f405); 563)
[2024-06-03T12:25:52.392+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T12:25:52.403+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:25:52.404+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:28:39.073+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:28:39.090+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:28:39.096+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:28:39.097+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:28:39.104+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:28:39.111+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=567) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:28:39.112+0000] {standard_task_runner.py:63} INFO - Started process 569 to run task
[2024-06-03T12:28:39.112+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp3raxh0f6']
[2024-06-03T12:28:39.113+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:28:39.146+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host f268f47424e3
[2024-06-03T12:28:39.261+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:28:39.262+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:28:39.263+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:28:39.264+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:28:39.486+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:28:39.486+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:28:39.494+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T122839, end_date=20240603T122839
[2024-06-03T12:28:39.526+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:28:39.537+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:28:39.538+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:36:53.542+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:36:53.557+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:36:53.563+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:36:53.563+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:36:53.570+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:36:53.576+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=562) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:36:53.577+0000] {standard_task_runner.py:63} INFO - Started process 564 to run task
[2024-06-03T12:36:53.577+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmppbu9su0p']
[2024-06-03T12:36:53.579+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:36:53.609+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host af9236f7a627
[2024-06-03T12:36:53.736+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:36:53.737+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:36:53.738+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:36:53.739+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:36:53.961+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:36:53.961+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:36:53.969+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T123653, end_date=20240603T123653
[2024-06-03T12:36:53.991+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:36:54.003+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:36:54.004+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:40:26.243+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:40:26.258+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:40:26.265+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:40:26.265+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:40:26.273+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:40:26.279+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=571) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:40:26.280+0000] {standard_task_runner.py:63} INFO - Started process 573 to run task
[2024-06-03T12:40:26.281+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpdfn6crb2']
[2024-06-03T12:40:26.282+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:40:26.314+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 148bf491c0c1
[2024-06-03T12:40:26.434+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:40:26.435+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:40:26.436+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:40:26.437+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:40:26.720+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:40:26.721+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:40:26.728+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T124026, end_date=20240603T124026
[2024-06-03T12:40:26.774+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:40:26.782+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:52:41.811+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:52:41.827+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:52:41.833+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:52:41.833+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:52:41.841+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:52:41.847+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=563) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:52:41.847+0000] {standard_task_runner.py:63} INFO - Started process 565 to run task
[2024-06-03T12:52:41.848+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpoq3dmzr4']
[2024-06-03T12:52:41.849+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:52:41.880+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 75def620a537
[2024-06-03T12:52:42.003+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:52:42.004+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:52:42.006+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:52:42.006+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:52:42.236+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:52:42.237+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:52:42.244+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T125241, end_date=20240603T125242
[2024-06-03T12:52:42.262+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:52:42.272+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:52:42.274+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T12:58:18.955+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T12:58:18.973+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:58:18.979+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T12:58:18.979+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T12:58:18.987+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T12:58:18.994+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=564) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T12:58:18.995+0000] {standard_task_runner.py:63} INFO - Started process 573 to run task
[2024-06-03T12:58:18.995+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp2t1xunml']
[2024-06-03T12:58:18.996+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T12:58:19.030+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host dd6d107969a3
[2024-06-03T12:58:19.148+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T12:58:19.149+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T12:58:19.151+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T12:58:19.151+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T12:58:19.398+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T12:58:19.399+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T12:58:19.406+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T125818, end_date=20240603T125819
[2024-06-03T12:58:19.449+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T12:58:19.460+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T12:58:19.462+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:06:29.525+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:06:29.541+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:06:29.547+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:06:29.548+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:06:29.556+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:06:29.562+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=559) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:06:29.563+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-03T13:06:29.564+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpbyp2v06t']
[2024-06-03T13:06:29.565+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:06:29.598+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host fdf5962c6ce8
[2024-06-03T13:06:29.731+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:06:29.732+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:06:29.733+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:06:29.734+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:06:29.919+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:06:29.919+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:06:29.927+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T130629, end_date=20240603T130629
[2024-06-03T13:06:29.977+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:06:29.988+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:06:29.990+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:10:33.098+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:10:33.115+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:10:33.120+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:10:33.120+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:10:33.128+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:10:33.134+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=562) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:10:33.135+0000] {standard_task_runner.py:63} INFO - Started process 564 to run task
[2024-06-03T13:10:33.136+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpxc08eg8b']
[2024-06-03T13:10:33.137+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:10:33.174+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host bc40b27929ff
[2024-06-03T13:10:33.294+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:10:33.295+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:10:33.296+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:10:33.297+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:10:33.466+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:10:33.466+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:10:33.473+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T131033, end_date=20240603T131033
[2024-06-03T13:10:33.509+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:10:33.520+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:10:33.522+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:14:46.718+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:14:46.734+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:14:46.741+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:14:46.741+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:14:46.749+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:14:46.755+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:14:46.756+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T13:14:46.757+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpdg53w71t']
[2024-06-03T13:14:46.758+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:14:46.791+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 079b70194df9
[2024-06-03T13:14:46.910+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:14:46.911+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:14:46.912+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:14:46.912+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:14:47.099+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:14:47.099+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:14:47.106+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T131446, end_date=20240603T131447
[2024-06-03T13:14:47.130+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:14:47.142+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:14:47.143+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:25:26.172+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:25:26.189+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:25:26.196+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:25:26.196+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:25:26.204+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:25:26.211+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:25:26.212+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T13:25:26.212+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpnwbgt6ua']
[2024-06-03T13:25:26.214+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:25:26.249+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 8a43854245bb
[2024-06-03T13:25:26.369+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:25:26.370+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:25:26.371+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:25:26.371+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:25:26.552+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:25:26.553+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:25:26.560+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T132526, end_date=20240603T132526
[2024-06-03T13:25:26.586+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:25:26.597+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:25:26.599+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:32:20.335+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:32:20.350+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:32:20.355+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:32:20.356+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:32:20.363+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:32:20.369+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:32:20.370+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T13:32:20.370+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpi0yeba4f']
[2024-06-03T13:32:20.372+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:32:20.406+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 358e05527583
[2024-06-03T13:32:20.528+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:32:20.529+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:32:20.530+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:32:20.531+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:32:20.717+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:32:20.717+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:32:20.725+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T133220, end_date=20240603T133220
[2024-06-03T13:32:20.744+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:32:20.756+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:32:20.757+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:35:14.106+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:35:14.123+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:35:14.129+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:35:14.129+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:35:14.138+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:35:14.144+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:35:14.145+0000] {standard_task_runner.py:63} INFO - Started process 569 to run task
[2024-06-03T13:35:14.145+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp1mpj1xkv']
[2024-06-03T13:35:14.147+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:35:14.179+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host e294eb76862f
[2024-06-03T13:35:14.297+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:35:14.298+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:35:14.299+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:35:14.300+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:35:14.481+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:35:14.482+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:35:14.489+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T133514, end_date=20240603T133514
[2024-06-03T13:35:14.520+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:35:14.531+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:35:14.532+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:38:40.436+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:38:40.453+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:38:40.460+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:38:40.460+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:38:40.469+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:38:40.475+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:38:40.476+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T13:38:40.477+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpw8ekrp_x']
[2024-06-03T13:38:40.478+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:38:40.517+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host c20b72d53e8b
[2024-06-03T13:38:40.628+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:38:40.629+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:38:40.630+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:38:40.631+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:38:40.815+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:38:40.816+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:38:40.823+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T133840, end_date=20240603T133840
[2024-06-03T13:38:40.850+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:38:40.862+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:38:40.863+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:41:16.506+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:41:16.522+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:41:16.527+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:41:16.527+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:41:16.536+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:41:16.542+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=559) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:41:16.542+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-03T13:41:16.543+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp1zc2f9q_']
[2024-06-03T13:41:16.545+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:41:16.590+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 7b55653f5a2d
[2024-06-03T13:41:16.718+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:41:16.719+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:41:16.720+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:41:16.720+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:41:16.889+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:41:16.889+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:41:16.896+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T134116, end_date=20240603T134116
[2024-06-03T13:41:16.917+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:41:16.928+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:41:16.929+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T13:59:21.783+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T13:59:21.807+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:59:21.815+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T13:59:21.815+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T13:59:21.826+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T13:59:21.833+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=559) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T13:59:21.835+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-03T13:59:21.834+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpyoy1o71p']
[2024-06-03T13:59:21.836+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T13:59:21.871+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host d95b8def734d
[2024-06-03T13:59:21.989+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T13:59:21.990+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T13:59:21.991+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T13:59:21.992+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T13:59:22.159+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T13:59:22.159+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T13:59:22.166+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T135921, end_date=20240603T135922
[2024-06-03T13:59:22.209+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T13:59:22.220+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T13:59:22.221+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:03:33.095+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:03:33.111+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:03:33.117+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:03:33.117+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:03:33.126+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:03:33.132+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=568) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:03:33.132+0000] {standard_task_runner.py:63} INFO - Started process 570 to run task
[2024-06-03T14:03:33.133+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpv8ab1fi_']
[2024-06-03T14:03:33.135+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:03:33.170+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host edc16a5e1b97
[2024-06-03T14:03:33.294+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:03:33.295+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:03:33.296+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:03:33.297+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:03:33.474+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:03:33.475+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:03:33.482+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T140333, end_date=20240603T140333
[2024-06-03T14:03:33.506+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:03:33.518+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:03:33.519+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:06:21.644+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:06:21.659+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:06:21.665+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:06:21.665+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:06:21.674+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:06:21.679+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=559) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:06:21.680+0000] {standard_task_runner.py:63} INFO - Started process 561 to run task
[2024-06-03T14:06:21.681+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp_wy9up1y']
[2024-06-03T14:06:21.682+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:06:21.715+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host a5361fc1545e
[2024-06-03T14:06:21.828+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:06:21.829+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:06:21.830+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:06:21.830+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:06:21.995+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:06:21.996+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:06:22.002+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T140621, end_date=20240603T140622
[2024-06-03T14:06:22.054+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:06:22.065+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:06:22.067+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:12:47.648+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:12:47.665+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:12:47.671+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:12:47.671+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:12:47.680+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:12:47.686+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:12:47.687+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T14:12:47.688+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp9oxnrqxf']
[2024-06-03T14:12:47.689+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:12:47.726+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 57458d438a7a
[2024-06-03T14:12:47.835+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:12:47.836+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:12:47.837+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:12:47.837+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:12:48.001+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:12:48.002+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:12:48.009+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T141247, end_date=20240603T141248
[2024-06-03T14:12:48.061+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:12:48.074+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:12:48.076+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:15:59.029+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:15:59.047+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:15:59.053+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:15:59.054+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:15:59.067+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:15:59.074+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:15:59.075+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T14:15:59.075+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpgvy348i4']
[2024-06-03T14:15:59.077+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:15:59.114+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 22a6bb50d764
[2024-06-03T14:15:59.236+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:15:59.237+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:15:59.238+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:15:59.239+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:15:59.399+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:15:59.400+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:15:59.408+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T141559, end_date=20240603T141559
[2024-06-03T14:15:59.449+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:15:59.459+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:15:59.461+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:26:28.452+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:26:28.470+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:26:28.477+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:26:28.477+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:26:28.485+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:26:28.491+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:26:28.492+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T14:26:28.493+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp2thn9azu']
[2024-06-03T14:26:28.495+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:26:28.527+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 0de6c9ac7879
[2024-06-03T14:26:28.645+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:26:28.646+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:26:28.647+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:26:28.647+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:26:28.704+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:26:28.705+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 189, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T14:26:28.721+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T142628, end_date=20240603T142628
[2024-06-03T14:26:28.731+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 562)
[2024-06-03T14:26:28.746+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T14:26:28.757+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:26:28.758+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:31:20.347+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:31:20.363+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:31:20.368+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:31:20.369+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:31:20.376+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:31:20.383+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=564) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:31:20.384+0000] {standard_task_runner.py:63} INFO - Started process 566 to run task
[2024-06-03T14:31:20.384+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpsdkzeaxz']
[2024-06-03T14:31:20.385+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:31:20.417+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host e215e198c4f4
[2024-06-03T14:31:20.531+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:31:20.531+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:31:20.533+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:31:20.533+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:31:20.590+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:31:20.591+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type timestamp: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 189, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T14:31:20.607+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T143120, end_date=20240603T143120
[2024-06-03T14:31:20.615+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:34:09.565"
LINE 1: ...4932, 64976, 1, 25.0, 58, 2, '1:29.187', 214.053, '1:34:09.5...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 566)
[2024-06-03T14:31:20.637+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T14:31:20.648+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:31:20.650+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:33:59.360+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:33:59.376+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:33:59.382+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:33:59.382+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:33:59.391+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:33:59.397+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=562) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:33:59.399+0000] {standard_task_runner.py:63} INFO - Started process 564 to run task
[2024-06-03T14:33:59.398+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpferwjmd0']
[2024-06-03T14:33:59.400+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:33:59.432+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host c6bc36c91dff
[2024-06-03T14:33:59.545+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:33:59.546+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:33:59.547+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:33:59.547+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:33:59.606+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:33:59.606+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 189, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T14:33:59.623+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T143359, end_date=20240603T143359
[2024-06-03T14:33:59.631+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 564)
[2024-06-03T14:33:59.652+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T14:33:59.663+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:33:59.664+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:36:35.140+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:36:35.156+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:36:35.162+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:36:35.162+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:36:35.170+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:36:35.176+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:36:35.177+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T14:36:35.177+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpetw8drw7']
[2024-06-03T14:36:35.179+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:36:35.213+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 13e1f5c75a30
[2024-06-03T14:36:35.330+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:36:35.331+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:36:35.332+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:36:35.333+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:36:35.544+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:36:35.544+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:36:35.551+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T143635, end_date=20240603T143635
[2024-06-03T14:36:35.591+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:36:35.601+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:36:35.603+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:42:40.273+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:42:40.287+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:42:40.293+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:42:40.293+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:42:40.300+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:42:40.306+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=561) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:42:40.307+0000] {standard_task_runner.py:63} INFO - Started process 563 to run task
[2024-06-03T14:42:40.307+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpxs4roqpe']
[2024-06-03T14:42:40.309+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:42:40.340+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 1eacd419231e
[2024-06-03T14:42:40.449+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:42:40.450+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:42:40.451+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:42:40.451+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:42:40.508+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:42:40.508+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.InvalidDatetimeFormat: invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 189, in load_data
    df.to_sql(table_name, engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h)
[2024-06-03T14:42:40.527+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T144240, end_date=20240603T144240
[2024-06-03T14:42:40.536+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 29 for task load_data__12 ((psycopg2.errors.InvalidDatetimeFormat) invalid input syntax for type timestamp: "1:29.187"
LINE 1: ...(21232, 860, 1, 18, 24932, 64976, 1, 25.0, 58, 2, '1:29.187'...
                                                             ^

[SQL: INSERT INTO "raceResultsFact" ("resultId", "raceId", "constructorId", "driverId", "constructorStandingsId", "driverStandingsId", "positionOrder", points, laps, grid, "fastestLapTime", "fastestLapSpeed", time, "fastestLap") VALUES (%(resultId)s, %(raceId)s, %(constructorId)s, %(driverId)s, %(constructorStandingsId)s, %(driverStandingsId)s, %(positionOrder)s, %(points)s, %(laps)s, %(grid)s, %(fastestLapTime)s, %(fastestLapSpeed)s, %(time)s, %(fastestLap)s)]
[parameters: ({'resultId': 21232, 'raceId': 860, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24932, 'driverStandingsId': 64976, 'positionOrder': 1, 'points': 25.0, 'laps': 58, 'grid': 2, 'fastestLapTime': '1:29.187', 'fastestLapSpeed': 214.053, 'time': '1:34:09.565', 'fastestLap': 56.0}, {'resultId': 21234, 'raceId': 860, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24932, 'driverStandingsId': 64978, 'positionOrder': 3, 'points': 15.0, 'laps': 58, 'grid': 1, 'fastestLapTime': '1:29.538', 'fastestLapSpeed': 213.214, 'time': '+4.075', 'fastestLap': 57.0}, {'resultId': 21269, 'raceId': 861, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24777, 'driverStandingsId': 64928, 'positionOrder': 14, 'points': 0.0, 'laps': 56, 'grid': 2, 'fastestLapTime': '1:42.100', 'fastestLapSpeed': 195.443, 'time': '+1:19.719', 'fastestLap': 50.0}, {'resultId': 21258, 'raceId': 861, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24777, 'driverStandingsId': 64930, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 1, 'fastestLapTime': '1:41.539', 'fastestLapSpeed': 196.523, 'time': '+14.591', 'fastestLap': 50.0}, {'resultId': 21281, 'raceId': 862, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24789, 'driverStandingsId': 64952, 'positionOrder': 2, 'points': 18.0, 'laps': 56, 'grid': 5, 'fastestLapTime': '1:40.422', 'fastestLapSpeed': 195.411, 'time': '+20.626', 'fastestLap': 56.0}, {'resultId': 21282, 'raceId': 862, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24789, 'driverStandingsId': 64954, 'positionOrder': 3, 'points': 15.0, 'laps': 56, 'grid': 7, 'fastestLapTime': '1:40.530', 'fastestLapSpeed': 195.201, 'time': '+26.012', 'fastestLap': 40.0}, {'resultId': 21311, 'raceId': 863, 'constructorId': 1, 'driverId': 1, 'constructorStandingsId': 24824, 'driverStandingsId': 65002, 'positionOrder': 8, 'points': 4.0, 'laps': 57, 'grid': 2, 'fastestLapTime': '1:37.733', 'fastestLapSpeed': 199.351, 'time': '+58.984', 'fastestLap': 38.0}, {'resultId': 21336, 'raceId': 864, 'constructorId': 1, 'driverId': 18, 'constructorStandingsId': 24836, 'driverStandingsId': 65024, 'positionOrder': 9, 'points': 2.0, 'laps': 66, 'grid': 10, 'fastestLapTime': '1:28.624', 'fastestLapSpeed': 189.09, 'time': '+1:25.246', 'fastestLap': 41.0}  ... displaying 10 of 4502 total bound parameter sets ...  {'resultId': 22894, 'raceId': 944, 'constructorId': 209, 'driverId': 834, 'constructorStandingsId': 26414, 'driverStandingsId': 67504, 'positionOrder': 18, 'points': 0.0, 'laps': 67, 'grid': 17, 'fastestLapTime': '1:18.617', 'fastestLapSpeed': 197.316, 'time': None, 'fastestLap': 43.0}, {'resultId': 23041, 'raceId': 953, 'constructorId': 209, 'driverId': 837, 'constructorStandingsId': 26501, 'driverStandingsId': 67681, 'positionOrder': 15, 'points': 0.0, 'laps': 74, 'grid': 19, 'fastestLapTime': '1:19.868', 'fastestLapSpeed': 150.413, 'time': None, 'fastestLap': 70.0})]
(Background on this error at: https://sqlalche.me/e/14/9h9h); 563)
[2024-06-03T14:42:40.561+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-03T14:42:40.571+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:42:40.573+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:48:04.832+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:48:04.849+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:48:04.855+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:48:04.855+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:48:04.863+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:48:04.869+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=560) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:48:04.870+0000] {standard_task_runner.py:63} INFO - Started process 562 to run task
[2024-06-03T14:48:04.871+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmposnrz2o1']
[2024-06-03T14:48:04.872+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:48:04.907+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host e08b3f871dde
[2024-06-03T14:48:05.026+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:48:05.027+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:48:05.028+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:48:05.028+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:48:05.280+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:48:05.281+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:48:05.290+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T144804, end_date=20240603T144805
[2024-06-03T14:48:05.324+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:48:05.335+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:48:05.336+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-03T14:53:21.976+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-03T14:53:21.993+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:53:22.000+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [queued]>
[2024-06-03T14:53:22.000+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-03T14:53:22.008+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__12> on 2024-06-02 00:00:00+00:00
[2024-06-03T14:53:22.015+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-03T14:53:22.016+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2024-06-03T14:53:22.016+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__12', 'scheduled__2024-06-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpo4h161xo']
[2024-06-03T14:53:22.018+0000] {standard_task_runner.py:91} INFO - Job 29: Subtask load_data__12
[2024-06-03T14:53:22.052+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__12 scheduled__2024-06-02T00:00:00+00:00 [running]> on host 8631da0c0b16
[2024-06-03T14:53:22.170+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__12' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-02T00:00:00+00:00'
[2024-06-03T14:53:22.171+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-03T14:53:22.172+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-03T14:53:22.173+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-03T14:53:22.398+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-03T14:53:22.399+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-03T14:53:22.406+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__12, run_id=scheduled__2024-06-02T00:00:00+00:00, execution_date=20240602T000000, start_date=20240603T145321, end_date=20240603T145322
[2024-06-03T14:53:22.430+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-03T14:53:22.442+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-03T14:53:22.443+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
