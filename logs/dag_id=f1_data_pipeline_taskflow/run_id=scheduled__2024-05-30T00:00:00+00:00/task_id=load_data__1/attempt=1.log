[2024-05-31T09:53:50.795+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T09:53:50.810+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T09:53:50.815+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T09:53:50.816+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T09:53:50.824+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T09:53:50.828+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=144) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T09:53:50.829+0000] {standard_task_runner.py:63} INFO - Started process 148 to run task
[2024-05-31T09:53:50.829+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpbwynu1oi']
[2024-05-31T09:53:50.830+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask load_data__1
[2024-05-31T09:53:50.862+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 994d2ba121a7
[2024-05-31T09:53:50.968+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T09:53:50.969+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T09:53:50.975+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T09:53:50.982+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 90, in load_data
    engine = postgres_hook.get_sqlalchemy_engine()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 219, in get_sqlalchemy_engine
    return create_engine(self.get_uri(), **engine_kwargs)
                         ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/postgres/hooks/postgres.py", line 190, in get_uri
    conn = self.get_connection(getattr(self, self.conn_name_attr))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/hooks/base.py", line 83, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py", line 519, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `sourcedb_connection` isn't defined
[2024-05-31T09:53:50.985+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T095350, end_date=20240531T095350
[2024-05-31T09:53:50.993+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 7 for task load_data__1 (The conn_id `sourcedb_connection` isn't defined; 148)
[2024-05-31T09:53:51.002+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-05-31T09:53:51.008+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T10:04:49.794+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T10:04:49.808+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:04:49.813+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:04:49.813+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T10:04:49.820+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T10:04:49.824+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=212) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T10:04:49.825+0000] {standard_task_runner.py:63} INFO - Started process 215 to run task
[2024-05-31T10:04:49.826+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpo2d6r6lv']
[2024-05-31T10:04:49.827+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask load_data__1
[2024-05-31T10:04:49.856+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 353c2808d24f
[2024-05-31T10:04:49.949+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T10:04:49.950+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T10:04:49.956+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T10:04:49.962+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_dag.py", line 91, in load_data
    engine = postgres_hook.get_sqlalchemy_engine()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 219, in get_sqlalchemy_engine
    return create_engine(self.get_uri(), **engine_kwargs)
                         ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/postgres/hooks/postgres.py", line 190, in get_uri
    conn = self.get_connection(getattr(self, self.conn_name_attr))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/hooks/base.py", line 83, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py", line 519, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `sourcedb_connection` isn't defined
[2024-05-31T10:04:49.965+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T100449, end_date=20240531T100449
[2024-05-31T10:04:49.972+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 6 for task load_data__1 (The conn_id `sourcedb_connection` isn't defined; 215)
[2024-05-31T10:04:49.998+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-05-31T10:04:50.008+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T10:04:50.010+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T10:21:44.354+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T10:21:44.367+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:21:44.371+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:21:44.371+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T10:21:44.379+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T10:21:44.383+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=140) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T10:21:44.384+0000] {standard_task_runner.py:63} INFO - Started process 145 to run task
[2024-05-31T10:21:44.384+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpimx9nwdy']
[2024-05-31T10:21:44.386+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask load_data__1
[2024-05-31T10:21:44.415+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 4f8e6627ba1c
[2024-05-31T10:21:44.506+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T10:21:44.507+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T10:21:44.508+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T10:21:44.508+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T10:21:44.524+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T10:21:44.524+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T10:21:44.531+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T102144, end_date=20240531T102144
[2024-05-31T10:21:44.557+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T10:21:44.563+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T10:44:25.066+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T10:44:25.079+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:44:25.083+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T10:44:25.084+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T10:44:25.091+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T10:44:25.094+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=146) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T10:44:25.095+0000] {standard_task_runner.py:63} INFO - Started process 150 to run task
[2024-05-31T10:44:25.096+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp2vdc5t31']
[2024-05-31T10:44:25.097+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask load_data__1
[2024-05-31T10:44:25.127+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host a14991e030bf
[2024-05-31T10:44:25.219+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T10:44:25.219+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T10:44:25.220+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T10:44:25.220+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T10:44:25.447+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T10:44:25.448+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T10:44:25.454+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T104425, end_date=20240531T104425
[2024-05-31T10:44:25.469+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T10:44:25.483+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T10:44:25.485+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T11:00:44.999+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T11:00:45.014+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T11:00:45.020+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T11:00:45.020+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T11:00:45.029+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T11:00:45.033+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=290) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T11:00:45.034+0000] {standard_task_runner.py:63} INFO - Started process 294 to run task
[2024-05-31T11:00:45.034+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpg9azm028']
[2024-05-31T11:00:45.036+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask load_data__1
[2024-05-31T11:00:45.065+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host d6facdba5536
[2024-05-31T11:00:45.201+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T11:00:45.202+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T11:00:45.203+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T11:00:45.203+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T11:00:45.433+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T11:00:45.433+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T11:00:45.440+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T110045, end_date=20240531T110045
[2024-05-31T11:00:45.488+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T11:00:45.499+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T11:00:45.500+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T11:50:03.576+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T11:50:03.590+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T11:50:03.594+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T11:50:03.595+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T11:50:03.602+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T11:50:03.606+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=147) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T11:50:03.607+0000] {standard_task_runner.py:63} INFO - Started process 150 to run task
[2024-05-31T11:50:03.607+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmplo9lcpsi']
[2024-05-31T11:50:03.608+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask load_data__1
[2024-05-31T11:50:03.639+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host e5f19cf3157d
[2024-05-31T11:50:03.736+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T11:50:03.737+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T11:50:03.738+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T11:50:03.738+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T11:50:04.007+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T11:50:04.007+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T11:50:04.014+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T115003, end_date=20240531T115004
[2024-05-31T11:50:04.061+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T11:50:04.078+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T11:50:04.079+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T12:11:57.019+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T12:11:57.033+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:11:57.038+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:11:57.038+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T12:11:57.045+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T12:11:57.050+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=189) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T12:11:57.051+0000] {standard_task_runner.py:63} INFO - Started process 197 to run task
[2024-05-31T12:11:57.051+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp7251f2sx']
[2024-05-31T12:11:57.053+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T12:11:57.085+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 635d0579969f
[2024-05-31T12:11:57.185+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T12:11:57.186+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T12:11:57.187+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T12:11:57.187+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T12:11:57.203+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T12:11:57.203+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T12:11:57.210+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T121157, end_date=20240531T121157
[2024-05-31T12:11:57.224+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T12:11:57.235+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T12:11:57.237+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T12:15:41.841+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T12:15:41.856+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:15:41.861+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:15:41.861+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T12:15:41.869+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T12:15:41.873+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=190) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T12:15:41.874+0000] {standard_task_runner.py:63} INFO - Started process 197 to run task
[2024-05-31T12:15:41.875+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp3f4pfq1y']
[2024-05-31T12:15:41.876+0000] {standard_task_runner.py:91} INFO - Job 9: Subtask load_data__1
[2024-05-31T12:15:41.908+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 32d043f0486c
[2024-05-31T12:15:42.016+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T12:15:42.017+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T12:15:42.018+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T12:15:42.018+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T12:15:42.035+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T12:15:42.035+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T12:15:42.042+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T121541, end_date=20240531T121542
[2024-05-31T12:15:42.088+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T12:15:42.098+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T12:15:42.099+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T12:27:14.631+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T12:27:14.770+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:27:14.777+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:27:14.778+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T12:27:14.788+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T12:27:14.793+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=189) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T12:27:14.793+0000] {standard_task_runner.py:63} INFO - Started process 202 to run task
[2024-05-31T12:27:14.794+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpl8zmoxj2']
[2024-05-31T12:27:14.795+0000] {standard_task_runner.py:91} INFO - Job 8: Subtask load_data__1
[2024-05-31T12:27:14.830+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 2b4626dac48c
[2024-05-31T12:27:14.966+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T12:27:14.967+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T12:27:14.968+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T12:27:14.969+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T12:27:14.990+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T12:27:14.991+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T12:27:15.001+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T122714, end_date=20240531T122715
[2024-05-31T12:27:15.047+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T12:27:15.059+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T12:27:15.061+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T12:31:45.669+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T12:31:45.685+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:31:45.690+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:31:45.691+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T12:31:45.700+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T12:31:45.704+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=201) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T12:31:45.705+0000] {standard_task_runner.py:63} INFO - Started process 209 to run task
[2024-05-31T12:31:45.705+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpb_m2zg53']
[2024-05-31T12:31:45.707+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask load_data__1
[2024-05-31T12:31:45.740+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 85acc91f6307
[2024-05-31T12:31:45.855+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T12:31:45.856+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T12:31:45.857+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T12:31:45.857+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T12:31:45.872+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T12:31:45.872+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T12:31:45.879+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T123145, end_date=20240531T123145
[2024-05-31T12:31:45.919+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T12:31:45.925+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T12:36:59.314+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T12:36:59.436+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:36:59.441+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T12:36:59.442+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T12:36:59.450+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T12:36:59.454+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=189) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T12:36:59.455+0000] {standard_task_runner.py:63} INFO - Started process 200 to run task
[2024-05-31T12:36:59.455+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpx5mqbnz8']
[2024-05-31T12:36:59.457+0000] {standard_task_runner.py:91} INFO - Job 8: Subtask load_data__1
[2024-05-31T12:36:59.489+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 69a8c1722b53
[2024-05-31T12:36:59.594+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T12:36:59.595+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T12:36:59.596+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T12:36:59.597+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T12:36:59.611+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T12:36:59.611+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T12:36:59.618+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T123659, end_date=20240531T123659
[2024-05-31T12:36:59.668+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T12:36:59.679+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T12:36:59.680+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:16:04.199+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:16:04.214+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:16:04.219+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:16:04.220+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:16:04.228+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:16:04.232+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=602) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:16:04.233+0000] {standard_task_runner.py:63} INFO - Started process 607 to run task
[2024-05-31T13:16:04.234+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpn898amkv']
[2024-05-31T13:16:04.236+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask load_data__1
[2024-05-31T13:16:04.275+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 29de999fd730
[2024-05-31T13:16:04.374+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:16:04.375+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:16:04.376+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:16:04.377+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:16:04.391+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:16:04.391+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:16:04.398+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T131604, end_date=20240531T131604
[2024-05-31T13:16:04.409+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:16:04.420+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:16:04.421+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:20:44.054+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:20:44.070+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:20:44.075+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:20:44.076+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:20:44.084+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:20:44.089+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=197) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:20:44.090+0000] {standard_task_runner.py:63} INFO - Started process 204 to run task
[2024-05-31T13:20:44.090+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpiqyl60or']
[2024-05-31T13:20:44.092+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T13:20:44.126+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 19edeffeeef7
[2024-05-31T13:20:44.230+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:20:44.231+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:20:44.232+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:20:44.232+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:20:44.247+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:20:44.247+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:20:44.254+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T132044, end_date=20240531T132044
[2024-05-31T13:20:44.303+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:20:44.314+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:20:44.315+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:30:58.066+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:30:58.080+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:30:58.085+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:30:58.085+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:30:58.093+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:30:58.097+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=214) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:30:58.098+0000] {standard_task_runner.py:63} INFO - Started process 222 to run task
[2024-05-31T13:30:58.098+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpa7n4r25r']
[2024-05-31T13:30:58.099+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T13:30:58.129+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 71bdf4d24007
[2024-05-31T13:30:58.225+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:30:58.226+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:30:58.227+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:30:58.227+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:30:58.249+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:30:58.249+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:30:58.256+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T133058, end_date=20240531T133058
[2024-05-31T13:30:58.271+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:30:58.277+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:38:33.521+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:38:33.536+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:38:33.541+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:38:33.541+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:38:33.551+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:38:33.557+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=205) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:38:33.557+0000] {standard_task_runner.py:63} INFO - Started process 211 to run task
[2024-05-31T13:38:33.558+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmps9lnf27l']
[2024-05-31T13:38:33.560+0000] {standard_task_runner.py:91} INFO - Job 9: Subtask load_data__1
[2024-05-31T13:38:33.600+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 140bbde645f4
[2024-05-31T13:38:33.722+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:38:33.723+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:38:33.724+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:38:33.724+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:38:33.741+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:38:33.741+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:38:33.747+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T133833, end_date=20240531T133833
[2024-05-31T13:38:33.772+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:38:33.782+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:38:33.784+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:42:24.633+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:42:24.648+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:42:24.653+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:42:24.653+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:42:24.661+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:42:24.665+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=205) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:42:24.666+0000] {standard_task_runner.py:63} INFO - Started process 212 to run task
[2024-05-31T13:42:24.667+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpzlrge279']
[2024-05-31T13:42:24.668+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T13:42:24.699+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 8abcc7a02d3d
[2024-05-31T13:42:24.796+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:42:24.797+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:42:24.798+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:42:24.798+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:42:24.812+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:42:24.813+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:42:24.820+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T134224, end_date=20240531T134224
[2024-05-31T13:42:24.839+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:42:24.852+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:42:24.853+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:46:03.840+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:46:03.854+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:46:03.858+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:46:03.859+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:46:03.866+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:46:03.870+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=213) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:46:03.871+0000] {standard_task_runner.py:63} INFO - Started process 218 to run task
[2024-05-31T13:46:03.871+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprazr9j4g']
[2024-05-31T13:46:03.873+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask load_data__1
[2024-05-31T13:46:03.903+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 2605f7bd5eb2
[2024-05-31T13:46:04.002+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:46:04.003+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:46:04.004+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:46:04.004+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:46:04.020+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:46:04.021+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:46:04.026+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T134603, end_date=20240531T134604
[2024-05-31T13:46:04.044+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:46:04.062+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:46:04.065+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:52:41.198+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:52:41.214+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:52:41.220+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:52:41.220+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:52:41.230+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:52:41.234+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=221) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:52:41.235+0000] {standard_task_runner.py:63} INFO - Started process 225 to run task
[2024-05-31T13:52:41.236+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpuq9ikadj']
[2024-05-31T13:52:41.237+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T13:52:41.271+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host a95aa6127783
[2024-05-31T13:52:41.374+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:52:41.375+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:52:41.376+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:52:41.376+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:52:41.390+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:52:41.391+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:52:41.397+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T135241, end_date=20240531T135241
[2024-05-31T13:52:41.408+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:52:41.418+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:52:41.420+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T13:59:37.939+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T13:59:38.512+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:59:38.517+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T13:59:38.518+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T13:59:38.526+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T13:59:38.531+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=247) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T13:59:38.532+0000] {standard_task_runner.py:63} INFO - Started process 276 to run task
[2024-05-31T13:59:38.532+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpvk5_tk57']
[2024-05-31T13:59:38.534+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask load_data__1
[2024-05-31T13:59:38.566+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host b6e8a688eec4
[2024-05-31T13:59:38.672+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T13:59:38.673+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T13:59:38.674+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T13:59:38.674+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T13:59:38.697+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T13:59:38.698+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T13:59:38.708+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T135938, end_date=20240531T135938
[2024-05-31T13:59:38.745+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T13:59:38.761+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T13:59:38.781+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:10:56.127+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:10:56.145+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:10:56.150+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:10:56.150+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:10:56.160+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:10:56.165+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=238) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:10:56.166+0000] {standard_task_runner.py:63} INFO - Started process 244 to run task
[2024-05-31T14:10:56.167+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpsaq1_2c5']
[2024-05-31T14:10:56.168+0000] {standard_task_runner.py:91} INFO - Job 11: Subtask load_data__1
[2024-05-31T14:10:56.201+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 7fde08b5b7bb
[2024-05-31T14:10:56.324+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:10:56.325+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:10:56.326+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:10:56.327+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:10:56.354+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:10:56.355+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:10:56.361+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T141056, end_date=20240531T141056
[2024-05-31T14:10:56.380+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:10:56.391+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-31T14:10:56.392+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:26:08.567+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:26:08.582+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:26:08.588+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:26:08.588+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:26:08.599+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:26:08.605+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=268) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:26:08.606+0000] {standard_task_runner.py:63} INFO - Started process 275 to run task
[2024-05-31T14:26:08.606+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp5licutle']
[2024-05-31T14:26:08.607+0000] {standard_task_runner.py:91} INFO - Job 13: Subtask load_data__1
[2024-05-31T14:26:08.642+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host e67b5c96142c
[2024-05-31T14:26:08.756+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:26:08.757+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:26:08.758+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:26:08.758+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:26:08.784+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:26:08.785+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:26:08.790+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T142608, end_date=20240531T142608
[2024-05-31T14:26:08.819+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:26:08.825+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:34:38.916+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:34:38.932+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:34:38.937+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:34:38.937+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:34:38.946+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:34:38.951+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=281) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:34:38.952+0000] {standard_task_runner.py:63} INFO - Started process 307 to run task
[2024-05-31T14:34:38.952+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpz_00vnya']
[2024-05-31T14:34:38.954+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask load_data__1
[2024-05-31T14:34:38.989+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host b904eb6286a6
[2024-05-31T14:34:39.100+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:34:39.101+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:34:39.102+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:34:39.102+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:34:39.118+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:34:39.118+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:34:39.125+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T143438, end_date=20240531T143439
[2024-05-31T14:34:39.165+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:34:39.180+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-31T14:34:39.181+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:41:21.170+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:41:21.187+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:41:21.193+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:41:21.193+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:41:21.203+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:41:21.209+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=314) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:41:21.210+0000] {standard_task_runner.py:63} INFO - Started process 319 to run task
[2024-05-31T14:41:21.210+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpgdjn8upl']
[2024-05-31T14:41:21.211+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_data__1
[2024-05-31T14:41:21.243+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 39ebc24e8ca6
[2024-05-31T14:41:21.370+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:41:21.371+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:41:21.372+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:41:21.372+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:41:21.399+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:41:21.400+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:41:21.407+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T144121, end_date=20240531T144121
[2024-05-31T14:41:21.423+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:41:21.441+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-31T14:41:21.442+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:44:42.362+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:44:43.018+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:44:43.024+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:44:43.025+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:44:43.035+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:44:43.042+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=315) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:44:43.043+0000] {standard_task_runner.py:63} INFO - Started process 344 to run task
[2024-05-31T14:44:43.043+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpi1t031co']
[2024-05-31T14:44:43.044+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_data__1
[2024-05-31T14:44:43.078+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host a9750641015b
[2024-05-31T14:44:43.188+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:44:43.189+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:44:43.190+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:44:43.191+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:44:43.209+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:44:43.210+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:44:43.218+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T144443, end_date=20240531T144443
[2024-05-31T14:44:43.256+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:44:43.275+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-31T14:44:43.277+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-31T14:48:47.043+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-31T14:48:47.061+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:48:47.067+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [queued]>
[2024-05-31T14:48:47.067+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-31T14:48:47.076+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_data__1> on 2024-05-30 00:00:00+00:00
[2024-05-31T14:48:47.082+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=312) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-31T14:48:47.083+0000] {standard_task_runner.py:63} INFO - Started process 327 to run task
[2024-05-31T14:48:47.083+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_data__1', 'scheduled__2024-05-30T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpc04410xk']
[2024-05-31T14:48:47.085+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask load_data__1
[2024-05-31T14:48:47.120+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_data__1 scheduled__2024-05-30T00:00:00+00:00 [running]> on host 5e099e29bc21
[2024-05-31T14:48:47.240+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_data__1' AIRFLOW_CTX_EXECUTION_DATE='2024-05-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-30T00:00:00+00:00'
[2024-05-31T14:48:47.241+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-31T14:48:47.242+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-05-31T14:48:47.243+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-05-31T14:48:47.260+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-31T14:48:47.261+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-31T14:48:47.268+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_data__1, run_id=scheduled__2024-05-30T00:00:00+00:00, execution_date=20240530T000000, start_date=20240531T144847, end_date=20240531T144847
[2024-05-31T14:48:47.296+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-31T14:48:47.315+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-31T14:48:47.316+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
