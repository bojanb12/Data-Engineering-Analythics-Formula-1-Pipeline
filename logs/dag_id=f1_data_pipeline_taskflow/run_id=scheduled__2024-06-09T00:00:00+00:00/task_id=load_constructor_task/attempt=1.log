[2024-06-10T07:43:52.642+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T07:43:52.658+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T07:43:52.664+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T07:43:52.664+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T07:43:52.674+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T07:43:52.680+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=339) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T07:43:52.682+0000] {standard_task_runner.py:63} INFO - Started process 373 to run task
[2024-06-10T07:43:52.682+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpbbajs25o']
[2024-06-10T07:43:52.684+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask load_constructor_task
[2024-06-10T07:43:52.720+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host e8457e1e96c0
[2024-06-10T07:43:52.832+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T07:43:52.834+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T07:43:52.835+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T07:43:52.835+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T07:43:52.850+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T07:43:52.850+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T07:43:52.857+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T074352, end_date=20240610T074352
[2024-06-10T07:43:52.895+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T07:43:52.910+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T07:43:52.911+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T08:20:12.164+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T08:20:12.184+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:20:12.191+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:20:12.191+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T08:20:12.218+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T08:20:12.225+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=319) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T08:20:12.227+0000] {standard_task_runner.py:63} INFO - Started process 329 to run task
[2024-06-10T08:20:12.227+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpxb0ejcb0']
[2024-06-10T08:20:12.228+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask load_constructor_task
[2024-06-10T08:20:12.266+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 1d74a271cedb
[2024-06-10T08:20:12.395+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T08:20:12.397+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T08:20:12.399+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T08:20:12.399+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T08:20:12.448+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T08:20:12.449+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T08:20:12.461+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T082012, end_date=20240610T082012
[2024-06-10T08:20:12.520+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T08:20:12.530+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T08:30:40.972+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T08:30:40.990+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:30:40.996+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:30:40.996+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T08:30:41.006+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T08:30:41.013+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=313) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T08:30:41.014+0000] {standard_task_runner.py:63} INFO - Started process 354 to run task
[2024-06-10T08:30:41.014+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpbzecvo2q']
[2024-06-10T08:30:41.016+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask load_constructor_task
[2024-06-10T08:30:41.052+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host c0d58a373fda
[2024-06-10T08:30:41.166+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T08:30:41.167+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T08:30:41.168+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T08:30:41.168+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T08:30:41.183+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T08:30:41.184+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T08:30:41.192+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T083040, end_date=20240610T083041
[2024-06-10T08:30:41.228+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T08:30:41.244+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T08:30:41.246+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T08:45:39.089+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T08:45:39.110+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:45:39.117+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T08:45:39.117+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T08:45:39.139+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T08:45:39.147+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=310) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T08:45:39.148+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-10T08:45:39.148+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp80ojp5ax']
[2024-06-10T08:45:39.150+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_constructor_task
[2024-06-10T08:45:39.187+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 27b2ec5a9b2d
[2024-06-10T08:45:39.333+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T08:45:39.334+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T08:45:39.335+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T08:45:39.336+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T08:45:39.384+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T08:45:39.386+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T08:45:39.403+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T084539, end_date=20240610T084539
[2024-06-10T08:45:39.482+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T08:45:39.490+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T09:01:49.339+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T09:01:49.358+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:01:49.364+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:01:49.364+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T09:01:49.374+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T09:01:49.380+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=318) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T09:01:49.381+0000] {standard_task_runner.py:63} INFO - Started process 362 to run task
[2024-06-10T09:01:49.382+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpb4r32qkq']
[2024-06-10T09:01:49.383+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask load_constructor_task
[2024-06-10T09:01:49.419+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 288f51e0edb6
[2024-06-10T09:01:49.524+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T09:01:49.525+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T09:01:49.527+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T09:01:49.527+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T09:01:49.541+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T09:01:49.542+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T09:01:49.549+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T090149, end_date=20240610T090149
[2024-06-10T09:01:49.595+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T09:01:49.609+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T09:01:49.612+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T09:12:09.727+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T09:12:09.744+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:12:09.750+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:12:09.751+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T09:12:09.760+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T09:12:09.766+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=321) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T09:12:09.767+0000] {standard_task_runner.py:63} INFO - Started process 347 to run task
[2024-06-10T09:12:09.768+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpm_fv1cge']
[2024-06-10T09:12:09.770+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask load_constructor_task
[2024-06-10T09:12:09.806+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 474224cb5bf2
[2024-06-10T09:12:09.919+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T09:12:09.921+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T09:12:09.923+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T09:12:09.923+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T09:12:09.940+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T09:12:09.941+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T09:12:09.948+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T091209, end_date=20240610T091209
[2024-06-10T09:12:09.981+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T09:12:09.998+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T09:12:10.001+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T09:46:59.860+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T09:46:59.877+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:46:59.883+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T09:46:59.883+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T09:46:59.892+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T09:46:59.899+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=362) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T09:46:59.900+0000] {standard_task_runner.py:63} INFO - Started process 390 to run task
[2024-06-10T09:46:59.900+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpjh73jz8g']
[2024-06-10T09:46:59.902+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-10T09:46:59.939+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 1c3d326a454c
[2024-06-10T09:47:00.047+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T09:47:00.049+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T09:47:00.050+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T09:47:00.051+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T09:47:00.098+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T09:47:00.098+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T09:47:00.106+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T094659, end_date=20240610T094700
[2024-06-10T09:47:00.153+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T09:47:00.168+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T09:47:00.169+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T11:55:46.554+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T11:55:46.572+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T11:55:46.577+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T11:55:46.577+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T11:55:46.593+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T11:55:46.600+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=317) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T11:55:46.601+0000] {standard_task_runner.py:63} INFO - Started process 324 to run task
[2024-06-10T11:55:46.601+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpblydm2ir']
[2024-06-10T11:55:46.603+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_constructor_task
[2024-06-10T11:55:46.636+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host aea94abb9e1c
[2024-06-10T11:55:46.755+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T11:55:46.756+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T11:55:46.758+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T11:55:46.758+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T11:55:46.795+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T11:55:46.796+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T11:55:46.803+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T115546, end_date=20240610T115546
[2024-06-10T11:55:46.854+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T11:55:46.869+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T11:55:46.870+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T12:36:33.947+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T12:36:33.964+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:36:33.971+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:36:33.971+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T12:36:33.980+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T12:36:33.987+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=323) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T12:36:33.989+0000] {standard_task_runner.py:63} INFO - Started process 331 to run task
[2024-06-10T12:36:33.989+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpiqmcok5v']
[2024-06-10T12:36:33.991+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-10T12:36:34.034+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 61fa0c91c3b7
[2024-06-10T12:36:34.190+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T12:36:34.195+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T12:36:34.197+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T12:36:34.198+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T12:36:34.220+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T12:36:34.221+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T12:36:34.228+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T123633, end_date=20240610T123634
[2024-06-10T12:36:34.242+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T12:36:34.259+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T12:36:34.260+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T12:43:08.387+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T12:43:08.412+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:43:08.420+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:43:08.421+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T12:43:08.433+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T12:43:08.442+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=313) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T12:43:08.443+0000] {standard_task_runner.py:63} INFO - Started process 320 to run task
[2024-06-10T12:43:08.443+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp49eoxem4']
[2024-06-10T12:43:08.445+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-10T12:43:08.493+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 963d823f23ad
[2024-06-10T12:43:08.625+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T12:43:08.627+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T12:43:08.628+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T12:43:08.628+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T12:43:08.668+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T12:43:08.669+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T12:43:08.676+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T124308, end_date=20240610T124308
[2024-06-10T12:43:08.696+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T12:43:08.711+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T12:43:08.713+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T12:53:15.914+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T12:53:15.931+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:53:15.937+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:53:15.937+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T12:53:15.946+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T12:53:15.953+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=318) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T12:53:15.954+0000] {standard_task_runner.py:63} INFO - Started process 336 to run task
[2024-06-10T12:53:15.954+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmprdzng2ct']
[2024-06-10T12:53:15.956+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-10T12:53:15.992+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host dde96eecb2ac
[2024-06-10T12:53:16.104+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T12:53:16.106+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T12:53:16.107+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T12:53:16.108+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T12:53:16.125+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T12:53:16.126+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T12:53:16.135+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T125315, end_date=20240610T125316
[2024-06-10T12:53:16.167+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T12:53:16.183+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T12:53:16.185+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T12:58:33.512+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T12:58:33.540+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:58:33.547+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T12:58:33.548+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T12:58:33.557+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T12:58:33.564+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=311) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T12:58:33.565+0000] {standard_task_runner.py:63} INFO - Started process 332 to run task
[2024-06-10T12:58:33.565+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpq52xp7ye']
[2024-06-10T12:58:33.567+0000] {standard_task_runner.py:91} INFO - Job 16: Subtask load_constructor_task
[2024-06-10T12:58:33.600+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 1827e5540201
[2024-06-10T12:58:33.704+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T12:58:33.706+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T12:58:33.707+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T12:58:33.708+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T12:58:33.722+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T12:58:33.723+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T12:58:33.730+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T125833, end_date=20240610T125833
[2024-06-10T12:58:33.778+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T12:58:33.794+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T12:58:33.795+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T13:08:25.900+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T13:08:25.917+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:08:25.923+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:08:25.924+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T13:08:25.937+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T13:08:25.945+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=320) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T13:08:25.946+0000] {standard_task_runner.py:63} INFO - Started process 329 to run task
[2024-06-10T13:08:25.947+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpctrlfgsv']
[2024-06-10T13:08:25.948+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-10T13:08:25.988+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 625f3a2113de
[2024-06-10T13:08:26.125+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T13:08:26.127+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T13:08:26.129+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T13:08:26.129+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T13:08:26.189+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T13:08:26.190+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T13:08:26.210+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T130825, end_date=20240610T130826
[2024-06-10T13:08:26.280+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T13:08:26.298+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T13:08:26.300+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T13:23:32.956+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T13:23:32.973+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:23:32.980+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:23:32.981+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T13:23:32.989+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T13:23:32.997+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=317) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T13:23:32.998+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-10T13:23:32.998+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp_p845yry']
[2024-06-10T13:23:33.000+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask load_constructor_task
[2024-06-10T13:23:33.035+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host d102255c9fd1
[2024-06-10T13:23:33.148+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T13:23:33.150+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T13:23:33.151+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T13:23:33.152+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T13:23:33.214+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T13:23:33.215+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T13:23:33.224+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T132332, end_date=20240610T132333
[2024-06-10T13:23:33.252+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T13:23:33.269+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T13:23:33.271+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T13:35:52.613+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T13:35:52.632+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:35:52.637+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:35:52.637+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T13:35:52.646+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T13:35:52.653+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=322) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T13:35:52.654+0000] {standard_task_runner.py:63} INFO - Started process 327 to run task
[2024-06-10T13:35:52.654+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpjj6mgtqc']
[2024-06-10T13:35:52.655+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask load_constructor_task
[2024-06-10T13:35:52.691+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 61e4f3dfec5c
[2024-06-10T13:35:52.824+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T13:35:52.826+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T13:35:52.827+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T13:35:52.827+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T13:35:52.882+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T13:35:52.883+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T13:35:52.894+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T133552, end_date=20240610T133552
[2024-06-10T13:35:52.948+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T13:35:52.972+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T13:35:52.974+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T13:42:02.902+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T13:42:02.922+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:42:02.927+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:42:02.928+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T13:42:02.936+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T13:42:02.943+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=309) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T13:42:02.945+0000] {standard_task_runner.py:63} INFO - Started process 316 to run task
[2024-06-10T13:42:02.944+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpw5omwvqr']
[2024-06-10T13:42:02.946+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask load_constructor_task
[2024-06-10T13:42:02.980+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 5feafd0b96fd
[2024-06-10T13:42:03.099+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T13:42:03.101+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T13:42:03.102+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T13:42:03.102+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T13:42:03.139+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T13:42:03.139+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T13:42:03.146+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T134202, end_date=20240610T134203
[2024-06-10T13:42:03.198+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T13:42:03.212+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T13:42:03.213+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-10T13:47:14.802+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-10T13:47:14.820+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:47:14.826+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-10T13:47:14.826+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-10T13:47:14.835+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-10T13:47:14.842+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=319) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-10T13:47:14.843+0000] {standard_task_runner.py:63} INFO - Started process 361 to run task
[2024-06-10T13:47:14.844+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp04ij2vfn']
[2024-06-10T13:47:14.845+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-10T13:47:14.883+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 0d5d688e6061
[2024-06-10T13:47:14.985+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-10T13:47:14.986+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-10T13:47:14.987+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-10T13:47:14.987+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-10T13:47:15.000+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-10T13:47:15.001+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-10T13:47:15.007+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240610T134714, end_date=20240610T134715
[2024-06-10T13:47:15.057+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-10T13:47:15.073+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-10T13:47:15.074+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-21T08:55:50.845+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-21T08:55:50.862+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-21T08:55:50.869+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-21T08:55:50.869+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-21T08:55:50.878+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-21T08:55:50.884+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=313) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-21T08:55:50.885+0000] {standard_task_runner.py:63} INFO - Started process 337 to run task
[2024-06-21T08:55:50.885+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpwt2kzstb']
[2024-06-21T08:55:50.887+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask load_constructor_task
[2024-06-21T08:55:50.925+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host da56922fb813
[2024-06-21T08:55:51.037+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-21T08:55:51.038+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-21T08:55:51.040+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-21T08:55:51.040+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-21T08:55:51.059+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-21T08:55:51.060+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-21T08:55:51.071+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240621T085550, end_date=20240621T085551
[2024-06-21T08:55:51.139+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-21T08:55:51.203+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-21T08:55:51.211+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-21T11:08:05.981+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-21T11:08:06.001+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-21T11:08:06.008+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [queued]>
[2024-06-21T11:08:06.008+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-21T11:08:06.020+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_constructor_task> on 2024-06-09 00:00:00+00:00
[2024-06-21T11:08:06.026+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=307) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-21T11:08:06.028+0000] {standard_task_runner.py:63} INFO - Started process 361 to run task
[2024-06-21T11:08:06.028+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_taskflow', 'load_constructor_task', 'scheduled__2024-06-09T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp8c_27eng']
[2024-06-21T11:08:06.030+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask load_constructor_task
[2024-06-21T11:08:06.077+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_taskflow.load_constructor_task scheduled__2024-06-09T00:00:00+00:00 [running]> on host 55d87b1d1f78
[2024-06-21T11:08:06.214+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_taskflow' AIRFLOW_CTX_TASK_ID='load_constructor_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-09T00:00:00+00:00'
[2024-06-21T11:08:06.215+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-21T11:08:06.216+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-21T11:08:06.217+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-21T11:08:06.231+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-21T11:08:06.231+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-21T11:08:06.238+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_taskflow, task_id=load_constructor_task, run_id=scheduled__2024-06-09T00:00:00+00:00, execution_date=20240609T000000, start_date=20240621T110806, end_date=20240621T110806
[2024-06-21T11:08:06.281+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-21T11:08:06.308+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-21T11:08:06.312+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
