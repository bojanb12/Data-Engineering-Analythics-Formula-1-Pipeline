[2024-06-18T12:00:00.972+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:00:00.986+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:00:00.991+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:00:00.991+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:00:00.998+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:00:01.004+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1252) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:00:01.005+0000] {standard_task_runner.py:63} INFO - Started process 1254 to run task
[2024-06-18T12:00:01.005+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpebp7s1x5']
[2024-06-18T12:00:01.006+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T12:00:01.037+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T12:00:01.087+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:00:01.088+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:00:01.089+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:00:01.090+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:00:01.090+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:00:01.192+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:00:01.193+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:00:01.194+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:00:01.194+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T12:00:01.195+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:00:01.195+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:00:01.239+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T12:00:01.239+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:00:01.240+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:00:01.240+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:30:59.580+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to success. Terminating instance.
[2024-06-18T12:30:59.581+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:30:59.582+0000] {process_utils.py:132} INFO - Sending 15 to group 1254. PIDs of all processes in the group: [1254]
[2024-06-18T12:30:59.582+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 1254
[2024-06-18T12:30:59.583+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-06-18T12:30:59.583+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:30:59.609+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=1254, status='terminated', exitcode=0, started='12:00:00') (1254) terminated with exit code 0
[2024-06-18T12:46:03.733+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:46:03.749+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:46:03.754+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:46:03.754+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:46:03.762+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:46:03.768+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=2000) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:46:03.769+0000] {standard_task_runner.py:63} INFO - Started process 2002 to run task
[2024-06-18T12:46:03.770+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpidkr5kq1']
[2024-06-18T12:46:03.772+0000] {standard_task_runner.py:91} INFO - Job 98: Subtask consume_and_load_raceResultsFact
[2024-06-18T12:46:03.810+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T12:46:03.874+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:46:03.875+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:46:03.877+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:46:03.877+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:46:03.878+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:46:03.979+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:46:03.980+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:46:03.981+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:46:03.981+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T12:46:03.982+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:46:03.982+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:46:04.040+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T12:46:04.040+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:46:04.041+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:46:04.041+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:46:05.145+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:46:05.146+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/ergast_kafka_consume_and_load.py", line 968, in consume_and_load_raceResultsFact
    race_result_data = message.value
                       ^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'value'. Did you mean: 'values'?
[2024-06-18T12:46:05.154+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T124603, end_date=20240618T124605
[2024-06-18T12:46:05.162+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 98 for task consume_and_load_raceResultsFact ('dict' object has no attribute 'value'; 2002)
[2024-06-18T12:46:05.188+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-18T12:46:05.200+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:46:05.202+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:57:09.794+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:57:09.811+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:57:09.816+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:57:09.816+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:57:09.824+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:57:09.830+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1259) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:57:09.831+0000] {standard_task_runner.py:63} INFO - Started process 1261 to run task
[2024-06-18T12:57:09.831+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp9g91q405']
[2024-06-18T12:57:09.832+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T12:57:09.865+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host 29634c3e6318
[2024-06-18T12:57:09.920+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:57:09.920+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:57:09.922+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:57:09.922+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:57:09.923+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:57:10.025+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:57:10.025+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:57:10.026+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:57:10.026+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T12:57:10.027+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:57:10.027+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:57:10.074+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T12:57:10.074+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:57:10.075+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:57:10.075+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:57:11.372+0000] {logging_mixin.py:188} INFO - No new messages received. Ending task.
[2024-06-18T12:57:11.373+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:57:11.373+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>
[2024-06-18T12:57:11.374+0000] {logging_mixin.py:188} INFO - Total number of race results loaded into the database: 40
[2024-06-18T12:57:11.374+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:57:11.375+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:57:11.385+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T125709, end_date=20240618T125711
[2024-06-18T12:57:11.410+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:57:11.422+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:57:11.424+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:22:39.505+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:22:39.521+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:22:39.527+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:22:39.527+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:22:39.535+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:22:39.540+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1282) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:22:39.541+0000] {standard_task_runner.py:63} INFO - Started process 1284 to run task
[2024-06-18T13:22:39.542+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp9l6gddyv']
[2024-06-18T13:22:39.543+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T13:22:39.574+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host 642827d53473
[2024-06-18T13:22:39.632+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:22:39.633+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:22:39.636+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:22:39.637+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:22:39.637+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:22:39.739+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:22:39.740+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:22:39.741+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T13:22:39.741+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T13:22:39.743+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:22:39.743+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:22:39.808+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T13:22:39.809+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:22:39.809+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:22:39.809+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:22:41.088+0000] {logging_mixin.py:188} INFO - No new messages received. Ending task.
[2024-06-18T13:22:41.088+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:22:41.088+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>
[2024-06-18T13:22:41.089+0000] {logging_mixin.py:188} INFO - Total number of race results loaded into the database: 40
[2024-06-18T13:22:41.089+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:22:41.089+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:22:41.097+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T132239, end_date=20240618T132241
[2024-06-18T13:22:41.121+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:22:41.132+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:22:41.134+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:32:47.303+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:32:47.318+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:32:47.323+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:32:47.323+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:32:47.331+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:32:47.336+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1250) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:32:47.337+0000] {standard_task_runner.py:63} INFO - Started process 1252 to run task
[2024-06-18T13:32:47.338+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpiom39j45']
[2024-06-18T13:32:47.339+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T13:32:47.371+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host 9ae4be1c5479
[2024-06-18T13:32:47.424+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:32:47.424+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:32:47.426+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:32:47.426+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:32:47.427+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:32:47.529+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:32:47.529+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:32:47.531+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T13:32:47.531+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T13:32:47.532+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:32:47.533+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:32:47.592+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T13:32:47.593+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:32:47.593+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:32:47.594+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:32:48.883+0000] {logging_mixin.py:188} INFO - No new messages received. Ending task.
[2024-06-18T13:32:48.883+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:32:48.884+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>
[2024-06-18T13:32:48.884+0000] {logging_mixin.py:188} INFO - Total number of race results loaded into the database: 40
[2024-06-18T13:32:48.884+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:32:48.884+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:32:48.891+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T133247, end_date=20240618T133248
[2024-06-18T13:32:48.917+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:32:48.927+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:32:48.929+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:01:58.638+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:01:58.653+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:01:58.658+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:01:58.658+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:01:58.666+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:01:58.671+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1279) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:01:58.671+0000] {standard_task_runner.py:63} INFO - Started process 1281 to run task
[2024-06-18T14:01:58.672+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpsmibgz44']
[2024-06-18T14:01:58.673+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T14:01:58.704+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host a16dbee39cfe
[2024-06-18T14:01:58.755+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:01:58.756+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:01:58.758+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T14:01:58.758+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T14:01:58.759+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T14:01:58.861+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T14:01:58.861+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T14:01:58.862+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T14:01:58.863+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T14:01:58.864+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T14:01:58.864+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T14:01:58.929+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T14:01:58.930+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T14:01:58.930+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T14:01:58.930+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:02:00.220+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:02:00.221+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/ergast_kafka_consume_and_load.py", line 958, in consume_and_load_raceResultsFact
    logging.info("No new messages received. Ending task.")
    ^^^^^^^
NameError: name 'logging' is not defined. Did you forget to import 'logging'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/ergast_kafka_consume_and_load.py", line 1082, in consume_and_load_raceResultsFact
    logging.error(f"Error polling messages: {e}")
    ^^^^^^^
NameError: name 'logging' is not defined. Did you forget to import 'logging'
[2024-06-18T14:02:00.232+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T140158, end_date=20240618T140200
[2024-06-18T14:02:00.241+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 53 for task consume_and_load_raceResultsFact (name 'logging' is not defined; 1281)
[2024-06-18T14:02:00.252+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-18T14:02:00.263+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:02:00.265+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:11:32.808+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:11:32.825+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:11:32.831+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:11:32.832+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:11:32.840+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_raceResultsFact> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:11:32.845+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1258) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:11:32.846+0000] {standard_task_runner.py:63} INFO - Started process 1260 to run task
[2024-06-18T14:11:32.847+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_raceResultsFact', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp0pcbt2z1']
[2024-06-18T14:11:32.849+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask consume_and_load_raceResultsFact
[2024-06-18T14:11:32.880+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_raceResultsFact scheduled__2024-06-17T00:00:00+00:00 [running]> on host f083cbcc503e
[2024-06-18T14:11:32.933+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_raceResultsFact' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:11:32.934+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:11:32.935+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:11:32.936+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T14:11:32.936+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:11:33.038+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T14:11:33.039+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T14:11:33.040+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T14:11:33.040+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('your_kafka_topic_raceResults',)
[2024-06-18T14:11:33.042+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T14:11:33.042+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T14:11:33.105+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('your_kafka_topic_raceResults', 0)]
[2024-06-18T14:11:33.106+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:11:33.107+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:11:33.107+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:11:34.366+0000] {logging_mixin.py:188} INFO - No new messages received. Ending task.
[2024-06-18T14:11:34.367+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:11:34.367+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>
[2024-06-18T14:11:34.368+0000] {logging_mixin.py:188} INFO - Total number of race results loaded into the database: 40
[2024-06-18T14:11:34.368+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T14:11:34.369+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:11:34.380+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_raceResultsFact, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T141132, end_date=20240618T141134
[2024-06-18T14:11:34.426+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T14:11:34.439+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:11:34.440+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
