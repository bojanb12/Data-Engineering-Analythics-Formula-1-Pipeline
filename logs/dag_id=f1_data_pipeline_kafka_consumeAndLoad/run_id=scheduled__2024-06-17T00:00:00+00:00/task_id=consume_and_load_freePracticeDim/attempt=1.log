[2024-06-18T07:23:47.466+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T07:23:47.482+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:23:47.488+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T07:23:47.488+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T07:23:47.497+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T07:23:47.502+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1191) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T07:23:47.503+0000] {standard_task_runner.py:63} INFO - Started process 1199 to run task
[2024-06-18T07:23:47.503+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpbjb34iyx']
[2024-06-18T07:23:47.505+0000] {standard_task_runner.py:91} INFO - Job 48: Subtask consume_and_load_freePracticeDim
[2024-06-18T07:23:47.541+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host ce62f6b650cd
[2024-06-18T07:23:47.596+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T07:23:47.597+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T07:23:47.599+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-18T07:23:47.600+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T07:23:47.600+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-18T07:23:47.702+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T07:23:47.703+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T07:23:47.704+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T07:23:47.704+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T07:23:47.706+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T07:23:47.706+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T07:23:47.740+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T07:23:47.741+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: connecting to kafka:9092 [('172.18.0.6', 9092) IPv4]
[2024-06-18T07:23:47.741+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.18.0.6', 9092)]>: Connection complete.
[2024-06-18T07:23:47.742+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-18T07:23:57.930+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>: Closing connection. 
[2024-06-18T07:23:57.931+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.18.0.6', 9092)]>
[2024-06-18T07:23:57.931+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T07:23:57.931+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T07:23:57.932+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T07:23:57.938+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T072347, end_date=20240618T072357
[2024-06-18T07:23:57.969+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T07:23:57.979+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T07:23:57.980+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T08:47:21.512+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T08:47:21.528+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:47:21.534+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T08:47:21.534+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T08:47:21.542+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T08:47:21.547+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=2425) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T08:47:21.548+0000] {standard_task_runner.py:63} INFO - Started process 2432 to run task
[2024-06-18T08:47:21.548+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp06ty359x']
[2024-06-18T08:47:21.550+0000] {standard_task_runner.py:91} INFO - Job 72: Subtask consume_and_load_freePracticeDim
[2024-06-18T08:47:21.583+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host d26fdf24870c
[2024-06-18T08:47:21.654+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T08:47:21.655+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T08:47:21.656+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-18T08:47:21.657+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T08:47:21.657+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-18T08:47:21.759+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T08:47:21.760+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T08:47:21.760+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T08:47:21.761+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T08:47:21.762+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T08:47:21.762+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T08:47:21.789+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T08:47:21.790+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: connecting to kafka:9092 [('172.21.0.6', 9092) IPv4]
[2024-06-18T08:47:21.791+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.21.0.6', 9092)]>: Connection complete.
[2024-06-18T08:47:21.791+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:47:32.023+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>: Closing connection. 
[2024-06-18T08:47:32.023+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.21.0.6', 9092)]>
[2024-06-18T08:47:32.024+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T08:47:32.025+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T08:47:32.025+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T08:47:32.032+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T084721, end_date=20240618T084732
[2024-06-18T08:47:32.046+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T08:47:32.056+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T08:47:32.057+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T09:01:36.501+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T09:01:36.516+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T09:01:36.522+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T09:01:36.522+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T09:01:36.531+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T09:01:36.536+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1184) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T09:01:36.536+0000] {standard_task_runner.py:63} INFO - Started process 1195 to run task
[2024-06-18T09:01:36.537+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp7ar_9pvd']
[2024-06-18T09:01:36.538+0000] {standard_task_runner.py:91} INFO - Job 51: Subtask consume_and_load_freePracticeDim
[2024-06-18T09:01:36.571+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 85d13f87db98
[2024-06-18T09:01:36.629+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T09:01:36.630+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T09:01:36.631+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T09:01:36.632+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T09:01:36.632+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T09:01:36.734+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T09:01:36.734+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T09:01:36.735+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T09:01:36.735+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T09:01:36.736+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T09:01:36.736+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T09:01:36.764+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T09:01:36.765+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T09:01:36.766+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T09:01:36.766+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T09:01:46.950+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T09:01:46.950+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>
[2024-06-18T09:01:46.951+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T09:01:46.951+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T09:01:46.951+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T09:01:46.958+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T090136, end_date=20240618T090146
[2024-06-18T09:01:46.996+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T09:01:47.006+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T09:01:47.007+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T10:55:57.376+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T10:55:57.393+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T10:55:57.399+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T10:55:57.399+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T10:55:57.407+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T10:55:57.413+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=4018) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T10:55:57.414+0000] {standard_task_runner.py:63} INFO - Started process 4025 to run task
[2024-06-18T10:55:57.414+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '141', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpqtzs40av']
[2024-06-18T10:55:57.416+0000] {standard_task_runner.py:91} INFO - Job 141: Subtask consume_and_load_freePracticeDim
[2024-06-18T10:55:57.452+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 85d13f87db98
[2024-06-18T10:55:57.508+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T10:55:57.509+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T10:55:57.511+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T10:55:57.511+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T10:55:57.511+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T10:55:57.614+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T10:55:57.614+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T10:55:57.616+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T10:55:57.616+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T10:55:57.617+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T10:55:57.618+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T10:55:57.648+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T10:55:57.649+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: connecting to kafka:9092 [('172.23.0.6', 9092) IPv4]
[2024-06-18T10:55:57.649+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.23.0.6', 9092)]>: Connection complete.
[2024-06-18T10:55:57.650+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T10:56:07.841+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>: Closing connection. 
[2024-06-18T10:56:07.841+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.23.0.6', 9092)]>
[2024-06-18T10:56:07.842+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 0
[2024-06-18T10:56:07.842+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T10:56:07.843+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T10:56:07.850+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T105557, end_date=20240618T105607
[2024-06-18T10:56:07.875+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T10:56:07.886+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T10:56:07.887+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T11:59:29.231+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T11:59:29.246+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:59:29.252+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T11:59:29.252+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T11:59:29.259+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T11:59:29.264+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1236) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T11:59:29.265+0000] {standard_task_runner.py:63} INFO - Started process 1244 to run task
[2024-06-18T11:59:29.265+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp0fqi4yjt']
[2024-06-18T11:59:29.266+0000] {standard_task_runner.py:91} INFO - Job 52: Subtask consume_and_load_freePracticeDim
[2024-06-18T11:59:29.297+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T11:59:29.355+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T11:59:29.355+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T11:59:29.357+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T11:59:29.358+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T11:59:29.358+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T11:59:29.460+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T11:59:29.460+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T11:59:29.461+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T11:59:29.461+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T11:59:29.462+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T11:59:29.462+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T11:59:29.492+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T11:59:29.494+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T11:59:29.494+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T11:59:29.495+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T11:59:39.674+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T11:59:39.675+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>
[2024-06-18T11:59:39.675+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T11:59:39.675+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T11:59:39.676+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T11:59:39.683+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T115929, end_date=20240618T115939
[2024-06-18T11:59:39.696+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T11:59:39.707+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T11:59:39.708+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:44:37.489+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:44:37.507+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:44:37.514+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:44:37.514+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:44:37.523+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:44:37.529+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1903) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:44:37.531+0000] {standard_task_runner.py:63} INFO - Started process 1912 to run task
[2024-06-18T12:44:37.530+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '75', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpkvjuetxk']
[2024-06-18T12:44:37.533+0000] {standard_task_runner.py:91} INFO - Job 75: Subtask consume_and_load_freePracticeDim
[2024-06-18T12:44:37.573+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T12:44:37.632+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:44:37.633+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:44:37.635+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:44:37.636+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:44:37.636+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:44:37.737+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:44:37.738+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:44:37.738+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:44:37.739+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T12:44:37.739+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:44:37.739+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:44:37.763+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T12:44:37.764+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:44:37.764+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:44:37.764+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:44:47.903+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:44:47.904+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>
[2024-06-18T12:44:47.904+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 0
[2024-06-18T12:44:47.904+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:44:47.905+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:44:47.912+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T124437, end_date=20240618T124447
[2024-06-18T12:44:47.951+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:44:47.962+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:44:47.964+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:45:33.473+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:45:33.488+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:45:33.494+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:45:33.494+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:45:33.502+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:45:33.507+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1981) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:45:33.508+0000] {standard_task_runner.py:63} INFO - Started process 1989 to run task
[2024-06-18T12:45:33.509+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '94', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmposcwl5hb']
[2024-06-18T12:45:33.510+0000] {standard_task_runner.py:91} INFO - Job 94: Subtask consume_and_load_freePracticeDim
[2024-06-18T12:45:33.545+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 21d7efd887f9
[2024-06-18T12:45:33.604+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:45:33.605+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:45:33.607+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:45:33.607+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:45:33.608+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:45:33.710+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:45:33.710+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:45:33.712+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:45:33.712+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T12:45:33.713+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:45:33.714+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:45:33.756+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T12:45:33.756+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: connecting to kafka:9092 [('172.24.0.6', 9092) IPv4]
[2024-06-18T12:45:33.757+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.24.0.6', 9092)]>: Connection complete.
[2024-06-18T12:45:33.757+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:45:43.901+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:45:43.901+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.24.0.6', 9092)]>
[2024-06-18T12:45:43.902+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 0
[2024-06-18T12:45:43.902+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:45:43.902+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:45:43.910+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T124533, end_date=20240618T124543
[2024-06-18T12:45:43.950+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:45:43.960+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:45:43.962+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T12:56:33.257+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T12:56:33.273+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:56:33.278+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T12:56:33.279+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T12:56:33.287+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T12:56:33.292+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1241) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T12:56:33.293+0000] {standard_task_runner.py:63} INFO - Started process 1248 to run task
[2024-06-18T12:56:33.293+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmptz9od6dh']
[2024-06-18T12:56:33.295+0000] {standard_task_runner.py:91} INFO - Job 49: Subtask consume_and_load_freePracticeDim
[2024-06-18T12:56:33.329+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 29634c3e6318
[2024-06-18T12:56:33.386+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T12:56:33.387+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T12:56:33.388+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:56:33.389+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T12:56:33.389+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:56:33.491+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T12:56:33.492+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T12:56:33.493+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T12:56:33.493+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T12:56:33.494+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T12:56:33.495+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T12:56:33.529+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T12:56:33.529+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: connecting to kafka:9092 [('172.25.0.6', 9092) IPv4]
[2024-06-18T12:56:33.530+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.25.0.6', 9092)]>: Connection complete.
[2024-06-18T12:56:33.530+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:56:43.724+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>: Closing connection. 
[2024-06-18T12:56:43.724+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.25.0.6', 9092)]>
[2024-06-18T12:56:43.725+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T12:56:43.725+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T12:56:43.725+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T12:56:43.733+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T125633, end_date=20240618T125643
[2024-06-18T12:56:43.758+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T12:56:43.781+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T12:56:43.786+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:22:03.039+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:22:03.055+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:22:03.061+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:22:03.061+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:22:03.069+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:22:03.074+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1263) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:22:03.075+0000] {standard_task_runner.py:63} INFO - Started process 1272 to run task
[2024-06-18T13:22:03.076+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp7bczvmkp']
[2024-06-18T13:22:03.077+0000] {standard_task_runner.py:91} INFO - Job 50: Subtask consume_and_load_freePracticeDim
[2024-06-18T13:22:03.111+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 642827d53473
[2024-06-18T13:22:03.167+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:22:03.168+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:22:03.169+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:22:03.170+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:22:03.170+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:22:03.272+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:22:03.272+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:22:03.273+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T13:22:03.274+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T13:22:03.275+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:22:03.276+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:22:03.308+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T13:22:03.310+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: connecting to kafka:9092 [('172.26.0.6', 9092) IPv4]
[2024-06-18T13:22:03.310+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.26.0.6', 9092)]>: Connection complete.
[2024-06-18T13:22:03.310+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:22:13.512+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:22:13.512+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.26.0.6', 9092)]>
[2024-06-18T13:22:13.513+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T13:22:13.513+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:22:13.513+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:22:13.520+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T132203, end_date=20240618T132213
[2024-06-18T13:22:13.538+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:22:13.553+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:22:13.555+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T13:32:12.052+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T13:32:12.068+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:32:12.073+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T13:32:12.073+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T13:32:12.081+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T13:32:12.086+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1231) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T13:32:12.087+0000] {standard_task_runner.py:63} INFO - Started process 1240 to run task
[2024-06-18T13:32:12.088+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp42elq4eo']
[2024-06-18T13:32:12.089+0000] {standard_task_runner.py:91} INFO - Job 50: Subtask consume_and_load_freePracticeDim
[2024-06-18T13:32:12.122+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host 9ae4be1c5479
[2024-06-18T13:32:12.177+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T13:32:12.177+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T13:32:12.179+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:32:12.180+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T13:32:12.180+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:32:12.282+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T13:32:12.283+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T13:32:12.284+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T13:32:12.284+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T13:32:12.285+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T13:32:12.286+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T13:32:12.319+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T13:32:12.320+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: connecting to kafka:9092 [('172.28.0.6', 9092) IPv4]
[2024-06-18T13:32:12.320+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.28.0.6', 9092)]>: Connection complete.
[2024-06-18T13:32:12.321+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:32:22.505+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>: Closing connection. 
[2024-06-18T13:32:22.506+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.28.0.6', 9092)]>
[2024-06-18T13:32:22.506+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T13:32:22.507+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T13:32:22.507+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T13:32:22.515+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T133212, end_date=20240618T133222
[2024-06-18T13:32:22.555+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T13:32:22.569+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T13:32:22.570+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:01:22.937+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:01:22.954+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:01:22.960+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:01:22.961+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:01:22.969+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:01:22.975+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1261) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:01:22.976+0000] {standard_task_runner.py:63} INFO - Started process 1271 to run task
[2024-06-18T14:01:22.976+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmpuz_xa59v']
[2024-06-18T14:01:22.978+0000] {standard_task_runner.py:91} INFO - Job 52: Subtask consume_and_load_freePracticeDim
[2024-06-18T14:01:23.014+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host a16dbee39cfe
[2024-06-18T14:01:23.073+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:01:23.074+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:01:23.076+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T14:01:23.076+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T14:01:23.077+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T14:01:23.179+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T14:01:23.179+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T14:01:23.180+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T14:01:23.180+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T14:01:23.181+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T14:01:23.181+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T14:01:23.212+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T14:01:23.213+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: connecting to kafka:9092 [('172.30.0.6', 9092) IPv4]
[2024-06-18T14:01:23.213+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.6', 9092)]>: Connection complete.
[2024-06-18T14:01:23.213+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:01:33.399+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:01:33.399+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.30.0.6', 9092)]>
[2024-06-18T14:01:33.400+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T14:01:33.400+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T14:01:33.400+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:01:33.409+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T140122, end_date=20240618T140133
[2024-06-18T14:01:33.434+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T14:01:33.450+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:01:33.455+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T14:10:58.453+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T14:10:58.468+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:10:58.474+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T14:10:58.475+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-18T14:10:58.483+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): consume_and_load_freePracticeDim> on 2024-06-17 00:00:00+00:00
[2024-06-18T14:10:58.488+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1241) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-18T14:10:58.489+0000] {standard_task_runner.py:63} INFO - Started process 1250 to run task
[2024-06-18T14:10:58.490+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'f1_data_pipeline_kafka_consumeAndLoad', 'consume_and_load_freePracticeDim', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/ergast_kafka_consume_and_load.py', '--cfg-path', '/tmp/tmp4zp2c0mn']
[2024-06-18T14:10:58.491+0000] {standard_task_runner.py:91} INFO - Job 52: Subtask consume_and_load_freePracticeDim
[2024-06-18T14:10:58.525+0000] {task_command.py:426} INFO - Running <TaskInstance: f1_data_pipeline_kafka_consumeAndLoad.consume_and_load_freePracticeDim scheduled__2024-06-17T00:00:00+00:00 [running]> on host f083cbcc503e
[2024-06-18T14:10:58.594+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='f1_data_pipeline_kafka_consumeAndLoad' AIRFLOW_CTX_TASK_ID='consume_and_load_freePracticeDim' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T14:10:58.595+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T14:10:58.597+0000] {conn.py:362} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:10:58.597+0000] {conn.py:957} INFO - Probing node bootstrap-0 broker version
[2024-06-18T14:10:58.598+0000] {conn.py:393} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:10:58.699+0000] {conn.py:1019} INFO - Broker version identified as 2.6.0
[2024-06-18T14:10:58.699+0000] {conn.py:1020} INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup
[2024-06-18T14:10:58.700+0000] {consumer.py:122} WARNING - group_id is None: disabling auto-commit.
[2024-06-18T14:10:58.700+0000] {subscription_state.py:167} INFO - Updating subscribed topics to: ('f1_data_topic_race',)
[2024-06-18T14:10:58.701+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2024-06-18T14:10:58.701+0000] {base.py:84} INFO - Using connection ID 'sourcedb_connection' for task execution.
[2024-06-18T14:10:58.726+0000] {subscription_state.py:253} INFO - Updated partition assignment: [('f1_data_topic_race', 0)]
[2024-06-18T14:10:58.727+0000] {conn.py:362} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: connecting to kafka:9092 [('172.31.0.6', 9092) IPv4]
[2024-06-18T14:10:58.727+0000] {conn.py:393} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.31.0.6', 9092)]>: Connection complete.
[2024-06-18T14:10:58.728+0000] {conn.py:673} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:11:08.914+0000] {conn.py:673} INFO - <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>: Closing connection. 
[2024-06-18T14:11:08.914+0000] {future.py:77} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:9092 <connected> [IPv4 ('172.31.0.6', 9092)]>
[2024-06-18T14:11:08.915+0000] {logging_mixin.py:188} INFO - Total number of free practices loaded into the database: 24
[2024-06-18T14:11:08.915+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T14:11:08.916+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T14:11:08.922+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=f1_data_pipeline_kafka_consumeAndLoad, task_id=consume_and_load_freePracticeDim, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T141058, end_date=20240618T141108
[2024-06-18T14:11:08.953+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T14:11:08.967+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T14:11:08.968+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
